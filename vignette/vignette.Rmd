---
title: "vignette"
author: "Fabien"
date: "2023-10-04"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r load the packages, message=FALSE, warning=FALSE}
library(mcpredomics)
library(predomics)

```




```{r loading filtering the data, message=FALSE, warning=FALSE, paged.print=FALSE}
# load the data
data("mc.input")
#recover the vector y
yvec <- mc.input$y$Enterotype[match(colnames(mc.input$X), rownames(mc.input$y))]
#Divide the dataset into training and testing
proportion_test <- 0.2
taille_test <- round(proportion_test * ncol(mc.input$X))
indices_test <- sample(1:ncol(mc.input$X), taille_test)
X <- mc.input$X[,-indices_test]
X.test <- mc.input$X[,indices_test]
y <- as.vector(yvec[-indices_test])
y.test <- as.vector(yvec[indices_test])

```

## Setting the learner context

```{r setting the classifier}

clf <- terga1_ovo(nCores = 1,
              seed = 1,
              plot = TRUE
)
printy(clf) # print the object for more information
isClf(clf)  # test whether the object is a classifier
class(clf)  # the class of the classifier object
```

## Running the learner experiment
```{r running experiment, echo=TRUE, fig.width=5}
runit = TRUE
if(runit)
{
  res_clf <- fit_OVO(X = X, y = y, clf = clf, cross.validate = TRUE, nfolds = 1); # class(res_clf)
  # save results
  save(res_clf, clf, file = "res_clf.rda", compression_level = 9)
}

# ... Database X is not a matrix! Converting ...
# ... Classification mode, computing factor(y) for speedup and robustness
# ... Loading feature correlation for speedup
# ... Correlation file loaded
# ... Storing data in the classifier object for speedup
# ... Computing ternary coefficients for speedup
# ... One seed found, setting by default
# ... Running the classifier terga2 with a single CPU
# ... Second and faster version of terga fitting based on Genetic Algorithm heuristics ...
# ... Cross validation mode
# ... Starting cross validation not in parallel
# ....................................................................................................
# ....................................................................................................
# ....................................................................................................
# ....................................................................................................
# ....................................................................................................
# ....................................................................................................
# ....................................................................................................
# ....................................................................................................
# ....................................................................................................
# ....................................................................................................
# ....................................................................................................
# ... Learning process is finished succesfuly
# ... Thank you for using Predomics. Don't forget to digest the results now.
# 
# [1] "experiment" "predomics" 
```



```{r load results, message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}
if(!runit)
{
  load("cirrhosis1_res_clf_terga2.rda")
}
```

### Digesting the results
```{r digesting results, fig.height=10, fig.width=7, message=FALSE, warning=FALSE, paged.print=FALSE}
res_clf.dig <- digest(obj = res_clf, penalty = 0.75/100, plot = TRUE)
```

### Visualizing the best model
```{r best model, fig.width=7, warning=FALSE}


# get the best model
best.model <- res_clf.dig$best$model
printy(best.model)
grid.arrange(plotModel_ovo(best.model, X=X, y=y, sort.features = FALSE, feature.name = TRUE),
plotModel_ovo(best.model, X=X, y=y, sort.features = FALSE, feature.name = TRUE, importance = TRUE),ncol=2)
```


### Testing the model in another dataset
```{r}


X.test <- dataset_test$X[rownames(dataset_test$X),]
all(rownames(dataset_test$X) == rownames(X.test)) # test ordering
y.test <- dataset_test$y

best.model.test <- evaluateModel_ovo(mod = best.model, X = X.test, y = y.test, clf = clf, eval.all = TRUE, force.re.evaluation = TRUE, mode = "test")
printy(best.model.test)
```
### One-versus-one class distribution train

```{r One-versus-one class distribution}
  nClasse <- unique(y)
  list_y <- list()
  list_X <- list()
  k <- 1
  for (i in 1:(length(nClasse)-1)) {
    for (j in (i+1):length(nClasse)) {
      class_i <- nClasse[i]
      class_j <- nClasse[j]
      indices <- which(y == class_i | y == class_j)
      y_pair <- y[indices]
      X_pair <- X[,indices]
      list_y[[k]] <- y_pair
      list_X[[k]] <- X_pair
      k <- k + 1
    }
  }



```

###One-versus-one class distribution test


```{r One-versus-one class distribution}
 
  nClasse <- unique(y.test)
  list_y.test <- list()
  list_X.test <- list()
  k <- 1
  for (i in 1:(length(nClasse)-1)) {
    for (j in (i+1):length(nClasse)) {
      class_i <- nClasse[i]
      class_j <- nClasse[j]
      indicess <- which(y.test == class_i | y.test == class_j)
      y_paire <- y[indicess]
      X_paire <- X[,indicess]
      list_y.test[[k]] <- y_paire
      list_X.test[[k]] <- X_paire
      k <- k + 1
    }
  }

 
```


```{r}
  # we recover the first output to apply the plot
  X <- list_X[[1]]
  y <- list_y[[1]]
  X.test <- list_X.test[[1]]
  y.test <- list_y.test[[1]]
```


### Visualizing model performance AUC
```{r roc analyses, fig.height=7, fig.width=7, message=FALSE, warning=FALSE, paged.print=FALSE}

tmp <- plotAUC(best.model$score_, y, percent = TRUE); rm(tmp)

# create the roc objects
rocobj.train <- roc(y ~ best.model$score_)
rocobj.test <- roc(y.test ~ best.model.test$score_)

# make the plot
ggroc(list(train = rocobj.train, test = rocobj.test))
```

###Family of Best Models (FBM)

```{r roc analyses, fig.height=7, fig.width=7, message=FALSE, warning=FALSE, paged.print=FALSE}
# get the population of models scrambled by model size
pop <- modelCollectionToPopulation(res_clf$classifier$models)
printy(pop)
pop.df <- populationToDataFrame(pop)
head(pop.df[,-c(3,4,7,8,14)])
pop.df.melt <- melt(pop.df, id.vars = c("accuracy_","eval.sparsity"))

g.before <- ggplot(data = pop.df.melt, aes(y = accuracy_, x = eval.sparsity)) + 
  geom_boxplot(notch = FALSE, outlier.shape = " ", position = position_dodge(width=0.9), alpha = 0.3) + 
  geom_point(aes(color = eval.sparsity), position=position_jitterdodge(dodge.width=0.9), size = 1, alpha = 0.5) +
  ylim(c(0,1)) +
  xlab("Model parsimony") +
  ggtitle("Original population") +
  theme_bw() +
  theme(legend.position="bottom", legend.direction="horizontal") +
  guides(colour="none")

# select the best 
fbm <- selectBestPopulation(pop)
printy(fbm)
fbm.df <- populationToDataFrame(fbm)
fbm.df.melt <- melt(fbm.df, id.vars = c("accuracy_","eval.sparsity"))#; head(fbm.df.melt)

g.after <- ggplot(data = fbm.df.melt, aes(y = accuracy_, x = eval.sparsity)) + 
  geom_boxplot(notch = FALSE, position = position_dodge(width=0.9), alpha = 0.3) + 
  geom_point(aes(color = eval.sparsity), position=position_jitterdodge(dodge.width=0.9), size = 1, alpha = 0.5) +
  ylim(c(0,1)) +
  xlab("Model parsimony") +
  ggtitle("FBM") +
  theme_bw() +
  theme(legend.position="bottom", legend.direction="horizontal") +
  guides(colour="none")

grid.arrange(g.before, g.after, ncol =2)
```

###Analyzing the FBM
```{r feature exploration, fig.height=7, fig.width=7, message=FALSE, warning=FALSE, paged.print=FALSE}
fa <- makeFeatureAnnot(pop = fbm, 
                       X = X, 
                       y = y, 
                       clf = clf)
dim(fa$pop.noz)
(g1 <- plotFeatureModelCoeffs(feat.model.coeffs = fa$pop.noz))
(g2 <- plotAbundanceByClass(features = rownames(fa$pop.noz), X = X, y = y))
(g3 <- plotPrevalence(features = rownames(fa$pop.noz), X = X, y = y))
```
### Random Forest

```{r}
#training
library(randomForest)
X <- mc.input$X[,-indices_test]
X.test <- mc.input$X[,indices_test]
y <- yvec[-indices_test]
y.test <- yvec[indices_test]
rf <-randomForest(y ~ ., data = t(X),mtry = 4, ntree = 500, importance=TRUE) 
pre <- predict(rf,x = t(X) )
tab = table(predictions = pre, actuelles =y)
#matrix, Accuracy
round(sum(diag(tab))/sum(tab),2)
tab

```
### Testing
```{r}
X.test = t(X.test)
pred_test <- predict(rf,X.test )
tab2 = table(predictions = pred_test, actuelles =y.test)
#Matrix, Accuracy
round(sum(diag(tab2))/sum(tab2),2)
tab2
```



