for (j in (i + 1):length(nClasse)) {
class_i <- nClasse[i]
class_j <- nClasse[j]
# Sélectionner les indices des classes i et j
indices <- which(y == class_i | y == class_j)
y_pair <- y[indices]
# Compléter avec des valeurs aléatoires si nécessaire
if (length(y_pair) < length(scores[[k]])) {
missing_len <- length(scores[[k]]) - length(y_pair)
# Ajouter des valeurs aléatoires depuis y et X
y_random <- sample(y_pair, missing_len, replace = TRUE)
# Combiner les données existantes avec les valeurs aléatoires
y_pair <- c(y_pair, y_random)
}
# Stocker les résultats dans les listes
list_y[[k]] <- as.vector(y_pair)
k <- k + 1
}
}
} else {
for (i in 1:length(nClasse)) {
class_i <- nClasse[i]
# Créer une nouvelle variable y_temp avec "class_i" vs "All"
y_temp <- ifelse(y == class_i, as.character(class_i), "All")
# Compléter avec des valeurs aléatoires si nécessaire
if (length(y_temp) < length(scores[[i]])) {
missing_len <- length(scores[[i]]) - length(y_temp)
# Ajouter des valeurs aléatoires depuis y et X
y_random <- sample(y_temp, missing_len, replace = TRUE)
# Combiner les données existantes avec les valeurs aléatoires
y_temp <- c(y_temp, y_random)
}
# Stocker dans les listes
list_y[[i]] <- as.vector(y_temp)
}
}
# Boucle pour générer les plots pour chaque combinaison de classes
for (i in 1:length(list_y)) {
list_plo[[i]] <- plotAUC(score = list_scores[[i]], y = list_y[[i]], percent = TRUE)
}
return(list_plo)
}
plotAUC_mc <- function(scores, y, main = "", ci = TRUE, percent = TRUE, approch = "ovo") {
nClasse <- unique(y)
list_y <- list()
list_plo <- list()
list_scores <- list()
list_scores <- scores
if (approch == "ovo") {
k <- 1
for (i in 1:(length(nClasse) - 1)) {
for (j in (i + 1):length(nClasse)) {
class_i <- nClasse[i]
class_j <- nClasse[j]
# Sélectionner les indices des classes i et j
indices <- which(y == class_i | y == class_j)
y_pair <- y[indices]
# Compléter avec des valeurs aléatoires si nécessaire
if (length(y_pair) < length(scores[[k]])) {
missing_len <- length(scores[[k]]) - length(y_pair)
# Ajouter des valeurs aléatoires depuis y et X
y_random <- sample(y_pair, missing_len, replace = TRUE)
# Combiner les données existantes avec les valeurs aléatoires
y_pair <- c(y_pair, y_random)
}
# Stocker les résultats dans les listes
list_y[[k]] <- as.vector(y_pair)
k <- k + 1
}
}
} else {
for (i in 1:length(nClasse)) {
class_i <- nClasse[i]
# Créer une nouvelle variable y_temp avec "class_i" vs "All"
y_temp <- ifelse(y == class_i, as.character(class_i), "All")
# Compléter avec des valeurs aléatoires si nécessaire
if (length(y_temp) < length(scores[[i]])) {
missing_len <- length(scores[[i]]) - length(y_temp)
# Ajouter des valeurs aléatoires depuis y et X
y_random <- sample(y_temp, missing_len, replace = TRUE)
# Combiner les données existantes avec les valeurs aléatoires
y_temp <- c(y_temp, y_random)
}
# Stocker dans les listes
list_y[[i]] <- as.vector(y_temp)
}
}
# Boucle pour générer les plots pour chaque combinaison de classes
for (i in 1:length(list_y)) {
list_plo[[i]] <- plotAUC(score = list_scores[[i]], y = list_y[[i]], percent = TRUE)
}
return(list_plo)
}
library(pROC)
library(ggplot2)
tmp <- plotAUC_mc(best.model_multi$score_, y, percent = TRUE, approch = "ovo"); rm(tmp)
# Create ROC objects for the training set
roc_objects_train <- lapply(best.model_multi$score_, function(score) {
roc(response = y, predictor = score)
})
# Create ROC objects for the test set
roc_objects_test <- lapply(best.model.test_multi$score_, function(score) {
roc(response = y.test, predictor = score)
})
# Function to extract TPR and FPR for ggplot
extract_roc_data <- function(roc_obj, dataset_name, submodel_name) {
data.frame(
FPR = 1 - roc_obj$specificities,  # False Positive Rate
TPR = roc_obj$sensitivities,       # True Positive Rate
Submodel = submodel_name,
Dataset = dataset_name
)
}
# Extract data from ROC objects for the training set
roc_df_train <- do.call(rbind, lapply(seq_along(roc_objects_train), function(i) {
extract_roc_data(roc_objects_train[[i]], "Train", paste("Submodel", i))
}))
# Extract data from ROC objects for the test set
roc_df_test <- do.call(rbind, lapply(seq_along(roc_objects_test), function(i) {
extract_roc_data(roc_objects_test[[i]], "Test", paste("Submodel", i))
}))
# Combine training and test ROC data
roc_df <- rbind(roc_df_train, roc_df_test)
# Make sure there are no NULL values in FPR and TPR
roc_df <- roc_df[!is.na(roc_df$FPR) & !is.na(roc_df$TPR), ]
# Plot ROC curves using ggplot
ggplot(roc_df, aes(x = FPR, y = TPR, color = Dataset)) +
geom_line() +
facet_wrap(~ Submodel, scales = "free", labeller = label_both) +
labs(title = "ROC Curves", x = "False Positive Rate", y = "True Positive Rate") +
theme_minimal() +
theme(legend.position = "bottom")
# Convert the model collection into a population of models scrambled by model size
pop <- modelCollectionToPopulation(Multi_Predomics_aggregation_ova$classifier$models)
# Convert the model collection into a population of models scrambled by model size
pop <- modelCollectionToPopulation(Multi_Predomics_aggregation_ovo$classifier$models)
printy_mc(pop)
# Convert the population to a data frame
pop.df <- populationToDataFrame_mc(pop)
# Plotting for the original population
g.before <- list()  # Initialize a list to store the plots
for(i in 1: length(pop.df)) {
pop.dff  <- as.data.frame(pop.df[[i]])  # Convert each submodel to a data frame
# Display the head of the dataframe excluding some columns
head(pop.dff[,-c(3, 4, 7, 8, 14)])
# Melt the dataframe for ggplot
pop.df.melt <- melt(pop.dff, id.vars = c("accuracy_", "eval.sparsity"))
# Create the ggplot for the original population
g.before[[i]] <- ggplot(data = pop.df.melt, aes(y = accuracy_, x = eval.sparsity)) +
geom_boxplot(notch = FALSE, outlier.shape = NA, position = position_dodge(width=0.9), alpha = 0.3) +
geom_point(aes(color = eval.sparsity), position=position_jitterdodge(dodge.width=0.9), size = 1, alpha = 0.5) +
ylim(c(0,1)) +
xlab("Model parsimony") +
ggtitle("Original population") +
theme_bw() +
theme(legend.position="bottom", legend.direction="horizontal") +
guides(colour="none")
}
# Select the best population models
fbm <- selectBestPopulation(pop)
printy_mc(fbm)
# Convert the best population models to a data frame
fbm.df <- populationToDataFrame_mc(fbm)
# Plotting for the selected best models
g.after <- list()  # Initialize a list to store the plots
for(j in 1:length(fbm.df)) {
fbm.dff  <- as.data.frame(fbm.df[[j]])  # Convert each submodel to a data frame
# Melt the dataframe for ggplot
fbm.df.melt <- melt(fbm.dff, id.vars = c("accuracy_", "eval.sparsity"))
# Create the ggplot for the best population models
g.after[[j]] <- ggplot(data = fbm.df.melt, aes(y = accuracy_, x = eval.sparsity)) +
geom_boxplot(notch = FALSE, position = position_dodge(width=0.9), alpha = 0.3) +
geom_point(aes(color = eval.sparsity), position=position_jitterdodge(dodge.width=0.9), size = 1, alpha = 0.5) +
ylim(c(0,1)) +
xlab("Model parsimony") +
ggtitle("FBM") +
theme_bw() +
theme(legend.position="bottom", legend.direction="horizontal") +
guides(colour="none")
}
# Arrange the plots side by side
grid.arrange(g.before[[1]], g.after[[1]], ncol = 2)
# Convert the model collection into a population of models scrambled by model size
pop <- modelCollectionToPopulation(Multi_Predomics_aggregation_ovo$classifier$models)
printy_mc(pop)
# Convert the population to a data frame
pop.df <- populationToDataFrame_mc(pop)
# Plotting for the original population
g.before <- list()  # Initialize a list to store the plots
for(i in 1: length(pop.df)) {
pop.dff  <- as.data.frame(pop.df[[i]])  # Convert each submodel to a data frame
# Display the head of the dataframe excluding some columns
head(pop.dff[,-c(3, 4, 7, 8, 14)])
# Melt the dataframe for ggplot
pop.df.melt <- melt(pop.dff, id.vars = c("accuracy_", "eval.sparsity"))
# Create the ggplot for the original population
g.before[[i]] <- ggplot(data = pop.df.melt, aes(y = accuracy_, x = eval.sparsity)) +
geom_boxplot(notch = FALSE, outlier.shape = NA, position = position_dodge(width=0.9), alpha = 0.3) +
geom_point(aes(color = eval.sparsity), position=position_jitterdodge(dodge.width=0.9), size = 1, alpha = 0.5) +
ylim(c(0,1)) +
xlab("Model parsimony") +
ggtitle("Original population") +
theme_bw() +
theme(legend.position="bottom", legend.direction="horizontal") +
guides(colour="none")
}
# Select the best population models
fbm <- selectBestPopulation(pop)
printy_mc(fbm)
# Convert the best population models to a data frame
fbm.df <- populationToDataFrame_mc(fbm)
# Plotting for the selected best models
g.after <- list()  # Initialize a list to store the plots
for(j in 1:length(fbm.df)) {
fbm.dff  <- as.data.frame(fbm.df[[j]])  # Convert each submodel to a data frame
# Melt the dataframe for ggplot
fbm.df.melt <- melt(fbm.dff, id.vars = c("accuracy_", "eval.sparsity"))
# Create the ggplot for the best population models
g.after[[j]] <- ggplot(data = fbm.df.melt, aes(y = accuracy_, x = eval.sparsity)) +
geom_boxplot(notch = FALSE, position = position_dodge(width=0.9), alpha = 0.3) +
geom_point(aes(color = eval.sparsity), position=position_jitterdodge(dodge.width=0.9), size = 1, alpha = 0.5) +
ylim(c(0,1)) +
xlab("Model parsimony") +
ggtitle("FBM") +
theme_bw() +
theme(legend.position="bottom", legend.direction="horizontal") +
guides(colour="none")
}
# Arrange the plots side by side
grid.arrange(g.before[[2]], g.after[[2]], ncol = 2)
fa <- makeFeatureAnnot_mc(pop = fbm,
X = X,
y = y,
clf = clf,
approch = "ovo")
dim(fa[[1]]$pop.noz)
for (i in 1:length(fa)) {
g <- plotFeatureModelCoeffs(feat.model.coeffs = fa[[i]]$pop.noz)
print(g)
}
(g2 <- plotAbundanceByClass_mc(features = fa, X = X, y = y, approch = "ovo"))
(g3 <- plotPrevalence_mc(features = fa, X = X, y = y , approch = "ovo"))
knitr::opts_chunk$set(echo = TRUE)
res_clf.dig_multi <- digestmc(obj = Multi_Predomics_Aggregation_ova , penalty = 0.75/100, plot = TRUE)
# get the best model
best.model_multi <- res_clf.dig_multi$best$model
printy_mc(best.model_multi)
plots11 <- plotModel_mc(best.model_multi, X, y, sort.features = FALSE, feature.name = TRUE, approch = "ova")
plots22 <- plotModel_mc(best.model_multi, X, y, sort.features = FALSE, feature.name = TRUE, importance = TRUE, approch = "ova")
# Extract the plots from each list and pass them to `grid.arrange
grid.arrange(grobs = c(plots11, plots22), ncol = 2)
clf <- regenerate_clf(clf, X, y, approch = "ova")
best.model.test_multi <- evaluateModel_mc(
mod = best.model_multi,
X = X.test,
y = y.test,
clf = clf,
eval.all = TRUE,
force.re.evaluation = TRUE,
approch = "ova",
aggregation_ = "Predomics_aggregation_ova",
mode = "test"
)
printy_mc(best.model.test_multi)
library(pROC)
library(ggplot2)
tmp <- plotAUC_mc(best.model_multi$score_, y, percent = TRUE, approch = "ova"); rm(tmp)
# Create ROC objects for the training set
roc_objects_train <- lapply(best.model_multi$score_, function(score) {
roc(response = y, predictor = score)
})
# Create ROC objects for the test set
roc_objects_test <- lapply(best.model.test_multi$score_, function(score) {
roc(response = y.test, predictor = score)
})
# Function to extract TPR and FPR for ggplot
extract_roc_data <- function(roc_obj, dataset_name, submodel_name) {
data.frame(
FPR = 1 - roc_obj$specificities,  # False Positive Rate
TPR = roc_obj$sensitivities,       # True Positive Rate
Submodel = submodel_name,
Dataset = dataset_name
)
}
# Extract data from ROC objects for the training set
roc_df_train <- do.call(rbind, lapply(seq_along(roc_objects_train), function(i) {
extract_roc_data(roc_objects_train[[i]], "Train", paste("Submodel", i))
}))
# Extract data from ROC objects for the test set
roc_df_test <- do.call(rbind, lapply(seq_along(roc_objects_test), function(i) {
extract_roc_data(roc_objects_test[[i]], "Test", paste("Submodel", i))
}))
# Combine training and test ROC data
roc_df <- rbind(roc_df_train, roc_df_test)
# Make sure there are no NULL values in FPR and TPR
roc_df <- roc_df[!is.na(roc_df$FPR) & !is.na(roc_df$TPR), ]
# Plot ROC curves using ggplot
ggplot(roc_df, aes(x = FPR, y = TPR, color = Dataset)) +
geom_line() +
facet_wrap(~ Submodel, scales = "free", labeller = label_both) +
labs(title = "ROC Curves", x = "False Positive Rate", y = "True Positive Rate") +
theme_minimal() +
theme(legend.position = "bottom")
# Convert the model collection into a population of models scrambled by model size
pop <- modelCollectionToPopulation(Multi_Predomics_Aggregation_ova$classifier$models)
printy_mc(pop)
# Convert the population to a data frame
pop.df <- populationToDataFrame_mc(pop)
# Plotting for the original population
g.before <- list()  # Initialize a list to store the plots
for(i in 1: length(pop.df)) {
pop.dff  <- as.data.frame(pop.df[[i]])  # Convert each submodel to a data frame
# Display the head of the dataframe excluding some columns
head(pop.dff[,-c(3, 4, 7, 8, 14)])
# Melt the dataframe for ggplot
pop.df.melt <- melt(pop.dff, id.vars = c("accuracy_", "eval.sparsity"))
# Create the ggplot for the original population
g.before[[i]] <- ggplot(data = pop.df.melt, aes(y = accuracy_, x = eval.sparsity)) +
geom_boxplot(notch = FALSE, outlier.shape = NA, position = position_dodge(width=0.9), alpha = 0.3) +
geom_point(aes(color = eval.sparsity), position=position_jitterdodge(dodge.width=0.9), size = 1, alpha = 0.5) +
ylim(c(0,1)) +
xlab("Model parsimony") +
ggtitle("Original population") +
theme_bw() +
theme(legend.position="bottom", legend.direction="horizontal") +
guides(colour="none")
}
# Select the best population models
fbm <- selectBestPopulation(pop)
printy_mc(fbm)
# Convert the best population models to a data frame
fbm.df <- populationToDataFrame_mc(fbm)
# Plotting for the selected best models
g.after <- list()  # Initialize a list to store the plots
for(j in 1:length(fbm.df)) {
fbm.dff  <- as.data.frame(fbm.df[[j]])  # Convert each submodel to a data frame
# Melt the dataframe for ggplot
fbm.df.melt <- melt(fbm.dff, id.vars = c("accuracy_", "eval.sparsity"))
# Create the ggplot for the best population models
g.after[[j]] <- ggplot(data = fbm.df.melt, aes(y = accuracy_, x = eval.sparsity)) +
geom_boxplot(notch = FALSE, position = position_dodge(width=0.9), alpha = 0.3) +
geom_point(aes(color = eval.sparsity), position=position_jitterdodge(dodge.width=0.9), size = 1, alpha = 0.5) +
ylim(c(0,1)) +
xlab("Model parsimony") +
ggtitle("FBM") +
theme_bw() +
theme(legend.position="bottom", legend.direction="horizontal") +
guides(colour="none")
}
# Arrange the plots side by side
grid.arrange(g.before[[2]], g.after[[2]], ncol = 2)
# Convert the model collection into a population of models scrambled by model size
pop <- modelCollectionToPopulation(Multi_Predomics_Aggregation_ova$classifier$models)
printy_mc(pop)
# Convert the population to a data frame
pop.df <- populationToDataFrame_mc(pop)
# Plotting for the original population
g.before <- list()  # Initialize a list to store the plots
for(i in 1: length(pop.df)) {
pop.dff  <- as.data.frame(pop.df[[i]])  # Convert each submodel to a data frame
# Display the head of the dataframe excluding some columns
head(pop.dff[,-c(3, 4, 7, 8, 14)])
# Melt the dataframe for ggplot
pop.df.melt <- melt(pop.dff, id.vars = c("accuracy_", "eval.sparsity"))
# Create the ggplot for the original population
g.before[[i]] <- ggplot(data = pop.df.melt, aes(y = accuracy_, x = eval.sparsity)) +
geom_boxplot(notch = FALSE, outlier.shape = NA, position = position_dodge(width=0.9), alpha = 0.3) +
geom_point(aes(color = eval.sparsity), position=position_jitterdodge(dodge.width=0.9), size = 1, alpha = 0.5) +
ylim(c(0,1)) +
xlab("Model parsimony") +
ggtitle("Original population") +
theme_bw() +
theme(legend.position="bottom", legend.direction="horizontal") +
guides(colour="none")
}
# Select the best population models
fbm <- selectBestPopulation(pop)
printy_mc(fbm)
# Convert the best population models to a data frame
fbm.df <- populationToDataFrame_mc(fbm)
# Plotting for the selected best models
g.after <- list()  # Initialize a list to store the plots
for(j in 1:length(fbm.df)) {
fbm.dff  <- as.data.frame(fbm.df[[j]])  # Convert each submodel to a data frame
# Melt the dataframe for ggplot
fbm.df.melt <- melt(fbm.dff, id.vars = c("accuracy_", "eval.sparsity"))
# Create the ggplot for the best population models
g.after[[j]] <- ggplot(data = fbm.df.melt, aes(y = accuracy_, x = eval.sparsity)) +
geom_boxplot(notch = FALSE, position = position_dodge(width=0.9), alpha = 0.3) +
geom_point(aes(color = eval.sparsity), position=position_jitterdodge(dodge.width=0.9), size = 1, alpha = 0.5) +
ylim(c(0,1)) +
xlab("Model parsimony") +
ggtitle("FBM") +
theme_bw() +
theme(legend.position="bottom", legend.direction="horizontal") +
guides(colour="none")
}
# Arrange the plots side by side
grid.arrange(g.before[[1]], g.after[[1]], ncol = 2)
fa <- makeFeatureAnnot_mc(pop = fbm,
X = X,
y = y,
clf = clf,
approch = "ova")
dim(fa[[1]]$pop.noz)
for (i in 1:length(fa)) {
g <- plotFeatureModelCoeffs(feat.model.coeffs = fa[[i]]$pop.noz)
print(g)
}
(g2 <- plotAbundanceByClass_mc(features = fa, X = X, y = y, approch = "ovo"))
fa <- makeFeatureAnnot_mc(pop = fbm,
X = X,
y = y,
clf = clf,
approch = "ova")
dim(fa[[1]]$pop.noz)
for (i in 1:length(fa)) {
g <- plotFeatureModelCoeffs(feat.model.coeffs = fa[[i]]$pop.noz)
print(g)
}
(g2 <- plotAbundanceByClass_mc(features = fa, X = X, y = y, approch = "ova"))
(g3 <- plotPrevalence_mc(features = fa, X = X, y = y , approch = "ova"))
knitr::opts_chunk$set(echo = TRUE)
library(mcpredomics)
library(predomics)
library(ggplot2)
library(gridExtra)
library(pROC)
library(reshape2)
library(randomForest)
library(caret)
library(gtools)
library(ggpubr)
library(dplyr)
library(tidyr)
library(tibble)
library(knitr)
library(kableExtra)
library(DT)
library(e1071)
library(glmnet)
chemin_du_dataset <- system.file("data", "mc.input.Rda", package = "mcpredomics")
load(chemin_du_dataset)
set.seed(123)
yvec <- mc.input$y$Enterotype[match(colnames(mc.input$X), rownames(mc.input$y))]
indices_tries <- order(yvec)
yvec_trie <- yvec[indices_tries]
X_general  <- mc.input$X[,indices_tries]
# Create an index vector for data partitioning
X_general <- X_general[rowSums(X_general)!=0,]; dim(X_general) # filter out variables with only zero values
X_general <- filterNoSignal(X = X_general, side = 1, threshold = "auto", verbose = FALSE); dim(X_general)
set.seed(42)
y = as.vector(yvec_trie)
X = X_general
# Number of desired samples in each class
nombre_echantillons_par_classe <- min(table(y))
# Function to balance the classes
equilibrer_classes <- function(y, X, nombre_echantillons_par_classe,seed =123) {
classes <- unique(y)
indices_equilibres <- integer(0)
for (classe in classes) {
indices_classe <- which(y == classe)
set.seed(seed)
indices_equilibres <- c(indices_equilibres, sample(indices_classe, nombre_echantillons_par_classe))
}
return(list(y = y[indices_equilibres], X = X[, indices_equilibres]))
}
donnees_equilibrees <- equilibrer_classes(y, X, nombre_echantillons_par_classe)
y_equilibre <- donnees_equilibrees$y
X_equilibre <- donnees_equilibrees$X
# Verify the distribution after balancing
set.seed(42)
indices_division <- createDataPartition(y_equilibre, p = 0.8, list = FALSE)
# Split yvec_trie into 80% train and 20% test
y <- as.vector(y_equilibre[indices_division])
y.test <- as.vector(y_equilibre[-indices_division])
X <- X_equilibre[,indices_division]
X.test <- X_equilibre[,-indices_division]
table(y)
table(y.test)
dim(X)
dim(X.test)
clf <- terBeam_mc(sparsity = c(2,3,4),
max.nb.features = 1000,
seed = 1,
nCores = 1,
evalToFit = "accuracy_",
objective = "auc",
experiment.id = "terBeam_mc",
experiment.save = "nothing")
printy(clf)
length(y)
length(y.test)
class(y)
load("Unique_Predomics_aggregation_ova.rda")
#load("Unique_Predomics_aggregation_ovo.rda")
#load("Unique_votingAggregation.rda")
#load("Unique_maximizationAggregation.rda")
#load("Unique_rankingAggregation.rda")
#load("Unique_weightedAggregation.rda")
#load("Multi_Predomics_aggregation_ova.rda")
#load("Multi_maximizationAggregation.rda")
#load("Multi_rankingAggregation.rda")
#load("Multi_weightedAggregation.rda")
#load("Multi_votingAggregation.rda")
#load("Multi_Predomics_aggregation_ovo.rda")
#load("res_clf.rda")
res_clf.dig <- digestmc(obj =Unique_Predomics_aggregation_ova, penalty = 0.75/100, plot = TRUE)
res_clf.dig$best$model$names_
res_clf.dig$best$model$indices_
res_clf.dig$best$model$sign_
printy_mc(res_clf.dig$best$model)
