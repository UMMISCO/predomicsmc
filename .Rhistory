# transform to a population of model objects
pop_last.mod <- listOfSparseVecToListOfModels_mc(X, y , clf = clf, v = pop_last,approch = approch)
# evaluate the population
pop.last.eval <- evaluatePopulation_mc(X , y, clf, pop_last.mod, force.re.evaluation = TRUE, eval.all = TRUE, approch=approch, aggregation_ = aggregation_)
# get the evaluation vector
evaluation    <- as.numeric(populationGet_X(element2get = "fit_", toVec = TRUE, na.rm = TRUE)(pop = pop.last.eval))
# get the evaluation
evaluation.ord <- order(abs(evaluation), decreasing = TRUE)
# order by best in front
evaluation <- evaluation[evaluation.ord]
pop_ordered_mod <- pop.last.eval[evaluation.ord] # we gain speed
# get the best individuals (should be the first)
best_individual_index <- which.max(abs(evaluation))
best_individual <- pop_ordered_mod[[best_individual_index]]
# print it out
if(clf$params$verbose)
{
if(isModel(best_individual))
{
try(cat(paste("gen =",i,"\t", printModel_mc(mod = best_individual, method = clf$params$print_ind_method, score = "fit_"),"\n")), silent = TRUE)
}
}
# transform the indexes into models
if(!isPopulation(obj = pop_ordered_mod))
{
pop_ordered_mod <- evaluatePopulation_mc(X, y, clf, pop_ordered_mod, force.re.evaluation = TRUE, approch = approch, aggregation_ = aggregation_,eval.all = TRUE)
}
# keep only models that are unique
pop_ordered_mod <- unique(pop_ordered_mod)
if(!(clf$params$popSaveFile=="NULL"))
{
#pop2Save      <- evaluatePopulation(X, y, clf, pop_ordered_mod, eval.all = TRUE)
pop2Save      <- pop_ordered_mod
savePopulation(pop2Save, paste("generation", i, clf$params$popSaveFile, sep = "_"))
}
# save the whole list of models ordered by fitting score. The best is the first
res[[paste("k",i,sep = "_")]] <- pop_ordered_mod
}
return(res)
}
#' Creates new combinations of features based from a parents.
#' @title evolve_mc
#' @description This function is used in terga1 and is the main engine of the algorithm that allows to cross, mutate and select individuals from one generation to the next (one versus one).
#' @param X: the data matrix with variables in the rows and observations in the columns
#' @param y: the response vector
#' @param clf: the classifier parameter object
#' @param pop: A population (i.e. list) of index vectors
#' @param seed: For reproductibility purpose to fix the random generator number.
#' @return a list population of models, containing parents and children(one versus one)
#' @export
evolve_mc <- function(X, y, clf, pop, seed = NULL, approch="ovo")
{
nClasse <- unique(y)
list_evolved_pop <- list() # List of different combinations of evolved
list_y <- list() # List of different combinations of y
list_X <- list() # List of different combinations of X
listcoeffs <- list() # List of different combinations of coeffs
listX <- list()
listXmin <- list() # List min of X
listXmax <- list() # List max of X
listy <- list()
listcoeffs <- clf$coeffs_
listX <- clf$data$X
listXmin <- clf$data$X.min
listXmax <- clf$data$X.max
listy <- clf$data$y
list_y <- list() #  List of different combinations of y
list_X <- list() #  List of different combinations of X
combi <- generate_combinations_with_factors(y, X, approch = approch)
list_y <- combi$list_y
list_X <- combi$list_X
for (i in 1:length(list_X)) {
clf$coeffs_ <- listcoeffs[[i]]
clf$data$X <- listX[[i]]
clf$data$X.min <- listXmin[[i]]
clf$data$X.max <- listXmax[[i]]
clf$data$y <- listy[[i]]
list_evolved_pop[[i]] <- evolve(X = list_X[[i]], y = list_y[[i]], clf, pop, seed = NULL)
}
evolved_pop <- list_evolved_pop
return(evolved_pop)
}
knitr::opts_chunk$set(echo = TRUE)
# Package multi class predomics
library(mcpredomics)
# Package predomics
library(predomics)
# Visualization library for creating complex plots
library(ggplot2)
# Arranges multiple ggplot objects on a single page
library(gridExtra)
# ROC curve analysis and AUC calculation
library(pROC)
# Reshaping and melting data frames
library(reshape2)
# Implementation of the Random Forest algorithm for classification and regression
library(randomForest)
# Comprehensive library for classification and regression training
library(caret)
# Various R programming tools and functions, including data manipulation
library(gtools)
# Adding statistical comparisons and publication-ready visualizations
library(ggpubr)
# Data manipulation and transformation (part of the tidyverse)
library(dplyr)
# Tidying messy data by gathering and spreading
library(tidyr)
# Enhanced data frames with row names as a column (tibble format)
library(tibble)
# Dynamic report generation and displaying results in tables
library(knitr)
# Creating aesthetically pleasing and customizable HTML tables
library(kableExtra)
# Interactive tables for data visualization and exploration
library(DT)
# Functions for statistical learning, including SVM and Naive Bayes
library(e1071)
# Lasso and ridge regression via generalized linear models
library(glmnet)
# Reading data from files (including CSV and text files)
library(readr)
# String manipulation and regular expression functions
library(stringr)
clf <- terBeam_mc(sparsity = c(3,4,5,6,7,8,9,10),
max.nb.features = 1000,
seed = 1,
nCores = 1,
evalToFit = "accuracy_",
objective = "auc",
experiment.id = "terBeam_mc",
experiment.save = "nothing")
printy(clf)
# Load the file
load("../data/predomics.inputs.ExperimentHubMulticlass.Rda")
lapply(predomics.inputs, function(x){summary(colSums(x[["X"]]))})
data1 <- predomics.inputs$KarlssonFH_2013
df <- data1$y.df
y <- df$study_condition
X <- data1$X
table(y)
dim(X)
clf <- terBeam_mc(sparsity = c(3,4,5,6,7,8,9,10),
max.nb.features = 1000,
seed = 1,
nCores = 1,
evalToFit = "accuracy_",
objective = "auc",
experiment.id = "terBeam_mc",
experiment.save = "nothing")
printy(clf)
load("~/Documents/multiclasse_predomics/mcpredomics/vignette/terbeam_OvaSearchMax_TD2_unconstrained_no_balance.rda")
terbeam_OvaSearchMax_TD2_unconstrained_no_balance$crossVal$scores$mean.acc
load("~/Documents/multiclasse_predomics/mcpredomics/vignette/terbeam_Majority_Voting_with_Tie_Breaking_TD2_unconstrained_no_balance.rda")
terbeam_Majority_Voting_with_Tie_Breaking_TD2_unconstrained_no_balance$crossVal$scores$mean.acc
load("~/Documents/multiclasse_predomics/mcpredomics/vignette/terbeam_Majority_Voting_TD2_unconstrained_no_balance.rda")
terbeam_Majority_Voting_TD2_unconstrained_no_balance$crossVal$scores$mean.acc
terbeam_Majority_Voting_TD2_unconstrained_no_balance$crossVal$mods_test$k_10$method
terbeam_Majority_Voting_TD2_unconstrained_no_balance$crossVal$mods_test$k_10$learner
runit = TRUE
if(runit)
{
terbeam_maximization_TD2_unconstrained_no_balance <- fit_mc(X = X, y = y, clf = clf,approch="ova", cross.validate = TRUE,aggregation_ = "maximization", nfolds= 5, constrained = FALSE);
save(terbeam_maximizationTD2_unconstrained_no_balance, clf, file ="terbeam_maximization_TD2_unconstrained_no_balance.rda", compression_level = 9)
}
clf <- terBeam_mc(sparsity = c(3,4,5,6,7,8,9,10),
max.nb.features = 1000,
seed = 1,
nCores = 1,
evalToFit = "accuracy_",
objective = "auc",
experiment.id = "terBeam_mc",
experiment.save = "nothing")
printy(clf)
runit = TRUE
if(runit)
{
terbeam_maximization_TD2_unconstrained_no_balance <- fit_mc(X = X, y = y, clf = clf,approch="ova", cross.validate = TRUE,aggregation_ = "maximization", nfolds= 5, constrained = FALSE);
save(terbeam_maximizationTD2_unconstrained_no_balance, clf, file ="terbeam_maximization_TD2_unconstrained_no_balance.rda", compression_level = 9)
}
runit = TRUE
if(runit)
{
terbeam_maximization_TD2_unconstrained_no_balance <- fit_mc(X = X, y = y, clf = clf,approch="ova", cross.validate = TRUE,aggregation_ = "maximization", nfolds= 5, constrained = FALSE);
save(terbeam_maximization_TD2_unconstrained_no_balance, clf, file ="terbeam_maximization_TD2_unconstrained_no_balance.rda", compression_level = 9)
}
terbeam_maximization_TD2_unconstrained_no_balance$crossVal$scores$mean.acc
load("~/Documents/multiclasse_predomics/mcpredomics/vignette/terbeam_Majority_Voting_TD2_unconstrained_no_balance.rda")
terbeam_Majority_Voting_TD2_unconstrained_no_balance$crossVal$scores$mean.acc
library(mcpredomics)
knitr::opts_chunk$set(echo = TRUE)
# Package multi class predomics
library(mcpredomics)
# Package predomics
library(predomics)
# Visualization library for creating complex plots
library(ggplot2)
# Arranges multiple ggplot objects on a single page
library(gridExtra)
# ROC curve analysis and AUC calculation
library(pROC)
# Reshaping and melting data frames
library(reshape2)
# Implementation of the Random Forest algorithm for classification and regression
library(randomForest)
# Comprehensive library for classification and regression training
library(caret)
# Various R programming tools and functions, including data manipulation
library(gtools)
# Adding statistical comparisons and publication-ready visualizations
library(ggpubr)
# Data manipulation and transformation (part of the tidyverse)
library(dplyr)
# Tidying messy data by gathering and spreading
library(tidyr)
# Enhanced data frames with row names as a column (tibble format)
library(tibble)
# Dynamic report generation and displaying results in tables
library(knitr)
# Creating aesthetically pleasing and customizable HTML tables
library(kableExtra)
# Interactive tables for data visualization and exploration
library(DT)
# Functions for statistical learning, including SVM and Naive Bayes
library(e1071)
# Lasso and ridge regression via generalized linear models
library(glmnet)
# Reading data from files (including CSV and text files)
library(readr)
# String manipulation and regular expression functions
library(stringr)
# Load the file
load("../data/predomics.inputs.ExperimentHubMulticlass.Rda")
lapply(predomics.inputs, function(x){summary(colSums(x[["X"]]))})
data1 <- predomics.inputs$KarlssonFH_2013
df <- data1$y.df
y <- df$study_condition
X <- data1$X
table(y)
dim(X)
clf <- terBeam_mc(sparsity = c(3,4,5,6,7,8,9,10),
max.nb.features = 1000,
seed = 1,
nCores = 1,
evalToFit = "accuracy_",
objective = "auc",
experiment.id = "terBeam_mc",
experiment.save = "nothing")
printy(clf)
runit = TRUE
if(runit)
{
terbeam_Majority_Voting_TD2_unconstrained_no_balance <- fit_mc(X = X, y = y, clf = clf,approch="ovo", cross.validate = TRUE,aggregation_ = "voting", nfolds= 5, constrained = FALSE);
save(terbeam_Majority_Voting_TD2_unconstrained_no_balance, clf, file ="terbeam_Majority_Voting_TD2_unconstrained_no_balance.rda", compression_level = 9)
}
terbeam_Majority_Voting_TD2_unconstrained_no_balance$crossVal$scores$mean.acc
clf <- terBeam_mc(sparsity = c(9,10),
max.nb.features = 1000,
seed = 1,
nCores = 1,
evalToFit = "accuracy_",
objective = "auc",
experiment.id = "terBeam_mc",
experiment.save = "nothing")
printy(clf)
load("~/Documents/multiclasse_predomics/mcpredomics/vignette/terga1_Majority_Voting_with_Tie_Breaking_CRC_unconstrained.rda")
load("~/Documents/multiclasse_predomics/mcpredomics/vignette/terbeam_Majority_Voting_with_Tie_Breaking_TD2_unconstrained_no_balance.rda")
terbeam_Majority_Voting_with_Tie_Breaking_TD2_unconstrained_no_balance$crossVal$scores$mean.acc
runit = TRUE
if(runit)
{
terbeam_Majority_Voting_with_Tie_Breaking_TD2_unconstrained_no_balance <- fit_mc(X = X, y = y, clf = clf,approch="ovo", cross.validate = TRUE,aggregation_ = "Predomics_aggregation_ovo", nfolds= 5, constrained = FALSE);
save(terbeam_Majority_Voting_with_Tie_Breaking_TD2_unconstrained_no_balance, clf, file ="terbeam_Majority_Voting_with_Tie_Breaking_TD2_unconstrained_no_balance.rda", compression_level = 9)
}
clf <- terBeam_mc(sparsity = c(9,10),
max.nb.features = 1000,
seed = 1,
nCores = 1,
evalToFit = "accuracy_",
objective = "auc",
experiment.id = "terBeam_mc",
experiment.save = "nothing")
printy(clf)
runit = TRUE
if(runit)
{
terbeam_Majority_Voting_with_Tie_Breaking_TD2_unconstrained_no_balance <- fit_mc(X = X, y = y, clf = clf,approch="ovo", cross.validate = TRUE,aggregation_ = "Predomics_aggregation_ovo", nfolds= 5, constrained = FALSE);
save(terbeam_Majority_Voting_with_Tie_Breaking_TD2_unconstrained_no_balance, clf, file ="terbeam_Majority_Voting_with_Tie_Breaking_TD2_unconstrained_no_balance.rda", compression_level = 9)
}
terbeam_Majority_Voting_with_Tie_Breaking_TD2_unconstrained_no_balance$crossVal$scores$mean.acc
load("~/Documents/multiclasse_predomics/mcpredomics/vignette/terbeam_Majority_Voting_metacardis_unconstrained_balance.rda")
knitr::opts_chunk$set(echo = TRUE)
# Package multi class predomics
library(mcpredomics)
# Package predomics
library(predomics)
# Visualization library for creating complex plots
library(ggplot2)
# Arranges multiple ggplot objects on a single page
library(gridExtra)
# ROC curve analysis and AUC calculation
library(pROC)
# Reshaping and melting data frames
library(reshape2)
# Implementation of the Random Forest algorithm for classification and regression
library(randomForest)
# Comprehensive library for classification and regression training
library(caret)
# Various R programming tools and functions, including data manipulation
library(gtools)
# Adding statistical comparisons and publication-ready visualizations
library(ggpubr)
# Data manipulation and transformation (part of the tidyverse)
library(dplyr)
# Tidying messy data by gathering and spreading
library(tidyr)
# Enhanced data frames with row names as a column (tibble format)
library(tibble)
# Dynamic report generation and displaying results in tables
library(knitr)
# Creating aesthetically pleasing and customizable HTML tables
library(kableExtra)
# Interactive tables for data visualization and exploration
library(DT)
# Functions for statistical learning, including SVM and Naive Bayes
library(e1071)
# Lasso and ridge regression via generalized linear models
library(glmnet)
# Reading data from files (including CSV and text files)
library(readr)
# String manipulation and regular expression functions
library(stringr)
chemin_du_dataset <- system.file("data", "mc.input.Rda", package = "mcpredomics")
load(chemin_du_dataset)
set.seed(123)
yvec <- mc.input$y$Enterotype[match(colnames(mc.input$X), rownames(mc.input$y))]
# Filter null values
X_general <- mc.input$X[, colSums(mc.input$X) != 0]
X_general <- filterNoSignal(X = X_general, side = 1, threshold = "auto", verbose = FALSE)
set.seed(42)
y = as.vector(yvec)
X = X_general
# Determine the number of samples per class
nombre_echantillons_par_classe <- min(table(y))
# Function to balance classes and maintain order
equilibrer_classes <- function(y, X, nombre_echantillons_par_classe, seed = 123) {
classes <- unique(y)
indices_equilibres <- integer(0)
for (classe in classes) {
indices_classe <- which(y == classe)
set.seed(seed)
indices_equilibres <- c(indices_equilibres, sample(indices_classe, nombre_echantillons_par_classe))
}
# Sort balanced indices to maintain original order
indices_equilibres <- sort(indices_equilibres)
return(list(y = y[indices_equilibres], X = X[, indices_equilibres]))
}
# Get balanced data
donnees_equilibrees <- equilibrer_classes(y, X, nombre_echantillons_par_classe)
y_equilibre <- donnees_equilibrees$y
X_equilibre <- donnees_equilibrees$X
# Check distribution after balancing
set.seed(42)
indices_division <- createDataPartition(y_equilibre, p = 0.8, list = FALSE)
# Split balanced data into 80% for training and 20% for testing
y <- as.vector(y_equilibre[indices_division])
y.test <- as.vector(y_equilibre[-indices_division])
X <- X_equilibre[, indices_division, drop = FALSE]
X.test <- X_equilibre[, -indices_division, drop = FALSE]
table(y)
dim(X)
clf <- terga1_mc(nCores = 1,
seed = 1,
plot = TRUE
)
printy(clf)
runit = TRUE
if(runit)
{
terga1_Majority_Voting_metacardis_unconstrained_balance <- fit_mc(X = X, y = y, clf = clf,approch="ovo", cross.validate = TRUE,aggregation_ = "voting", nfolds= 10, constrained = FALSE);
save(terga1_Majority_Voting_metacardis_unconstrained_balance, clf, file ="terga1_Majority_Voting_metacardis_unconstrained_balance.rda", compression_level = 9)
}
terga1_Majority_Voting_metacardis_unconstrained_balance$crossVal$scores$mean.acc
chemin_du_dataset <- system.file("data", "mc.input.Rda", package = "mcpredomics")
load(chemin_du_dataset)
set.seed(123)
yvec <- mc.input$y$Enterotype[match(colnames(mc.input$X), rownames(mc.input$y))]
# Filter null values
X_general <- mc.input$X[, colSums(mc.input$X) != 0]
X_general <- filterNoSignal(X = X_general, side = 1, threshold = "auto", verbose = FALSE)
set.seed(42)
y = as.vector(yvec)
X = X_general
# Check distribution after balancing
set.seed(42)
indices_division <- createDataPartition(y, p = 0.8, list = FALSE)
# Split balanced data into 80% for training and 20% for testing
y <- as.vector(y[indices_division])
y.test <- as.vector(y[-indices_division])
X <- X[, indices_division, drop = FALSE]
X.test <- X[, -indices_division, drop = FALSE]
table(y)
dim(X)
runit = TRUE
if(runit)
{
terga1_Majority_Voting_metacardis_unconstrained_no_balance <- fit_mc(X = X, y = y, clf = clf,approch="ovo", cross.validate = TRUE,aggregation_ = "voting", nfolds= 10, constrained = FALSE);
save(terga1_Majority_Voting_metacardis_unconstrained_no_balance, clf, file ="terga1_Majority_Voting_metacardis_unconstrained_no_balance.rda", compression_level = 9)
}
terga1_Majority_Voting_metacardis_unconstrained_no_balance$crossVal$scores$mean.acc
load("~/Documents/multiclasse_predomics/mcpredomics/vignette/terga1_Majority_Voting_with_Tie_Breaking_metacardis_unconstrained_balance.rda")
terga1_Majority_Voting_with_Tie_Breaking_metacardis_unconstrained_balance$crossVal$scores$mean.acc
load("~/Documents/multiclasse_predomics/mcpredomics/vignette/terga1_Majority_Voting_with_Tie_Breaking_metacardis_unconstrained_no_balance.rda")
terga1_Majority_Voting_with_Tie_Breaking_metacardis_unconstrained_no_balance$crossVal$scores$mean.acc
load("~/Documents/multiclasse_predomics/mcpredomics/vignette/terga1_Majority_Voting_with_Tie_Breaking_CRC_unconstrained.rda")
# Load the file
load("../data/predomics.inputs.ExperimentHubMulticlass.Rda")
lapply(predomics.inputs, function(x){summary(colSums(x[["X"]]))})
# Extract data
data1 <- predomics.inputs$FengQ_2015
df <- data1$y.df
y <- df$study_condition
X <- data1$X
table(y)
dim(X)
clf <- terga1_mc(nCores = 1,
seed = 1,
plot = TRUE
)
printy(clf)
runit = TRUE
if(runit)
{
terga1_Majority_Voting_CRC_unconstrained <- fit_mc(X = X, y = y, clf = clf,approch="ovo", cross.validate = TRUE,aggregation_ = "voting", nfolds= 10, constrained = FALSE);
save(terga1_Majority_Voting_CRC_unconstrained, clf, file ="terga1_Majority_Voting_CRC_unconstrained.rda", compression_level = 9)
}
terga1_Majority_Voting_CRC_unconstrained$crossVal$scores$mean.acc
load("~/Documents/multiclasse_predomics/mcpredomics/vignette/terga1_Majority_Voting_with_Tie_Breaking_CRC_unconstrained.rda")
terga1_Majority_Voting_with_Tie_Breaking_CRC_unconstrained$crossVal$scores$mean.acc
data1 <- predomics.inputs$KarlssonFH_2013
df <- data1$y.df
y <- df$study_condition
X <- data1$X
table(y)
dim(X)
clf <- terga1_mc(nCores = 1,
seed = 1,
plot = TRUE
)
printy(clf)
runit = TRUE
if(runit)
{
terga1_Majority_Voting_TD2_unconstrained <- fit_mc(X = X, y = y, clf = clf,approch="ovo", cross.validate = TRUE,aggregation_ = "voting", nfolds= 10, constrained = FALSE);
save(terga1_Majority_Voting_TD2_unconstrained, clf, file ="terga1_Majority_Voting_TD2_unconstrained.rda", compression_level = 9)
}
runit = TRUE
if(runit)
{
terga1_Majority_Voting_TD2_unconstrained <- fit_mc(X = X, y = y, clf = clf,approch="ovo", cross.validate = TRUE,aggregation_ = "voting", nfolds= 5, constrained = FALSE);
save(terga1_Majority_Voting_TD2_unconstrained, clf, file ="terga1_Majority_Voting_TD2_unconstrained.rda", compression_level = 9)
}
terga1_Majority_Voting_TD2_unconstrained$crossVal$scores$mean.acc
load("~/Documents/multiclasse_predomics/mcpredomics/vignette/terbeam_OvaSearchMax_TD2_unconstrained_no_balance.rda")
terbeam_OvaSearchMax_TD2_unconstrained_no_balance$crossVal$scores$mean.acc
load("~/Documents/multiclasse_predomics/mcpredomics/vignette/terbeam_Majority_Voting_TD2_unconstrained_no_balance.rda")
terbeam_Majority_Voting_TD2_unconstrained_no_balance$crossVal$scores$mean.acc
chemin_du_dataset <- system.file("data", "mc.input.Rda", package = "mcpredomics")
load(chemin_du_dataset)
set.seed(123)
yvec <- mc.input$y$Enterotype[match(colnames(mc.input$X), rownames(mc.input$y))]
# Filter null values
X_general <- mc.input$X[, colSums(mc.input$X) != 0]
X_general <- filterNoSignal(X = X_general, side = 1, threshold = "auto", verbose = FALSE)
set.seed(42)
y = as.vector(yvec)
X = X_general
# Determine the number of samples per class
nombre_echantillons_par_classe <- min(table(y))
# Function to balance classes and maintain order
equilibrer_classes <- function(y, X, nombre_echantillons_par_classe, seed = 123) {
classes <- unique(y)
indices_equilibres <- integer(0)
for (classe in classes) {
indices_classe <- which(y == classe)
set.seed(seed)
indices_equilibres <- c(indices_equilibres, sample(indices_classe, nombre_echantillons_par_classe))
}
# Sort balanced indices to maintain original order
indices_equilibres <- sort(indices_equilibres)
return(list(y = y[indices_equilibres], X = X[, indices_equilibres]))
}
# Get balanced data
donnees_equilibrees <- equilibrer_classes(y, X, nombre_echantillons_par_classe)
y_equilibre <- donnees_equilibrees$y
X_equilibre <- donnees_equilibrees$X
# Check distribution after balancing
set.seed(42)
indices_division <- createDataPartition(y_equilibre, p = 0.8, list = FALSE)
# Split balanced data into 80% for training and 20% for testing
y <- as.vector(y_equilibre[indices_division])
y.test <- as.vector(y_equilibre[-indices_division])
X <- X_equilibre[, indices_division, drop = FALSE]
X.test <- X_equilibre[, -indices_division, drop = FALSE]
table(y)
dim(X)
load("~/Documents/multiclasse_predomics/mcpredomics/vignette/terga1_OvaSearchMax_metacardis_unconstrained_balance.rda")
runit = TRUE
if(runit)
{
terga1_OvaSearchMax_metacardis_constrained_balance <- fit_mc(X = X, y = y, clf = clf,approch="ova", cross.validate = TRUE,aggregation_ = "Predomics_aggregation_ova", nfolds= 10, constrained = TRUE);
save(terga1_OvaSearchMax_metacardis_constrained_balance, clf, file ="terga1_OvaSearchMax_metacardis_constrained_balance.rda", compression_level = 9)
}
