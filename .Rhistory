yi = as.factor(yi)
selected.features <- rownames(clf$feature.cor[[o]])[order(clf$feature.cor[[o]]$p)][1:k]
x.reduced <- xi[,selected.features]
### Launch randomForest with the parameters from the clf
set.seed(clf$params$seed)
rf[[o]] <- randomForest(x = x.reduced, y=yi,
ntree=clf$params$ntree,
mtry=clf$params$mtry,
replace=clf$params$replace,
classwt=clf$params$classwt,
maxnodes = clf$params$maxnodes,
importance=clf$params$importance,
localImp=clf$params$localImp,
nPerm=nPerm,
norm.votes=clf$params$norm.votes,
do.trace=clf$params$do.trace,
keep.forest=clf$params$keep.forest,
corr.bias=clf$params$corr.bias,
keep.inbag=clf$params$keep.inbag
)
}
# build the model for this given sparsity
mod.res                  <- list() # to send the results
# Fill the object up with the rest of the values
mod.res$learner          <- clf$learner
mod.res$language         <- clf$params$language
mod.res$names_           <- selected.features
# match the index
mod.res$indices_         <- match(selected.features, rownames(X))
mod.res$eval.sparsity    <- length(unique(mod.res$names_))
# Add the rf object
mod.res$obj              <- rf
mod.res$auc_             <- NA
mod.res$cor_             <- NA
mod.res$aic_             <- NA
mod.res$score_           <- NA
mod.res$fit_             <- NA
mod.res$unpenalized_fit_ <- NA
mod.res$intercept_       <- NA
mod.res$sign_            <- NA
}
mod.res
mod.res$obj = mod.res$obj[[1]]
mod.res$obj
mod.res
mod = mod.res
eval.all = FALSE
force.re.evaluation = FALSE
estim.feat.importance = FALSE
mode = 'train'
if(mode != "train" & mode != "test")
{
stop("evaluateModel: mode should be one of c('train','test')")
}
#One-versus-one class distribution
nClasse <- unique(y)
list_mod <- list()
list_y <- list()
list_X <- list()
listcoeffs <- list()
k <- 1
for (i in 1:(length(nClasse)-1)) {
for (j in (i+1):length(nClasse)) {
class_i <- nClasse[i]
class_j <- nClasse[j]
indices <- which(y == class_i | y == class_j)
y_pair <- y[indices]
X_pair <- X[,indices]
list_y[[k]] <- y_pair
list_X[[k]] <- X_pair
k <- k + 1
}
}
mod.res <- list()
listcoeffs <- clf$coeffs_
listobjet <- list()
mod_res <- list()
mod_res <- mod
# DON'T EVALUATE RATIO, TER and TERINTER MODELS WITHOUT NEGATIVE AND POSITIVE TERMS
for(i in 1:length(list_mod)){
if(!isModelSota(list_mod[[i]]))
{
# at this stage the model should be a valid one. If not return NULL
if(!isModel(list_mod[[i]]))
{
if(clf$params$warnings) warning("evaluateModel: the model to be evaluated does not exist and at this stage it should be one, returning NULL.")
return(NULL)
}
}
}
for(i in 1:(length(list_X))){
list_mod[[i]] = mod
}
mod_res <- list()
mod_res <- mod
# DON'T EVALUATE RATIO, TER and TERINTER MODELS WITHOUT NEGATIVE AND POSITIVE TERMS
for(i in 1:length(list_mod)){
if(!isModelSota(list_mod[[i]]))
{
# at this stage the model should be a valid one. If not return NULL
if(!isModel(list_mod[[i]]))
{
if(clf$params$warnings) warning("evaluateModel: the model to be evaluated does not exist and at this stage it should be one, returning NULL.")
return(NULL)
}
}
}
# make a copy of the model object
mod.res <- list_mod
if(mode == "train")
{
for(i in 1:length(mod.res)){
# reset the attributes that need to be recomputed
# general attributes
mod.res[[i]]$fit_                <- NA
mod.res[[i]]$unpenalized_fit_    <- NA
# classification
mod.res[[i]]$auc_                <- NA
mod.res[[i]]$accuracy_           <- NA
mod.res[[i]]$precision_          <- NA
mod.res[[i]]$recall_             <- NA
mod.res[[i]]$f1_                 <- NA
mod.res[[i]]$intercept_          <- NA # the intercept
mod.res[[i]]$sign_               <- NA # the sign of the model
# regression
mod.res[[i]]$cor_                <- NA
mod.res[[i]]$rsq_                <- NA # r2
mod.res[[i]]$ser_                <- NA # standard error of the mean
mod.res[[i]]$aic_                <- NA
mod.res[[i]]$score_              <- NA # model score
mod.res[[i]]$pos_score_          <- NA # the positive model score
mod.res[[i]]$neg_score_          <- NA # the negative model score
}
}
# If this is a regression problem no need to find intercepts etc...
if(clf$params$objective == "cor")
{
for(i in 1:length(mod.res)) {
if(!isModelSota(mod.res[[i]])){
mod.res <- evaluateModelRegression_ovo(mod = mod.res, X = X, y = y, clf = clf, eval.all = eval.all, force.re.evaluation = force.re.evaluation)
return(mod.res)
}
else
{
if(clf$params$warnings) warning("evaluateModel: evaluating a sota model in correlation objective")
}
}
}
for(i in 1:length(mod.res)){
if(isModelSota(mod.res[[i]]))
{
# feature importance estimation will be switched off for the sotas, since the internal model structure is very different
if(estim.feat.importance)
{
estim.feat.importance = FALSE
}
}
}
for(i in 1:length(mod.res)){
# If sparsity is not the same
if(mod.res[[i]]$eval.sparsity != length(unique(mod.res[[i]]$indices_)))
{
if(clf$params$warnings) warning("evaluateModel: An individual has at least one indice replicated")
values2keep           <- which(mod.res[[i]]$indices_ == unique(mod.res[[i]]$indices_))
mod.res[[i]]$indices_      <- mod.res[[i]]$indices_[values2keep]
mod.res[[i]]$names_        <- mod.res[[i]]$names_[values2keep]
mod.res[[i]]$coeffs_       <- mod.res[[i]]$coeffs[values2keep]
mod.res[[i]]$eval.sparsity <- length(unique(mod.res[[i]]$indices_))
}
}
# first evaluate the fit
mod.res <- evaluateFit_ovo(mod = mod.res, X=X, y=y, clf=clf, force.re.evaluation = force.re.evaluation, mode = mode)
list_mod
scorelist <- getModelScore(mod = list_mod[[1]], X = list_X[[1]], clf = clf, force.re.evaluation = force.re.evaluation)
scorelist
scorelist <- getModelScore(mod = list_mod[[2]], X = list_X[[2]], clf = clf, force.re.evaluation = force.re.evaluation)
scorelist
scorelist <- getModelScore(mod = list_mod[[4]], X = list_X[[4]], clf = clf, force.re.evaluation = force.re.evaluation)
scorelist
clf$params$max.nb.features
jeancy = mod.res
jeancy
jeancy = jeancy[[1]]
jeancy
x <- as.matrix(t(X))
feature.cor <- list()
rf <- list()
nClasse <- unique(y)
list_y <- list()
list_X <- list()
k <- 1
clf$feature.cor <- NA
list_selected_ <- list()
rows_list <- list()
listing_ <- list()
for (i in 1:(length(nClasse)-1)) {
for (j in (i+1):length(nClasse)) {
class_i <- nClasse[i]
class_j <- nClasse[j]
indices <- which(y == class_i | y == class_j)
y_pair <- y[indices]
y_pair <- as.vector(y_pair)
X_pair <- X[,indices]
list_y[[k]] <- y_pair
list_X[[k]] <- X_pair
k <- k+1
}
}
for(j in 1:length(list_y)){
yy <- list_y[[j]]
xx <- list_X[[j]]
# compute the feature correlation for feature selection
feature.cor[[j]] <- filterfeaturesK(data = xx, trait = yy, k = nrow(X), sort = TRUE) # to avoid having to recompute this all the time
}
clf$feature.cor <- feature.cor
listing_ <- clf$feature.cor
# initialize some parameteres
if(is.null(clf$params$mtry))
{
clf$params$mtry = if(!is.null(y) && !is.factor(y))
max(floor(ncol(x)/3), 1) else floor(sqrt(ncol(x)))
}
if(is.null(clf$params$sampsize))
{
clf$params$sampsize = if(clf$params$replace) nrow(x) else ceiling(.632*nrow(x))
}
if(is.null(clf$params$nodesize))
{
clf$params$nodesize = if(!is.null(y) && !is.factor(y)) 5 else 1
}
if(is.null(clf$params$sparsity))
{
clf$params$sparsity <- nrow(X)
}
model_collection <- list()
for(i in 1:length(clf$params$sparsity))  # sparsity is = k, i.e. the number of features in a model
{
k <- clf$params$sparsity[i]
if(clf$params$verbose) cat("... ... Resolving problem with\t", k, "\tvariables ...\n")
for (o in 1:length(clf$feature.cor)){
xi <- list_X[[o]]
yi <- list_y[[o]]
xi <- as.matrix(t(xi))
y = as.factor(y)
selected.features <- rownames(clf$feature.cor[[o]])[order(clf$feature.cor[[o]]$p)][1:k]
x.reduced <- x[,selected.features]
### Launch randomForest with the parameters from the clf
set.seed(clf$params$seed)
rf[[o]] <- randomForest(x = x.reduced, y=y,
ntree=clf$params$ntree,
mtry=clf$params$mtry,
replace=clf$params$replace,
classwt=clf$params$classwt,
maxnodes = clf$params$maxnodes,
importance=clf$params$importance,
localImp=clf$params$localImp,
nPerm=nPerm,
norm.votes=clf$params$norm.votes,
do.trace=clf$params$do.trace,
keep.forest=clf$params$keep.forest,
corr.bias=clf$params$corr.bias,
keep.inbag=clf$params$keep.inbag
)
}
# build the model for this given sparsity
mod.res                  <- list() # to send the results
# Fill the object up with the rest of the values
mod.res$learner          <- clf$learner
mod.res$language         <- clf$params$language
mod.res$names_           <- selected.features
# match the index
mod.res$indices_         <- match(selected.features, rownames(X))
mod.res$eval.sparsity    <- length(unique(mod.res$names_))
# Add the rf object
mod.res$obj              <- rf
mod.res$auc_             <- NA
mod.res$cor_             <- NA
mod.res$aic_             <- NA
mod.res$score_           <- NA
mod.res$fit_             <- NA
mod.res$unpenalized_fit_ <- NA
mod.res$intercept_       <- NA
mod.res$sign_            <- NA
# evaluate all
}
mod.res
mod.res                  <- evaluateModel_ovo(mod = mod.res,
X = X,
y = y,
clf = clf,
eval.all = TRUE,
force.re.evaluation = TRUE,
estim.feat.importance = TRUE)
x <- as.matrix(t(X))
feature.cor <- list()
#rf <- list()
nClasse <- unique(y)
list_y <- list()
list_X <- list()
k <- 1
clf$feature.cor <- NA
list_selected_ <- list()
rows_list <- list()
listing_ <- list()
for (i in 1:(length(nClasse)-1)) {
for (j in (i+1):length(nClasse)) {
class_i <- nClasse[i]
class_j <- nClasse[j]
indices <- which(y == class_i | y == class_j)
y_pair <- y[indices]
y_pair <- as.vector(y_pair)
X_pair <- X[,indices]
list_y[[k]] <- y_pair
list_X[[k]] <- X_pair
k <- k+1
}
}
for(j in 1:length(list_y)){
yy <- list_y[[j]]
xx <- list_X[[j]]
# compute the feature correlation for feature selection
feature.cor[[j]] <- filterfeaturesK(data = xx, trait = yy, k = nrow(X), sort = TRUE) # to avoid having to recompute this all the time
}
clf$feature.cor <- feature.cor
listing_ <- clf$feature.cor
# initialize some parameteres
if(is.null(clf$params$mtry))
{
clf$params$mtry = if(!is.null(y) && !is.factor(y))
max(floor(ncol(x)/3), 1) else floor(sqrt(ncol(x)))
}
if(is.null(clf$params$sampsize))
{
clf$params$sampsize = if(clf$params$replace) nrow(x) else ceiling(.632*nrow(x))
}
if(is.null(clf$params$nodesize))
{
clf$params$nodesize = if(!is.null(y) && !is.factor(y)) 5 else 1
}
if(is.null(clf$params$sparsity))
{
clf$params$sparsity <- nrow(X)
}
model_collection <- list()
for(i in 1:length(clf$params$sparsity))  # sparsity is = k, i.e. the number of features in a model
{
k <- clf$params$sparsity[i]
if(clf$params$verbose) cat("... ... Resolving problem with\t", k, "\tvariables ...\n")
for (o in 1:length(clf$feature.cor)){
xi <- list_X[[o]]
yi <- list_y[[o]]
xi <- as.matrix(t(xi))
y = as.factor(y)
selected.features <- rownames(clf$feature.cor[[o]])[order(clf$feature.cor[[o]]$p)][1:k]
x.reduced <- x[,selected.features]
### Launch randomForest with the parameters from the clf
set.seed(clf$params$seed)
rf <- randomForest(x = x.reduced, y=y,
ntree=clf$params$ntree,
mtry=clf$params$mtry,
replace=clf$params$replace,
classwt=clf$params$classwt,
maxnodes = clf$params$maxnodes,
importance=clf$params$importance,
localImp=clf$params$localImp,
nPerm=nPerm,
norm.votes=clf$params$norm.votes,
do.trace=clf$params$do.trace,
keep.forest=clf$params$keep.forest,
corr.bias=clf$params$corr.bias,
keep.inbag=clf$params$keep.inbag
)
}
# build the model for this given sparsity
mod.res                  <- list() # to send the results
# Fill the object up with the rest of the values
mod.res$learner          <- clf$learner
mod.res$language         <- clf$params$language
mod.res$names_           <- selected.features
# match the index
mod.res$indices_         <- match(selected.features, rownames(X))
mod.res$eval.sparsity    <- length(unique(mod.res$names_))
# Add the rf object
mod.res$obj              <- rf
mod.res$auc_             <- NA
mod.res$cor_             <- NA
mod.res$aic_             <- NA
mod.res$score_           <- NA
mod.res$fit_             <- NA
mod.res$unpenalized_fit_ <- NA
mod.res$intercept_       <- NA
mod.res$sign_            <- NA
# evaluate all
mod.res                  <- evaluateModel_ovo(mod = mod.res,
X = X,
y = y,
clf = clf,
eval.all = TRUE,
force.re.evaluation = TRUE,
estim.feat.importance = TRUE)
if(clf$params$verbose)
}
mod.res
x <- as.matrix(t(X))
feature.cor <- list()
#rf <- list()
nClasse <- unique(y)
list_y <- list()
list_X <- list()
k <- 1
clf$feature.cor <- NA
list_selected_ <- list()
rows_list <- list()
listing_ <- list()
for (i in 1:(length(nClasse)-1)) {
for (j in (i+1):length(nClasse)) {
class_i <- nClasse[i]
class_j <- nClasse[j]
indices <- which(y == class_i | y == class_j)
y_pair <- y[indices]
y_pair <- as.vector(y_pair)
X_pair <- X[,indices]
list_y[[k]] <- y_pair
list_X[[k]] <- X_pair
k <- k+1
}
}
for(j in 1:length(list_y)){
yy <- list_y[[j]]
xx <- list_X[[j]]
# compute the feature correlation for feature selection
feature.cor[[j]] <- filterfeaturesK(data = xx, trait = yy, k = nrow(X), sort = TRUE) # to avoid having to recompute this all the time
}
clf$feature.cor <- feature.cor
listing_ <- clf$feature.cor
# initialize some parameteres
if(is.null(clf$params$mtry))
{
clf$params$mtry = if(!is.null(y) && !is.factor(y))
max(floor(ncol(x)/3), 1) else floor(sqrt(ncol(x)))
}
if(is.null(clf$params$sampsize))
{
clf$params$sampsize = if(clf$params$replace) nrow(x) else ceiling(.632*nrow(x))
}
if(is.null(clf$params$nodesize))
{
clf$params$nodesize = if(!is.null(y) && !is.factor(y)) 5 else 1
}
if(is.null(clf$params$sparsity))
{
clf$params$sparsity <- nrow(X)
}
model_collection <- list()
for(i in 1:length(clf$params$sparsity))  # sparsity is = k, i.e. the number of features in a model
{
k <- clf$params$sparsity[i]
if(clf$params$verbose) cat("... ... Resolving problem with\t", k, "\tvariables ...\n")
for (o in 1:length(clf$feature.cor)){
xi <- list_X[[o]]
yi <- list_y[[o]]
xi <- as.matrix(t(xi))
y = as.factor(y)
selected.features <- rownames(clf$feature.cor[[o]])[order(clf$feature.cor[[o]]$p)][1:k]
x.reduced <- x[,selected.features]
### Launch randomForest with the parameters from the clf
set.seed(clf$params$seed)
rf <- randomForest(x = x.reduced, y=y,
ntree=clf$params$ntree,
mtry=clf$params$mtry,
replace=clf$params$replace,
classwt=clf$params$classwt,
maxnodes = clf$params$maxnodes,
importance=clf$params$importance,
localImp=clf$params$localImp,
nPerm=nPerm,
norm.votes=clf$params$norm.votes,
do.trace=clf$params$do.trace,
keep.forest=clf$params$keep.forest,
corr.bias=clf$params$corr.bias,
keep.inbag=clf$params$keep.inbag
)
}
# build the model for this given sparsity
mod.res                  <- list() # to send the results
# Fill the object up with the rest of the values
mod.res$learner          <- clf$learner
mod.res$language         <- clf$params$language
mod.res$names_           <- selected.features
# match the index
mod.res$indices_         <- match(selected.features, rownames(X))
mod.res$eval.sparsity    <- length(unique(mod.res$names_))
# Add the rf object
mod.res$obj              <- rf
mod.res$auc_             <- NA
mod.res$cor_             <- NA
mod.res$aic_             <- NA
mod.res$score_           <- NA
mod.res$fit_             <- NA
mod.res$unpenalized_fit_ <- NA
mod.res$intercept_       <- NA
mod.res$sign_            <- NA
# evaluate all
mod.res                  <- evaluateModel_ovo(mod = mod.res,
X = X,
y = y,
clf = clf,
eval.all = TRUE,
force.re.evaluation = TRUE,
estim.feat.importance = TRUE)
}
load("~/Documents/multiclasse_predomics/mcpredomics/data/mc.input.Rda")
