{
if(any(is.na(match(rownames(feature.cor), rownames(X)))))
{
stop(paste("... feature.cor does not match X... needs to be recomputed. You can delete the following file",path.feature.cor))
}
}else
{
stop("feature.cor object does not exist. Please check the name.")
}
}else
{
cat("... Computing feature correlation for speedup\n")
if(clf$params$objective == "cor") # correlation
{
# if any NA in y omit them
if(any(is.na(y)))
{
ina <- is.na(y)
cat(paste("... y contains ",sum(ina), "NA values ... ommiting the observations in both y and X\n"))
# transforming to dataframe first will make sure to keep the dimnames such as for instance when it is sparse table or otu_table (phyloseq)
y.nona <- y[!ina]
X.nona <- X[,!ina]
}else
{
y.nona <- y
X.nona <- X
}
feature.cor     <- filterfeaturesK(data = t(apply(X.nona, 1, rank)), # for speedup
trait = rank(y.nona),             # for speedup
k = max.nb.features,
type = "pearson",                 # for speedup
sort = TRUE,
verbose = clf$params$verbose,
return.data = FALSE) # to avoid having to recompute this all the time
}else # classification
{
# Dataset decomposition phase using the one-versus-one and one-versus-all approaches
feature.cor   <- list() # List of different combinations of feature.cor
list_y <- list() #  List of different combinations of y
list_X <- list() #  List of different combinations of X
list_y <- list() #  List of different combinations of y
list_X <- list() #  List of different combinations of X
combi <- generate_combinations_with_factors(y, X, approch = approch)
list_y <- combi$list_y
list_X <- combi$list_X
for (i in 1:(length(list_y))) {
feature.cor[[i]]     <- filterfeaturesK(data = list_X[[i]],
trait = list_y[[i]],
k = max.nb.features,
type = "wilcoxon",
sort = TRUE,
verbose = clf$params$verbose,
return.data = FALSE) # to avoid having to recompute this all the time
}
}
if(!is.null(path))
{
save(feature.cor, file = path.feature.cor)
cat("... Correlation file saved\n")
}
}
cat("... Storing data in the classifier object for speedup\n")
clf$feature.cor <- feature.cor # add them to the clf
if(all(is.na(clf$feature.cor[[1]]$p)))
{
warning("runClassifier: does not seem to have produced a pvalue")
}
# store the initial order and indexes
clf$data          <- list()
list_features <- list()
clf$data$features <- list_features
names(clf$data$features) <- clf$data$features
list_XX <- list() # List of X combinations
list_min <- list() # List min of X
list_max <- list() # List max of X
for (i in 1:(length(list_X))) {
Xi <- list_X[[i]][rownames(clf$feature.cor[[i]])[1:max.nb.features],]
mino <- min(Xi, na.rm=TRUE)
maxo <- max(Xi, na.rm=TRUE)
list_XX[[i]] <- Xi
list_min[[i]] <-  mino
list_max[[i]] <-  maxo
}
clf$data$X        <- list_XX
clf$data$X.min    <- list_min
clf$data$X.max    <- list_max
clf$data$y        <- list_y
# compute the coefficients once for all to improve performance
cat("... Computing ternary coefficients for speedup\n")
coeffs          <- getSign_mc(X = X, y = y, clf = clf, approch = approch, parallel.local = FALSE)
clf$coeffs_     <- coeffs # add them to the clf
# check sparsity not to be larger than variables in X
if(any(is.na(clf$params$sparsity > nrow(X))))
{
# adding the maximum number of featuers
clf$params$sparsity <- c(clf$params$sparsity, nrow(X))
}
# mark NAs the bigger ones
clf$params$sparsity[clf$params$sparsity > nrow(X)] <- NA
# delete them
clf$params$sparsity <- clf$params$sparsity[!is.na(clf$params$sparsity)]
# set the seed while sanity checking
if(!(any(clf$params$seed=="NULL")))
{
# convert from list to a vector
if(is.list(clf$params$seed))
{
clf$params$seed <- unlist(clf$params$seed)
if(any(class(clf$params$seed)!="numeric"))
{
stop("fit: convertion of seed from list to numeric vector failed.")
}
}
# we can have multiple k-folds per experiment if the seed is vectors of seeds
if(length(clf$params$seed)==1)
{
set.seed(clf$params$seed)
cat("... One seed found, setting by default\n")
}else
{
if(length(clf$params$seed)==0)
{
stop("fit: the seed should have at least one value.")
}
# if we are here this means that it everything is as expected seed is a
# vector of numeric values.
set.seed(clf$params$seed[1])
cat("... Multiple seeds found, setting the default\n")
}
}
# check and set the number of folds
if(!is.null(lfolds))
{
cat("... Custom folds are provided\n")
if(!is.list(lfolds))
{
lfolds = NULL
}else #if lfolds exists
{
nfolds = length(lfolds)
}
}
if(nfolds == 1)
{
cat("... The number of folds is set to 1. In this case I'm deactivating the cross-validation process\n")
cross.validate = FALSE
}
# set the parallelize.folds parameter. If no crossval than it is deactivated
clf$params$parallelize.folds <- parallelize.folds & cross.validate & clf$params$parallel
# add a parallel.local parameter if we wish to speed out some local steps
clf$params$parallel.local <- FALSE
# START CLUSTER if parallel computing set the cluster
if(clf$params$parallel)
{
cat(paste("... Running the classifier", clf$learner,"in parallel mode with ",clf$params$nCores + 1,"CPUs\n"))
# adding another core for the whole dataset. If it is taken into account
# during the launch this will be a sleeping thread so no harm, if not it
# will allow to run faster as we won't forget to increment it
registerDoSNOW(clf$params$cluster <- makeCluster(clf$params$nCores + 1, type = "SOCK", outfile = log.file))
if(!clf$params$parallelize.folds)  # if folds are not parallelized
{
clf$params$parallel.local <- TRUE # switch the local parallel to TRUE
}
}else
{
cat(paste("... Running the classifier", clf$learner,"with a single CPU\n"))
}
# for all the predomics learners
if(!isLearnerSota(clf)) # if runing the BTR algorithms
{
# set the epsilon
if(!is.null(clf$params$epsilon))
{
if(clf$params$epsilon=="NULL")
{
#clf$params$epsilon        <- .Machine$double.xmin
clf$params$epsilon        <- 0
if(clf$params$verbose) cat("... Setting epsilon for predomics learners\n")
}
}
}
# save the data step by step to be able to resume
if(clf$experiment$save != "nothing")
{
if(clf$params$verbose) cat("... Saving experiments\n")
fileNames                 <- gsub(" ", "_", clf$experiment$id)
dir.create(fileNames)
setwd(fileNames)
saveResults(X, paste("X", fileNames, "yml", sep = "."))
saveResults(y, paste("Y", fileNames, "yml", sep = "."))
experiment <- list()
experiment$desc           <- clf$experiment$description
experiment$params         <- list(clf=list(learner = clf$learner, params = clf$params, experiment = clf$experiment))
if(clf$experiment$save == "full")
{
if((clf$params$popSaveFile=="NULL"))
{
clf$params$popSaveFile <- fileNames
}
}
}
switch(clf$learner,
terda=
{
# Here we handle also the sota.glmnet as well since this is a derivate of terda
cat('... terda fitting based on Linear programming relaxation ...\n')
},
terga1=
{
cat('... First version of terga fitting based on Genetic Algorithm heuristics ...\n')
},
terga1_mc=
{
cat('... First version of terga fitting based on Genetic Algorithm heuristics ...\n')
},
terga2=
{
cat('... Second and faster version of terga fitting based on Genetic Algorithm heuristics ...\n')
},
terBeam=
{
cat('... terbeam fitting based on Exhaustive Heuristic beam search ...\n')
},
terBeam_mc=
{
cat('... terbeam fitting based on Exhaustive Heuristic beam search ...\n')
},
metal=
{
cat('... model fitting based on aggregating different Heuristics ...\n')
},
sota.svm=
{
cat('... SOTA: state of the art SVM fitting ...\n')
},
sota.rf=
{
cat('... SOTA: state of the art Ranfom Forest fitting ...\n')
},
{
warning('This method does not exist !')
}
)
# open plot file
if(clf$params$plot)
{
pdf(file = paste0("graphics_from_",clf$experiment$description,".pdf"))
}
# lancer le classifier
if(!cross.validate)
{
cat("... No cross validation mode\n")
res.clf               <- list()
res.clf$classifier    <- runClassifier_mc(X, y, clf, approch = approch, aggregation_ = aggregation_, constrained = constrained)
} else
{
cat("... Cross validation mode\n")
res.clf               <- list()
res.clf$classifier    <- list()
res.clf$lfolds        <- lfolds
res.clf$crossVal      <- runCrossval_mc(X, y, clf, lfolds = lfolds, nfolds = nfolds, return.all = return.all, approch = approch, aggregation_ = aggregation_, constrained = constrained)
# store the whole dataset results in the right place
res.clf$classifier    <- res.clf$crossVal$whole
# unweight the crossVal object that played the role of the transporter
res.clf$crossVal      <- res.clf$crossVal[-match("whole", names(res.clf$crossVal))]
res.clf$lfolds        <- lfolds
# add FEATURE IMPORTANCE to the model objects based on the crossval feature importance
if(compute.importance & cross.validate)
{
if(!is.null(res.clf$crossVal$fip))
{
feature.importance.cv <- rowMeans(res.clf$crossVal$fip$mda, na.rm = TRUE)
feature.prevalence.cv <- res.clf$crossVal$fip$fpf / ncol(res.clf$crossVal$fip$mda) # normalize %
if(!is.null(res.clf$classifier$fip$mda))
{
feature.importance  <- res.clf$classifier$fip$mda
}else
{
feature.importance  <- rep(NA, length(clf$data$features))
names(feature.importance) <- names(clf$data$features)
}
if(isModelCollection(res.clf$classifier$models))
{
pop <- modelCollectionToPopulation(res.clf$classifier$models)
}else
{
pop <- NULL
}
if(!isPopulation(pop))
{
cat("... Bad news! The population of models seems to be empty. No models were found\n")
res.clf$classifier$models <- listOfModels2ModelCollection(pop)
cat("... Thank you for using Predomics\n")
return(res.clf)
}
# for each model add a vector with feature importance
mda.cv_ <- list() # Initializing the list of MDA results
ind.features <- list() # Initializing the list of feature indices
prev.cv_ <- list()
mda_ <- list()
for (i in 1:length(pop)) {
# Generalizing MDA
# Initializing mda.cv_ for each model in the population
pop[[i]]$mda.cv_ <- list()
# Looping over feature names for each model
for (j in 1:length(pop[[1]]$names_)) {
# Assigning feature names to mda.cv_
pop[[i]]$mda.cv_[[j]] <- rep(0, length(pop[[i]]$names_[[j]]))
names(pop[[i]]$mda.cv_[[j]]) <- pop[[i]]$names_[[j]]
# Intersection of feature names with the names of feature importance
ind.features[[j]] <- intersect(pop[[i]]$names_[[j]], names(feature.importance.cv))
}
# Assigning feature importance results to mda.cv_
for (j in 1:length(ind.features)) {
pop[[i]]$mda.cv_[[j]][ind.features[[j]]] <- feature.importance.cv[ind.features[[j]]]
}
# Initializing mda.cv_ for each model in the population
pop[[i]]$prev.cv_ <- list()
# Looping over feature names for each model
for (j in 1:length(pop[[1]]$names_)) {
# prevalence in top models in the folds
pop[[i]]$prev.cv_[[j]] <- rep(0, length(pop[[i]]$names_[[j]]))
names(pop[[i]]$prev.cv_[[j]]) <- pop[[i]]$names_[[j]]
ind.features[[j]] <-intersect(pop[[i]]$names_[[j]], names(feature.prevalence.cv))
}
for (j in 1:length(ind.features)) {
pop[[i]]$prev.cv_[[j]][ind.features[[j]]] <-feature.prevalence.cv[ind.features[[j]]]
}
# MDA empirical
pop[[i]]$mda_ <- list()
for (j in 1:length(pop[[1]]$names_)) {
pop[[i]]$mda_[[j]] <- rep(0, length(pop[[i]]$names_[[j]]))
names(pop[[i]]$mda_[[j]]) <- pop[[i]]$names_[[j]]
ind.features[[j]] <-intersect(pop[[i]]$names_[[j]], names(feature.importance))
}
for (j in 1:length(ind.features)) {
pop[[i]]$mda_[[j]][ind.features[[j]]] <-feature.importance[ind.features[[j]]]
}
}
# convert to model collection and put back
res.clf$classifier$models <- listOfModels2ModelCollection(pop)
}
}
if(clf$experiment$save != "nothing")
{
experiment$params$lfolds <- lfolds
}
} # end cross.validate test
cat("... Learning process is finished succesfuly\n")
# STOP CLUSTER
if(clf$params$parallel)
{
stopCluster(clf$params$cluster)
cat("... Stopping the parallel cluster\n")
}
# SAVE EXPERIMENT
if(clf$experiment$save != "nothing")
{
experiment$results    <- res.clf
saveResults(experiment, paste(fileNames, "yml", sep = "."))
setwd("..")
cat("... Saving exmeriment finished\n")
}
# closing graphics
if(clf$params$plot)
{
dev.off()
}
cat("... Thank you for using Predomics. Don't forget to digest the results now.\n")
class(res.clf) <- c("experiment","predomics")
res.clf$classifier$model$k_5[[1]]$Multi_confusionMatrix_
res.clf$classifier$model$k_5[[1]]$accuracy_
knitr::opts_chunk$set(echo = TRUE)
runit = TRUE
if(runit)
{
res_clf_predomics_ova <- fit_mc(X = X, y = y, clf = clf,approch="ova", cross.validate = TRUE,aggregation_ = "Predomics_aggregation_ova", nfolds= 1, constrained = FALSE);
#save(res_clf_predomics_ova , clf, file ="res_clf_predomics_ova.rda", compression_level = 9)
}
res_clf.dig <- digestmc(obj = res_clf_predomics_ova, penalty = 0.75/100, plot = TRUE)
y
table(y)
load("~/Documents/multiclasse_predomics/mcpredomics/vignette/ terbeam_predomics_aggregation_ova_constrained_no_balance.rda")
clf <- terBeam_mc(sparsity = c(5,8,9,10),
max.nb.features = 1000,
seed = 1,
nCores = 1,
evalToFit = "accuracy_",
objective = "auc",
experiment.id = "terBeam_mc",
experiment.save = "nothing")
printy(clf)
runit = TRUE
if(runit)
{
terbeam_predomics_aggregation_ova_constrained_no_balance <- fit_mc(X = X, y = y, clf = clf,approch="ova", cross.validate = TRUE,aggregation_ = "Predomics_aggregation_ova", nfolds= 10, constrained = TRUE);
save(terbeam_predomics_aggregation_ova_constrained_no_balance , clf, file ="terbeam_predomics_aggregation_ova_constrained_no_balance.rda", compression_level = 9)
}
terbeam_predomics_aggregation_ova_constrained_no_balance$crossVal$scores$mean.acc
clf <- terBeam_mc(sparsity = c(5,6,7,8,9,10),
max.nb.features = 1000,
seed = 1,
nCores = 1,
evalToFit = "accuracy_",
objective = "auc",
experiment.id = "terBeam_mc",
experiment.save = "nothing")
printy(clf)
runit = TRUE
if(runit)
{
terbeam_predomics_aggregation_ova_unconstrained_no_balance <- fit_mc(X = X, y = y, clf = clf,approch="ova", cross.validate = TRUE,aggregation_ = "Predomics_aggregation_ova", nfolds= 10, constrained = FALSE);
save(terbeam_predomics_aggregation_ova_unconstrained_no_balance , clf, file ="terbeam_predomics_aggregation_ova_unconstrained_no_balance.rda", compression_level = 9)
}
res_clf.dig <- digestmc(obj = terbeam_predomics_aggregation_ova_unconstrained_no_balance, penalty = 0.75/100, plot = TRUE)
terbeam_predomics_aggregation_ova_unconstrained_no_balance$classifier$data$y
terbeam_predomics_aggregation_ova_unconstrained_no_balance$crossVal$scores$mean.acc
clf <- regenerate_clf(clf, X, y, approch = "ova")
# get the best model
best.model = res_clf.dig$best$model
# Visualize the model information (if needed)
printy_mc(best.model)
# Generate the plots
plots1 <- plotModel_mc(best.model, X, y, sort.features = FALSE, feature.name = TRUE, approch = "ova")
plots2 <- plotModel_mc(best.model, X, y, sort.features = FALSE, feature.name = TRUE, importance = TRUE, approch = "ova")
# Open a PDF device to save the grid of plots
pdf("model_visualization_plots.pdf", width = 12, height = 8)  # Adjust width and height as needed
# Extract the plots from each list and pass them to `grid.arrange`
grid.arrange(grobs = c(plots1, plots2), ncol = 4)
# Close the PDF device
dev.off()
# Confirmation of the save process
cat("The plots have been saved under the name 'model_visualization_plots.pdf'.\n")
tmp <- plotAUC_mc(scores = best.model$score_, y = y, percent = TRUE, approch = "ova"); rm(tmp)
# Convert the model collection into a population of models scrambled by model size
pop <- modelCollectionToPopulation(terga1_weighted_unconstrained_no_balance$classifier$models)
# Convert the model collection into a population of models scrambled by model size
pop <- modelCollectionToPopulation(terbeam_predomics_aggregation_ova_unconstrained_no_balance$classifier$models)
printy_mc(pop)
# Function to create boxplot for a given data frame
create_boxplot <- function(data, title) {
# Melt the dataframe for ggplot
data.melt <- melt(data, id.vars = c("accuracy_", "eval.sparsity"))
# Create ggplot
plot <- ggplot(data = data.melt, aes(y = accuracy_, x = eval.sparsity)) +
geom_boxplot(notch = FALSE, outlier.shape = NA, position = position_dodge(width = 0.9), alpha = 0.3) +
geom_point(aes(color = eval.sparsity), position = position_jitterdodge(dodge.width = 0.9), size = 1, alpha = 0.5) +
ylim(c(0, 1)) +
xlab("Model Parsimony") +
ggtitle(title) +
theme_bw() +
theme(legend.position = "bottom", legend.direction = "horizontal") +
guides(colour = "none")
return(plot)
}
# Convert the population to a data frame
pop.df <- populationToDataFrame_mc(pop)
# Plotting for the original population (single figure)
pop.dff <- as.data.frame(pop.df[[1]])  # Convert the first submodel to a data frame
g.before <- create_boxplot(pop.dff, title = "Original Population")
#print(g.before)  # Display the plot
# Select the best population models
fbm <- selectBestPopulation(pop)
#printy_mc(fbm)
# Convert the best population models to a data frame
fbm.df <- populationToDataFrame_mc(fbm)
# Plotting for the selected best models (single figure)
fbm.dff <- as.data.frame(fbm.df[[1]])  # Convert the first submodel to a data frame
g.after <- create_boxplot(fbm.dff, title = "FBM")
print(g.after)  # Display the plot
fa <- makeFeatureAnnot_mc(pop = fbm,
X = X,
y = y,
clf = clf,
approch = "ovo")
fa <- makeFeatureAnnot_mc(pop = fbm,
X = X,
y = y,
clf = clf,
approch = "ova")
plot_distribution <- plotFeatureModelCoeffs_mc(feat.model.coeffs = fa, y, approch = "ova")
plots_abundance <- plotAbundanceByClass_mc(features = fa, X, y, approch = "ova")
plots_prevalence <- plotPrevalence_mc(features = fa, X = X, y = y, approch = "ova")
feat1.import <- mergeMeltImportanceCV_mc(list.results = list(terBeam = terbeam_predomics_aggregation_ova_unconstrained_no_balance),
filter.cv.prev = 0,
min.kfold.nb = FALSE,
learner.grep.pattern = "*",
#nb.top.features = 50,
feature.selection = fa,
scaled.importance = TRUE,
make.plot = TRUE,
cv.prevalence = FALSE)
feat2.import <- mergeMeltImportanceCV_mc(list.results = list(terBeam = terbeam_predomics_aggregation_ova_unconstrained_no_balance),
filter.cv.prev = 0,
min.kfold.nb = FALSE,
learner.grep.pattern = "*",
nb.top.features = 148,
#feature.selection = rownames(fa$pop.noz),
scaled.importance = TRUE,
make.plot = TRUE,
cv.prevalence = FALSE)
load("~/Documents/multiclasse_predomics/mcpredomics/vignette/terbeam_predomics_aggregation_ovo_unconstrained_no_balance.rda")
terbeam_predomics_aggregation_ovo_unconstrained_no_balance$classifier$data$y
terbeam_predomics_aggregation_ovo_unconstrained_no_balance$crossVal$scores$mean.acc
load("~/Documents/multiclasse_predomics/mcpredomics/vignette/terbeam_voting_unconstrained_no_balance.rda")
terbeam_voting_unconstrained_no_balance$crossVal$scores$mean.acc
load("~/Documents/multiclasse_predomics/mcpredomics/vignette/terbeam_weighted_unconstrained_no_balance.rda")
terbeam_weighted_unconstrained_no_balance$crossVal$scores$mean.acc
load("~/Documents/multiclasse_predomics/mcpredomics/vignette/terga1_voting_unconstrained_no_balance.rda")
terga1_voting_unconstrained_no_balance$classifier$data$y
load("~/Documents/multiclasse_predomics/mcpredomics/vignette/ terga1_Predomics_aggregation_ovo_constrained_no_balance.rda")
terga1_Predomics_aggregation_ovo_constrained_no_balance$classifier$data$y
