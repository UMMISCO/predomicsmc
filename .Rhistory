{
pop <- listOfModelsToListOfSparseVec(list.models = pop)
}
# then we evolve
pop_last      <- evolve_mc(X, y, clf, pop, seed = clf$params$current_seed,approch = approch)
# Initialiser la liste des indices
list_indices <- list()
# Convert 'constrained' to logical type if it's not already
constrained <- as.logical(constrained)
if (constrained == FALSE) {
# Loop through the indices of the first list in 'pop_last'
for (i in 1:length(pop_last[[1]])) {
# Initialize the list of indices for each iteration
list_indices[[i]] <- list()
# Loop through the different lists in 'pop_last'
for (j in 1:length(pop_last)) {
if (i <= length(pop_last[[j]])) {
# Add the corresponding element from 'pop_last' to 'list_indices'
list_indices[[i]][[j]] <- pop_last[[j]][[i]]
} else {
# Reuse the previous element if the index exceeds the length of the sublist
list_indices[[i]][[j]] <- list_indices[[i - 1]][[j]]
}
}
}
# Update 'pop_last' with the new list of indices
pop_last <- list_indices
} else if (constrained == TRUE) {
# Case where 'constrained' is TRUE
for (i in 1:length(pop_last[[1]])) {
# Initialize the list of indices for each iteration
list_indices[[i]] <- list()
# Loop through the different lists in 'pop_last'
for (j in 1:length(pop_last)) {
if (i <= length(pop_last[[j]])) {
# Add the corresponding element from 'pop_last' to 'list_indices'
list_indices[[i]][[j]] <- pop_last[[j]][[i]]
} else {
# Reuse the previous element if the index exceeds the length of the sublist
list_indices[[i]][[j]] <- list_indices[[i - 1]][[j]]
}
}
}
# Initialize the output list 'new_list'
new_list <- list()
# Fill 'new_list' with the first element of each sublist in 'list_indices'
for (jj in seq_along(list_indices)) {
# Get the first element of the sublist from 'list_indices'
first_element <- list_indices[[jj]][[1]]
# Create a sublist in 'new_list' with this first element repeated
new_list[[jj]] <- rep(list(first_element), length(list_indices[[jj]]))
}
# Update 'pop_last' with the new list
pop_last <- new_list
}
}
# evaluate the fitting function for all the models of the populaion
# transform to a population of model objects
pop_last.mod <- listOfSparseVecToListOfModels_mc(X, y , clf = clf, v = pop_last,approch = approch)
# evaluate the population
pop.last.eval <- evaluatePopulation_mc(X , y, clf, pop_last.mod, force.re.evaluation = TRUE, eval.all = TRUE, approch=approch, aggregation_ = aggregation_)
# get the evaluation vector
evaluation    <- as.numeric(populationGet_X(element2get = "fit_", toVec = TRUE, na.rm = TRUE)(pop = pop.last.eval))
# get the evaluation
evaluation.ord <- order(abs(evaluation), decreasing = TRUE)
# order by best in front
evaluation <- evaluation[evaluation.ord]
pop_ordered_mod <- pop.last.eval[evaluation.ord] # we gain speed
# get the best individuals (should be the first)
best_individual_index <- which.max(abs(evaluation))
best_individual <- pop_ordered_mod[[best_individual_index]]
# print it out
if(clf$params$verbose)
{
if(isModel(best_individual))
{
try(cat(paste("gen =",i,"\t", printModel_mc(mod = best_individual, method = clf$params$print_ind_method, score = "fit_"),"\n")), silent = TRUE)
}
}
# transform the indexes into models
if(!isPopulation(obj = pop_ordered_mod))
{
pop_ordered_mod <- evaluatePopulation_mc(X, y, clf, pop_ordered_mod, force.re.evaluation = TRUE, approch = approch, aggregation_ = aggregation_,eval.all = TRUE)
}
# keep only models that are unique
pop_ordered_mod <- unique(pop_ordered_mod)
if(!(clf$params$popSaveFile=="NULL"))
{
#pop2Save      <- evaluatePopulation(X, y, clf, pop_ordered_mod, eval.all = TRUE)
pop2Save      <- pop_ordered_mod
savePopulation(pop2Save, paste("generation", i, clf$params$popSaveFile, sep = "_"))
}
# save the whole list of models ordered by fitting score. The best is the first
res[[paste("k",i,sep = "_")]] <- pop_ordered_mod
}
return(res)
}
#' Creates new combinations of features based from a parents.
#' @title evolve_mc
#' @description This function is used in terga1 and is the main engine of the algorithm that allows to cross, mutate and select individuals from one generation to the next (one versus one).
#' @param X: the data matrix with variables in the rows and observations in the columns
#' @param y: the response vector
#' @param clf: the classifier parameter object
#' @param pop: A population (i.e. list) of index vectors
#' @param seed: For reproductibility purpose to fix the random generator number.
#' @return a list population of models, containing parents and children(one versus one)
#' @export
evolve_mc <- function(X, y, clf, pop, seed = NULL, approch="ovo")
{
nClasse <- unique(y)
list_evolved_pop <- list() # List of different combinations of evolved
list_y <- list() # List of different combinations of y
list_X <- list() # List of different combinations of X
listcoeffs <- list() # List of different combinations of coeffs
listX <- list()
listXmin <- list() # List min of X
listXmax <- list() # List max of X
listy <- list()
listcoeffs <- clf$coeffs_
listX <- clf$data$X
listXmin <- clf$data$X.min
listXmax <- clf$data$X.max
listy <- clf$data$y
list_y <- list() #  List of different combinations of y
list_X <- list() #  List of different combinations of X
combi <- generate_combinations_with_factors(y, X, approch = approch)
list_y <- combi$list_y
list_X <- combi$list_X
for (i in 1:length(list_X)) {
clf$coeffs_ <- listcoeffs[[i]]
clf$data$X <- listX[[i]]
clf$data$X.min <- listXmin[[i]]
clf$data$X.max <- listXmax[[i]]
clf$data$y <- listy[[i]]
list_evolved_pop[[i]] <- evolve(X = list_X[[i]], y = list_y[[i]], clf, pop, seed = NULL)
}
evolved_pop <- list_evolved_pop
return(evolved_pop)
}
knitr::opts_chunk$set(echo = TRUE)
# Package multi class predomics
library(mcpredomics)
# Package predomics
library(predomics)
# Visualization library for creating complex plots
library(ggplot2)
# Arranges multiple ggplot objects on a single page
library(gridExtra)
# ROC curve analysis and AUC calculation
library(pROC)
# Reshaping and melting data frames
library(reshape2)
# Implementation of the Random Forest algorithm for classification and regression
library(randomForest)
# Comprehensive library for classification and regression training
library(caret)
# Various R programming tools and functions, including data manipulation
library(gtools)
# Adding statistical comparisons and publication-ready visualizations
library(ggpubr)
# Data manipulation and transformation (part of the tidyverse)
library(dplyr)
# Tidying messy data by gathering and spreading
library(tidyr)
# Enhanced data frames with row names as a column (tibble format)
library(tibble)
# Dynamic report generation and displaying results in tables
library(knitr)
# Creating aesthetically pleasing and customizable HTML tables
library(kableExtra)
# Interactive tables for data visualization and exploration
library(DT)
# Functions for statistical learning, including SVM and Naive Bayes
library(e1071)
# Lasso and ridge regression via generalized linear models
library(glmnet)
# Reading data from files (including CSV and text files)
library(readr)
# String manipulation and regular expression functions
library(stringr)
load("~/Documents/multiclasse_predomics/mcpredomics/vignette/terbeam_Majority_Voting_with_Tie_Breaking_metacardis_unconstrained_balance.rda")
terbeam_Majority_Voting_with_Tie_Breaking_metacardis_unconstrained_balance$crossVal$scores$mean.acc
load("~/Documents/multiclasse_predomics/mcpredomics/vignette/terga1_Majority_Voting_with_Tie_Breaking_metacardis_unconstrained_balance.rda")
terga1_Majority_Voting_with_Tie_Breaking_metacardis_unconstrained_balance$crossVal$scores$mean.acc
chemin_du_dataset <- system.file("data", "mc.input.Rda", package = "mcpredomics")
load(chemin_du_dataset)
set.seed(123)
yvec <- mc.input$y$Enterotype[match(colnames(mc.input$X), rownames(mc.input$y))]
# Filter null values
X_general <- mc.input$X[, colSums(mc.input$X) != 0]
X_general <- filterNoSignal(X = X_general, side = 1, threshold = "auto", verbose = FALSE)
set.seed(42)
y = as.vector(yvec)
X = X_general
# Check distribution after balancing
set.seed(42)
indices_division <- createDataPartition(y, p = 0.8, list = FALSE)
# Split balanced data into 80% for training and 20% for testing
y <- as.vector(y[indices_division])
y.test <- as.vector(y[-indices_division])
X <- X[, indices_division, drop = FALSE]
X.test <- X[, -indices_division, drop = FALSE]
table(y)
dim(X)
clf <- terBeam_mc(sparsity = c(8),
max.nb.features = 1000,
seed = 1,
nCores = 1,
evalToFit = "accuracy_",
objective = "auc",
experiment.id = "terBeam_mc",
experiment.save = "nothing")
printy(clf)
runit = TRUE
if(runit)
{
terbeam_maximization_metacardis_unconstrained_no_balance <- fit_mc(X = X, y = y, clf = clf,approch="ova", cross.validate = TRUE,aggregation_ = "maximization", nfolds= 10, constrained = FALSE);
save(terbeam_maximization_metacardis_unconstrained_no_balance, clf, file ="terbeam_maximization_metacardis_unconstrained_no_balance.rda", compression_level = 9)
}
terbeam_maximization_metacardis_unconstrained_no_balance$crossVal$scores$mean.acc
load("~/Documents/multiclasse_predomics/mcpredomics/vignette/terbeam_OvaSearchMax_metacardis_unconstrained_balance.rda")
clf <- terBeam_mc(sparsity = c(5,6,7,8,9,10),
max.nb.features = 1000,
seed = 1,
nCores = 1,
evalToFit = "accuracy_",
objective = "auc",
experiment.id = "terBeam_mc",
experiment.save = "nothing")
printy(clf)
runit = TRUE
if(runit)
{
terbeam_OvaSearchMax_metacardis_unconstrained_no_balance <- fit_mc(X = X, y = y, clf = clf,approch="ova", cross.validate = TRUE,aggregation_ = "Predomics_aggregation_ova", nfolds= 10, constrained = FALSE);
save(terbeam_OvaSearchMax_metacardis_unconstrained_no_balance, clf, file ="terbeam_OvaSearchMax_metacardis_unconstrained_no_balance.rda", compression_level = 9)
}
terbeam_OvaSearchMax_metacardis_unconstrained_no_balance$crossVal$scores$mean.acc
# Load the file
load("../data/predomics.inputs.ExperimentHubMulticlass.Rda")
lapply(predomics.inputs, function(x){summary(colSums(x[["X"]]))})
# Extract data
data1 <- predomics.inputs$FengQ_2015
df <- data1$y.df
y <- df$study_condition
X <- data1$X
table(y)
dim(X)
clf <- terBeam_mc(sparsity = c(8,9,10),
max.nb.features = 1000,
seed = 1,
nCores = 1,
evalToFit = "accuracy_",
objective = "auc",
experiment.id = "terBeam_mc",
experiment.save = "nothing")
printy(clf)
table(y)
runit = TRUE
if(runit)
{
terbeam_OvaSearchMax_CRC_unconstrained_no_balance <- fit_mc(X = X, y = y, clf = clf,approch="ova", cross.validate = TRUE,aggregation_ = "Predomics_aggregation_ova", nfolds= 10, constrained = FALSE);
save(terbeam_OvaSearchMax_CRC_unconstrained_no_balance, clf, file ="terbeam_OvaSearchMax_CRC_unconstrained_no_balance.rda", compression_level = 9)
}
terbeam_OvaSearchMax_CRC_unconstrained_no_balance$crossVal$scores$mean.acc
load("~/Documents/multiclasse_predomics/mcpredomics/vignette/terga1_Majority_Voting_with_Tie_Breaking_CRC_unconstrained.rda")
terga1_Majority_Voting_with_Tie_Breaking_CRC_unconstrained$crossVal$scores$mean.acc
load("~/Documents/multiclasse_predomics/mcpredomics/vignette/terga1_OvaSearchMax_CRC_unconstrained_no_balance.rda")
terga1_OvaSearchMax_CRC_unconstrained_no_balance$crossVal$scores$mean.acc
clf <- terBeam_mc(sparsity = c(8,9,10),
max.nb.features = 1000,
seed = 1,
nCores = 1,
evalToFit = "accuracy_",
objective = "auc",
experiment.id = "terBeam_mc",
experiment.save = "nothing")
printy(clf)
runit = TRUE
if(runit)
{
terbeam_Majority_Voting_with_Tie_Breaking_CRC_unconstrained_no_balance <- fit_mc(X = X, y = y, clf = clf,approch="ovo", cross.validate = TRUE,aggregation_ = "Predomics_aggregation_ovo", nfolds= 10, constrained = FALSE);
save(terbeam_Majority_Voting_with_Tie_Breaking_CRC_unconstrained_no_balance, clf, file ="terbeam_Majority_Voting_with_Tie_Breaking_CRC_unconstrained_no_balance.rda", compression_level = 9)
}
terbeam_Majority_Voting_with_Tie_Breaking_CRC_unconstrained_no_balance$crossVal$scores$mean.acc
load("~/Documents/multiclasse_predomics/mcpredomics/vignette/terga1_Majority_Voting_with_Tie_Breaking_CRC_unconstrained.rda")
terga1_Majority_Voting_with_Tie_Breaking_CRC_unconstrained$crossVal$scores$mean.acc
clf <- terBeam_mc(sparsity = c(5,7,8),
max.nb.features = 1000,
seed = 1,
nCores = 1,
evalToFit = "accuracy_",
objective = "auc",
experiment.id = "terBeam_mc",
experiment.save = "nothing")
printy(clf)
runit = TRUE
if(runit)
{
terbeam_Majority_Voting_CRC_unconstrained_no_balance <- fit_mc(X = X, y = y, clf = clf,approch="ovo", cross.validate = TRUE,aggregation_ = "voting", nfolds= 10, constrained = FALSE);
save(terbeam_Majority_Voting_CRC_unconstrained_no_balance, clf, file ="terbeam_Majority_Voting_CRC_unconstrained_no_balance.rda", compression_level = 9)
}
terbeam_Majority_Voting_CRC_unconstrained_no_balance$crossVal$scores$mean.acc
load("~/Documents/multiclasse_predomics/mcpredomics/vignette/terga1_Majority_Voting_with_Tie_Breaking_CRC_unconstrained.rda")
terga1_Majority_Voting_with_Tie_Breaking_CRC_unconstrained$crossVal$scores$mean.acc
load("~/Documents/multiclasse_predomics/mcpredomics/vignette/terbeam_Majority_Voting_with_Tie_Breaking_CRC_unconstrained_no_balance.rda")
terbeam_Majority_Voting_with_Tie_Breaking_CRC_unconstrained_no_balance$crossVal$scores$mean.acc
terbeam_Majority_Voting_CRC_unconstrained_no_balance$crossVal$mods_test$k_8$Multi_confusionMatrix_
terbeam_Majority_Voting_CRC_unconstrained_no_balance$crossVal$mods_train$k_8$Multi_confusionMatrix_
terbeam_Majority_Voting_CRC_unconstrained_no_balance$crossVal$scores$mean.acc
load("~/Documents/multiclasse_predomics/mcpredomics/vignette/terbeam_Majority_Voting_with_Tie_Breaking_metacardis_unconstrained_balance.rda")
terbeam_Majority_Voting_with_Tie_Breaking_metacardis_unconstrained_balance$crossVal$scores$mean.acc
chemin_du_dataset <- system.file("data", "mc.input.Rda", package = "mcpredomics")
load(chemin_du_dataset)
set.seed(123)
yvec <- mc.input$y$Enterotype[match(colnames(mc.input$X), rownames(mc.input$y))]
# Filter null values
X_general <- mc.input$X[, colSums(mc.input$X) != 0]
X_general <- filterNoSignal(X = X_general, side = 1, threshold = "auto", verbose = FALSE)
set.seed(42)
y = as.vector(yvec)
X = X_general
# Determine the number of samples per class
nombre_echantillons_par_classe <- min(table(y))
# Function to balance classes and maintain order
equilibrer_classes <- function(y, X, nombre_echantillons_par_classe, seed = 123) {
classes <- unique(y)
indices_equilibres <- integer(0)
for (classe in classes) {
indices_classe <- which(y == classe)
set.seed(seed)
indices_equilibres <- c(indices_equilibres, sample(indices_classe, nombre_echantillons_par_classe))
}
# Sort balanced indices to maintain original order
indices_equilibres <- sort(indices_equilibres)
return(list(y = y[indices_equilibres], X = X[, indices_equilibres]))
}
# Get balanced data
donnees_equilibrees <- equilibrer_classes(y, X, nombre_echantillons_par_classe)
y_equilibre <- donnees_equilibrees$y
X_equilibre <- donnees_equilibrees$X
# Check distribution after balancing
set.seed(42)
indices_division <- createDataPartition(y_equilibre, p = 0.8, list = FALSE)
# Split balanced data into 80% for training and 20% for testing
y <- as.vector(y_equilibre[indices_division])
y.test <- as.vector(y_equilibre[-indices_division])
X <- X_equilibre[, indices_division, drop = FALSE]
X.test <- X_equilibre[, -indices_division, drop = FALSE]
table(y)
dim(X)
clf <- terBeam_mc(sparsity = c(9,10),
max.nb.features = 1000,
seed = 1,
nCores = 1,
evalToFit = "accuracy_",
objective = "auc",
experiment.id = "terBeam_mc",
experiment.save = "nothing")
printy(clf)
runit = TRUE
if(runit)
{
terbeam_Majority_Voting_metacardis_unconstrained_balance <- fit_mc(X = X, y = y, clf = clf,approch="ovo", cross.validate = TRUE,aggregation_ = "voting", nfolds= 10, constrained = FALSE);
save(terbeam_Majority_Voting_metacardis_unconstrained_balance, clf, file ="terbeam_Majority_Voting_metacardis_unconstrained_balance.rda", compression_level = 9)
}
terbeam_Majority_Voting_metacardis_unconstrained_balance$crossVal$scores$mean.acc
table(y)
load("~/Documents/multiclasse_predomics/mcpredomics/vignette/terbeam_Majority_Voting_with_Tie_Breaking_metacardis_unconstrained_no_balance.rda")
terbeam_Majority_Voting_with_Tie_Breaking_metacardis_unconstrained_no_balance$crossVal$scores$mean.acc
chemin_du_dataset <- system.file("data", "mc.input.Rda", package = "mcpredomics")
load(chemin_du_dataset)
set.seed(123)
yvec <- mc.input$y$Enterotype[match(colnames(mc.input$X), rownames(mc.input$y))]
# Filter null values
X_general <- mc.input$X[, colSums(mc.input$X) != 0]
X_general <- filterNoSignal(X = X_general, side = 1, threshold = "auto", verbose = FALSE)
set.seed(42)
y = as.vector(yvec)
X = X_general
# Check distribution after balancing
set.seed(42)
indices_division <- createDataPartition(y, p = 0.8, list = FALSE)
# Split balanced data into 80% for training and 20% for testing
y <- as.vector(y[indices_division])
y.test <- as.vector(y[-indices_division])
X <- X[, indices_division, drop = FALSE]
X.test <- X[, -indices_division, drop = FALSE]
table(y)
dim(X)
clf <- terBeam_mc(sparsity = c(10),
max.nb.features = 1000,
seed = 1,
nCores = 1,
evalToFit = "accuracy_",
objective = "auc",
experiment.id = "terBeam_mc",
experiment.save = "nothing")
printy(clf)
load("~/Documents/multiclasse_predomics/mcpredomics/vignette/terbeam_OvaSearchMax_metacardis_unconstrained_balance.rda")
terbeam_OvaSearchMax_metacardis_unconstrained_balance$crossVal$scores$mean.acc
load("~/Documents/multiclasse_predomics/mcpredomics/vignette/terbeam_OvaSearchMax_metacardis_unconstrained_no_balance.rda")
terbeam_OvaSearchMax_metacardis_unconstrained_no_balance$crossVal$scores$mean.acc
runit = TRUE
if(runit)
{
terbeam_Majority_Voting_metacardis_unconstrained_no_balance <- fit_mc(X = X, y = y, clf = clf,approch="ovo", cross.validate = TRUE,aggregation_ = "voting", nfolds= 10, constrained = FALSE);
save(terbeam_Majority_Voting_metacardis_unconstrained_no_balance, clf, file ="terbeam_Majority_Voting_metacardis_unconstrained_no_balance.rda", compression_level = 9)
}
clf <- terBeam_mc(sparsity = c(10),
max.nb.features = 1000,
seed = 1,
nCores = 1,
evalToFit = "accuracy_",
objective = "auc",
experiment.id = "terBeam_mc",
experiment.save = "nothing")
printy(clf)
runit = TRUE
if(runit)
{
terbeam_Majority_Voting_metacardis_unconstrained_no_balance <- fit_mc(X = X, y = y, clf = clf,approch="ovo", cross.validate = TRUE,aggregation_ = "voting", nfolds= 10, constrained = FALSE);
save(terbeam_Majority_Voting_metacardis_unconstrained_no_balance, clf, file ="terbeam_Majority_Voting_metacardis_unconstrained_no_balance.rda", compression_level = 9)
}
terbeam_Majority_Voting_metacardis_unconstrained_no_balance$crossVal$scores$mean.acc
clf <- terBeam_mc(sparsity = c(7),
max.nb.features = 1000,
seed = 1,
nCores = 1,
evalToFit = "accuracy_",
objective = "auc",
experiment.id = "terBeam_mc",
experiment.save = "nothing")
printy(clf)
load("~/Documents/multiclasse_predomics/mcpredomics/vignette/terga1_weighted_voting_T2D_unconstrained_no_balance1.rda")
load("~/Documents/multiclasse_predomics/mcpredomics/vignette/terbeam_Majority_Voting_with_Tie_Breaking_CRC_unconstrained_no_balance.rda")
data1 <- predomics.inputs$KarlssonFH_2013
df <- data1$y.df
y <- df$study_condition
X <- data1$X
table(y)
dim(X)
runit = TRUE
if(runit)
{
terbeam_Majority_Voting_with_Tie_Breaking_TD2_unconstrained_no_balance <- fit_mc(X = X, y = y, clf = clf,approch="ovo", cross.validate = TRUE,aggregation_ = "Predomics_aggregation_ovo", nfolds= 5, constrained = FALSE);
save(terbeam_Majority_Voting_with_Tie_Breaking_TD2_unconstrained_no_balance, clf, file ="terbeam_Majority_Voting_with_Tie_Breaking_TD2_unconstrained_no_balance.rda", compression_level = 9)
}
clf <- terBeam_mc(sparsity = c(7),
max.nb.features = 1000,
seed = 1,
nCores = 1,
evalToFit = "accuracy_",
objective = "auc",
experiment.id = "terBeam_mc",
experiment.save = "nothing")
printy(clf)
runit = TRUE
if(runit)
{
terbeam_Majority_Voting_with_Tie_Breaking_TD2_unconstrained_no_balance <- fit_mc(X = X, y = y, clf = clf,approch="ovo", cross.validate = TRUE,aggregation_ = "Predomics_aggregation_ovo", nfolds= 5, constrained = FALSE);
save(terbeam_Majority_Voting_with_Tie_Breaking_TD2_unconstrained_no_balance, clf, file ="terbeam_Majority_Voting_with_Tie_Breaking_TD2_unconstrained_no_balance.rda", compression_level = 9)
}
terbeam_Majority_Voting_with_Tie_Breaking_TD2_unconstrained_no_balance$crossVal$scores$mean.acc
clf <- terBeam_mc(sparsity = c(10),
max.nb.features = 1000,
seed = 1,
nCores = 1,
evalToFit = "accuracy_",
objective = "auc",
experiment.id = "terBeam_mc",
experiment.save = "nothing")
printy(clf)
load("~/Documents/multiclasse_predomics/mcpredomics/vignette/terga1_OvaSearchMax_T2D_unconstrained_no_balance.rda")
terga1_OvaSearchMax_T2D_unconstrained_no_balance$crossVal$scores$mean.acc
load("~/Documents/multiclasse_predomics/mcpredomics/vignette/terga1_Maximization_T2D_unconstrained_no_balance.rda")
terga1_Maximization_T2D_unconstrained_no_balance$crossVal$scores$mean.acc
runit = TRUE
if(runit)
{
terbeam_Majority_Voting_TD2_unconstrained_no_balance <- fit_mc(X = X, y = y, clf = clf,approch="ovo", cross.validate = TRUE,aggregation_ = "voting", nfolds= 5, constrained = FALSE);
save(terbeam_Majority_Voting_TD2_unconstrained_no_balance, clf, file ="terbeam_Majority_Voting_TD2_unconstrained_no_balance.rda", compression_level = 9)
}
terbeam_Majority_Voting_TD2_unconstrained_no_balance$crossVal$scores$mean.acc
load("~/Documents/multiclasse_predomics/mcpredomics/vignette/terbeam_OvaSearchMax_CRC_unconstrained_no_balance.rda")
runit = TRUE
if(runit)
{
terbeam_OvaSearchMax_TD2_unconstrained_no_balance <- fit_mc(X = X, y = y, clf = clf,approch="ovo", cross.validate = TRUE,aggregation_ = "Predomics_aggregation_ova", nfolds= 5, constrained = FALSE);
save(terbeam_OvaSearchMax_TD2_unconstrained_no_balance, clf, file ="terbeam_OvaSearchMax_TD2_unconstrained_no_balance.rda", compression_level = 9)
}
clf <- terBeam_mc(sparsity = c(3,4,5,6,7,8,9,10),
max.nb.features = 1000,
seed = 1,
nCores = 1,
evalToFit = "accuracy_",
objective = "auc",
experiment.id = "terBeam_mc",
experiment.save = "nothing")
printy(clf)
runit = TRUE
if(runit)
{
terbeam_OvaSearchMax_TD2_unconstrained_no_balance <- fit_mc(X = X, y = y, clf = clf,approch="ovo", cross.validate = TRUE,aggregation_ = "Predomics_aggregation_ova", nfolds= 5, constrained = FALSE);
save(terbeam_OvaSearchMax_TD2_unconstrained_no_balance, clf, file ="terbeam_OvaSearchMax_TD2_unconstrained_no_balance.rda", compression_level = 9)
}
runit = TRUE
if(runit)
{
terbeam_OvaSearchMax_TD2_unconstrained_no_balance <- fit_mc(X = X, y = y, clf = clf,approch="ova", cross.validate = TRUE,aggregation_ = "Predomics_aggregation_ova", nfolds= 5, constrained = FALSE);
save(terbeam_OvaSearchMax_TD2_unconstrained_no_balance, clf, file ="terbeam_OvaSearchMax_TD2_unconstrained_no_balance.rda", compression_level = 9)
}
terbeam_OvaSearchMax_TD2_unconstrained_no_balance$crossVal$scores$mean.acc
