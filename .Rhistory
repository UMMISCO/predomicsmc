g.recall.emp, g.precision.emp,
ncol = 2)
} # end classification
}
# return digested results
return(res)
}
#' @title votingova
#' @description Function to aggregate one-versus-one or one-versus-all predictions using majority voting.
#' If there's a tie, a class is randomly selected. If no class is predicted, one is also randomly chosen among all possible.
#' @param mod List of submodels containing predictions and metadata.
#' @param y Vector of class labels (true labels or full set of possible classes).
#' @return A list representing the aggregated model object.
#' @export
votingova <- function(mod, y) {
predictions_list <- lapply(mod, function(x) x$predictions)  # Extract predictions
all_classes <- unique(as.character(y))
num_samples <- length(predictions_list[[1]])
aggregated_vector <- character(num_samples)
set.seed(123)  # Fix seed for reproducibility
for (i in 1:num_samples) {
votes <- table(sapply(predictions_list, `[`, i))
# Remove votes for "ALL" (OVA: means not predicted)
votes <- votes[names(votes) != "ALL"]
if (length(votes) == 0) {
# No class predicted at all: choose randomly from all classes
aggregated_vector[i] <- sample(all_classes, 1)
} else {
max_vote <- max(votes)
top_classes <- names(votes)[votes == max_vote]
if (length(top_classes) == 1) {
aggregated_vector[i] <- top_classes
} else {
aggregated_vector[i] <- sample(top_classes, 1)
}
}
}
# Reconstruct the model
model <- list()
model$learner <- mod[[1]]$learner
model$language <- mod[[1]]$language
model$objective <- mod[[1]]$objective
model$indices_ <- lapply(mod, function(x) x$indices_)
model$names_ <- lapply(mod, function(x) x$names_)
model$coeffs_ <- lapply(mod, function(x) x$coeffs_)
model$fit_ <- lapply(mod, function(x) x$fit_)
model$unpenalized_fit_ <- lapply(mod, function(x) x$unpenalized_fit_)
model$auc_ <- lapply(mod, function(x) x$auc_)
model$accuracy_ <- lapply(mod, function(x) x$accuracy_)
model$cor_ <- NA
model$aic_ <- NA
model$list_intercept_ <- lapply(mod, function(x) x$intercept_)
model$intercept_ <- mean(sapply(mod, function(x) x$intercept_))
model$eval.sparsity <- mod[[1]]$eval.sparsity
model$precision_ <- lapply(mod, function(x) x$precision_)
model$recall_ <- lapply(mod, function(x) x$recall_)
model$f1_ <- lapply(mod, function(x) x$f1_)
model$sign_ <- lapply(mod, function(x) x$sign_)
model$rsq_ <- lapply(mod, function(x) x$rsq_)
model$ser_ <- lapply(mod, function(x) x$ser_)
model$score_ <- lapply(mod, function(x) x$score_)
model$predictions <- predictions_list
model$scores_predictions <- lapply(mod, function(x) x$scores_predictions)
model$pos_score_ <- lapply(mod, function(x) x$pos_score_)
model$neg_score_ <- lapply(mod, function(x) x$neg_score_)
model$confusionMatrix_ <- lapply(mod, function(x) x$confusionMatrix_)
model$predictions_aggre <- aggregated_vector
model$method <- "votingova"
model$approach <- "ova"  # <-- Change ici si besoin
return(model)
}
knitr::opts_chunk$set(echo = TRUE)
# Package multi class predomics
library(mcpredomics)
# Package predomics
library(predomics)
# Visualization library for creating complex plots
library(ggplot2)
# Arranges multiple ggplot objects on a single page
library(gridExtra)
# ROC curve analysis and AUC calculation
library(pROC)
# Reshaping and melting data frames
library(reshape2)
# Implementation of the Random Forest algorithm for classification and regression
library(randomForest)
# Comprehensive library for classification and regression training
library(caret)
# Various R programming tools and functions, including data manipulation
library(gtools)
# Adding statistical comparisons and publication-ready visualizations
library(ggpubr)
# Data manipulation and transformation (part of the tidyverse)
library(dplyr)
# Tidying messy data by gathering and spreading
library(tidyr)
# Enhanced data frames with row names as a column (tibble format)
library(tibble)
# Dynamic report generation and displaying results in tables
library(knitr)
# Creating aesthetically pleasing and customizable HTML tables
library(kableExtra)
# Interactive tables for data visualization and exploration
library(DT)
# Functions for statistical learning, including SVM and Naive Bayes
library(e1071)
# Lasso and ridge regression via generalized linear models
library(glmnet)
# Reading data from files (including CSV and text files)
library(readr)
# String manipulation and regular expression functions
library(stringr)
chemin_du_dataset <- system.file("data", "mc.input.Rda", package = "mcpredomics")
load(chemin_du_dataset)
set.seed(123)
yvec <- mc.input$y$Enterotype[match(colnames(mc.input$X), rownames(mc.input$y))]
# Filter null values
X_general <- mc.input$X[, colSums(mc.input$X) != 0]
X_general <- filterNoSignal(X = X_general, side = 1, threshold = "auto", verbose = FALSE)
set.seed(42)
y = as.vector(yvec)
X = X_general
# Check distribution after balancing
set.seed(42)
indices_division <- createDataPartition(y, p = 0.8, list = FALSE)
# Split balanced data into 80% for training and 20% for testing
y <- as.vector(y[indices_division])
y.test <- as.vector(y[-indices_division])
X <- X[, indices_division, drop = FALSE]
X.test <- X[, -indices_division, drop = FALSE]
table(y)
dim(X)
load("~/Documents/multiclasse_predomics/mcpredomics/vignette/res_clf_Unbalancefull.rda")
# Convert the model collection into a population of models scrambled by model size
pop <- modelCollectionToPopulation(res_clf_Unbalancefull$classifier$models)
printy_mc(pop)
# Function to create boxplot for a given data frame
create_boxplot <- function(data, title) {
# Melt the dataframe for ggplot
data.melt <- melt(data, id.vars = c("accuracy_", "eval.sparsity"))
# Create ggplot
plot <- ggplot(data = data.melt, aes(y = accuracy_, x = eval.sparsity)) +
geom_boxplot(notch = FALSE, outlier.shape = NA, position = position_dodge(width = 0.9), alpha = 0.3) +
geom_point(aes(color = eval.sparsity), position = position_jitterdodge(dodge.width = 0.9), size = 1, alpha = 0.5) +
ylim(c(0, 1)) +
xlab("Model Parsimony") +
ggtitle(title) +
theme_bw() +
theme(legend.position = "bottom", legend.direction = "horizontal") +
guides(colour = "none")
return(plot)
}
# Convert the population to a data frame
pop.df <- populationToDataFrame_mc(pop)
# Plotting for the original population (single figure)
pop.dff <- as.data.frame(pop.df[[1]])  # Convert the first submodel to a data frame
g.before <- create_boxplot(pop.dff, title = "Original Population")
#print(g.before)  # Display the plot
# Select the best population models
fbm <- selectBestPopulation(pop)
#printy_mc(fbm)
# Convert the best population models to a data frame
fbm.df <- populationToDataFrame_mc(fbm)
# Plotting for the selected best models (single figure)
fbm.dff <- as.data.frame(fbm.df[[1]])  # Convert the first submodel to a data frame
g.after <- create_boxplot(fbm.dff, title = "FBM")
print(g.after)  # Display the plot
fa <- makeFeatureAnnot_mc(pop = fbm,
X = X,
y = y,
clf = clf,
approch = "ovo")
plot_distribution <- plotFeatureModelCoeffs_mc(feat.model.coeffs = fa, y, approch = "ovo")
plots_abundance <- plotAbundanceByClass_mc(features = fa, X, y, approch = "ovo")
plots_prevalence <- plotPrevalence_mc(features = fa, X = X, y = y, approch = "ovo")
fa <- makeFeatureAnnot_mc(pop = fbm,
X = X,
y = y,
clf = clf,
approch = "ovo")
plot_distribution <- plotFeatureModelCoeffs_mc(feat.model.coeffs = fa, y, approch = "ovo")
plots_abundance <- plotAbundanceByClass_mc(features = fa, X, y, approch = "ovo")
plots_prevalence <- plotPrevalence_mc(features = fa, X = X, y = y, approch = "ovo")
fa <- makeFeatureAnnot_mc(pop = fbm,
X = X,
y = y,
clf = clf,
approch = "ovo")
plot_distribution <- plotFeatureModelCoeffs_mc(feat.model.coeffs = fa, y, approch = "ovo")
plots_abundance <- plotAbundanceByClass_mc(features = fa, X, y, approch = "ovo")
plots_prevalence <- plotPrevalence_mc(features = fa, X = X, y = y, approch = "ovo")
fa <- makeFeatureAnnot_mc(pop = fbm,
X = X,
y = y,
clf = clf,
approch = "ovo")
plot_distribution <- plotFeatureModelCoeffs_mc(feat.model.coeffs = fa, y, approch = "ovo")
plots_abundance <- plotAbundanceByClass_mc(features = fa, X, y, approch = "ovo")
plots_prevalence <- plotPrevalence_mc(features = fa, X = X, y = y, approch = "ovo")
feat1.import <- mergeMeltImportanceCV_mc(list.results = list(terBeam = res_clf_Unbalancefull),
filter.cv.prev = 0,
min.kfold.nb = FALSE,
learner.grep.pattern = "*",
#nb.top.features = 50,
feature.selection = fa,
scaled.importance = TRUE,
make.plot = TRUE,
cv.prevalence = FALSE)
feat2.import <- mergeMeltImportanceCV_mc(list.results = list(terBeam = res_clf_Unbalancefull),
filter.cv.prev = 0,
min.kfold.nb = FALSE,
learner.grep.pattern = "*",
nb.top.features = 148,
#feature.selection = rownames(fa$pop.noz),
scaled.importance = TRUE,
make.plot = TRUE,
cv.prevalence = FALSE)
# get the best model
best.model = fbm[[1]]
# Visualize the model information (if needed)
printy_mc(best.model)
# Generate the plots
plots1 <- plotModel_mc(best.model, X, y, sort.features = FALSE, feature.name = TRUE, approch = "ovo")
plots2 <- plotModel_mc(best.model, X, y, sort.features = FALSE, feature.name = TRUE, importance = TRUE, approch = "ovo")
# Open a PDF device to save the grid of plots
pdf("model_visualization_plots2.pdf", width = 18, height = 12)  # Adjust width and height as needed
# Extract the plots from each list and pass them to `grid.arrange`
grid.arrange(grobs = c(plots1, plots2), ncol = 4)
# Close the PDF device
dev.off()
# Confirmation of the save process
cat("The plots have been saved under the name 'model_visualization_plots2.pdf'.\n")
best.model.test <- evaluateModel_mc(
mod = fbm[[1]],
X = X.test,
y = y.test,
clf = clf,
eval.all = TRUE,
force.re.evaluation = TRUE,
aggregation_ = "voting",
constraint_factor = "fully_constrained",
mode = "test",
approch = "ovo"
)
best.model.test$score_
tmp <- plotAUC_mcc(scores = best.model.test$score_, y = y.test, percent = TRUE, approch = "ovo"); rm(tmp)
feat1.import <- mergeMeltImportanceCV_mc(list.results = list(terBeam = res_clf_Unbalancefull),
filter.cv.prev = 0,
min.kfold.nb = FALSE,
learner.grep.pattern = "*",
#nb.top.features = 50,
feature.selection = fa,
scaled.importance = TRUE,
make.plot = TRUE,
cv.prevalence = FALSE)
feat2.import <- mergeMeltImportanceCV_mc(list.results = list(terBeam = res_clf_Unbalancefull),
filter.cv.prev = 0,
min.kfold.nb = FALSE,
learner.grep.pattern = "*",
nb.top.features = 148,
#feature.selection = rownames(fa$pop.noz),
scaled.importance = TRUE,
make.plot = TRUE,
cv.prevalence = FALSE)
load("~/Documents/multiclasse_predomics/mcpredomics/vignette/Constrained_CRC_Voting2.rda")
Constrained_CRC_Voting2$crossVal$scores$mean.acc
load("~/Documents/multiclasse_predomics/mcpredomics/vignette/Constrained_CRC_Voting.rda")
Constrained_CRC_Voting$crossVal$scores$mean.acc
# Load the file
load("../data/predomics.inputs.ExperimentHubMulticlass.Rda")
lapply(predomics.inputs, function(x){summary(colSums(x[["X"]]))})
# Extract data
data1 <- predomics.inputs$FengQ_2015
df <- data1$y.df
y <- df$study_condition
X <- data1$X
table(y)
dim(X)
# Convert the model collection into a population of models scrambled by model size
pop <- modelCollectionToPopulation(Constrained_CRC_Voting$classifier$models)
printy_mc(pop)
# Function to create boxplot for a given data frame
create_boxplot <- function(data, title) {
# Melt the dataframe for ggplot
data.melt <- melt(data, id.vars = c("accuracy_", "eval.sparsity"))
# Create ggplot
plot <- ggplot(data = data.melt, aes(y = accuracy_, x = eval.sparsity)) +
geom_boxplot(notch = FALSE, outlier.shape = NA, position = position_dodge(width = 0.9), alpha = 0.3) +
geom_point(aes(color = eval.sparsity), position = position_jitterdodge(dodge.width = 0.9), size = 1, alpha = 0.5) +
ylim(c(0, 1)) +
xlab("Model Parsimony") +
ggtitle(title) +
theme_bw() +
theme(legend.position = "bottom", legend.direction = "horizontal") +
guides(colour = "none")
return(plot)
}
# Convert the population to a data frame
pop.df <- populationToDataFrame_mc(pop)
# Plotting for the original population (single figure)
pop.dff <- as.data.frame(pop.df[[1]])  # Convert the first submodel to a data frame
g.before <- create_boxplot(pop.dff, title = "Original Population")
#print(g.before)  # Display the plot
# Select the best population models
fbm <- selectBestPopulation(pop)
#printy_mc(fbm)
# Convert the best population models to a data frame
fbm.df <- populationToDataFrame_mc(fbm)
# Plotting for the selected best models (single figure)
fbm.dff <- as.data.frame(fbm.df[[1]])  # Convert the first submodel to a data frame
g.after <- create_boxplot(fbm.dff, title = "FBM")
print(g.after)  # Display the plot
fa <- makeFeatureAnnot_mc(pop = fbm,
X = X,
y = y,
clf = clf,
approch = "ovo")
plot_distribution <- plotFeatureModelCoeffs_mc(feat.model.coeffs = fa, y, approch = "ovo")
plots_abundance <- plotAbundanceByClass_mc(features = fa, X, y, approch = "ovo")
plots_prevalence <- plotPrevalence_mc(features = fa, X = X, y = y, approch = "ovo")
fa <- makeFeatureAnnot_mc(pop = fbm,
X = X,
y = y,
clf = clf,
approch = "ovo")
plot_distribution <- plotFeatureModelCoeffs_mc(feat.model.coeffs = fa, y, approch = "ovo")
plots_abundance <- plotAbundanceByClass_mc(features = fa, X, y, approch = "ovo")
plots_prevalence <- plotPrevalence_mc(features = fa, X = X, y = y, approch = "ovo")
fa <- makeFeatureAnnot_mc(pop = fbm,
X = X,
y = y,
clf = clf,
approch = "ovo")
plot_distribution <- plotFeatureModelCoeffs_mc(feat.model.coeffs = fa, y, approch = "ovo")
plots_abundance <- plotAbundanceByClass_mc(features = fa, X, y, approch = "ovo")
plots_prevalence <- plotPrevalence_mc(features = fa, X = X, y = y, approch = "ovo")
fa <- makeFeatureAnnot_mc(pop = fbm,
X = X,
y = y,
clf = clf,
approch = "ovo")
plot_distribution <- plotFeatureModelCoeffs_mc(feat.model.coeffs = fa, y, approch = "ovo")
plots_abundance <- plotAbundanceByClass_mc(features = fa, X, y, approch = "ovo")
plots_prevalence <- plotPrevalence_mc(features = fa, X = X, y = y, approch = "ovo")
fa <- makeFeatureAnnot_mc(pop = fbm,
X = X,
y = y,
clf = clf,
approch = "ovo")
plot_distribution <- plotFeatureModelCoeffs_mc(feat.model.coeffs = fa, y, approch = "ovo")
plots_abundance <- plotAbundanceByClass_mc(features = fa, X, y, approch = "ovo")
plots_prevalence <- plotPrevalence_mc(features = fa, X = X, y = y, approch = "ovo")
feat1.import <- mergeMeltImportanceCV_mc(list.results = list(terBeam = Constrained_CRC_Voting),
filter.cv.prev = 0,
min.kfold.nb = FALSE,
learner.grep.pattern = "*",
#nb.top.features = 50,
feature.selection = fa,
scaled.importance = TRUE,
make.plot = TRUE,
cv.prevalence = FALSE)
feat2.import <- mergeMeltImportanceCV_mc(list.results = list(terBeam = Constrained_CRC_Voting),
filter.cv.prev = 0,
min.kfold.nb = FALSE,
learner.grep.pattern = "*",
nb.top.features = 148,
#feature.selection = rownames(fa$pop.noz),
scaled.importance = TRUE,
make.plot = TRUE,
cv.prevalence = FALSE)
feat1.import <- mergeMeltImportanceCV_mc(list.results = list(terBeam = Constrained_CRC_Voting),
filter.cv.prev = 0,
min.kfold.nb = FALSE,
learner.grep.pattern = "*",
#nb.top.features = 50,
feature.selection = fa,
scaled.importance = TRUE,
make.plot = TRUE,
cv.prevalence = FALSE)
feat2.import <- mergeMeltImportanceCV_mc(list.results = list(terBeam = Constrained_CRC_Voting),
filter.cv.prev = 0,
min.kfold.nb = FALSE,
learner.grep.pattern = "*",
nb.top.features = 148,
#feature.selection = rownames(fa$pop.noz),
scaled.importance = TRUE,
make.plot = TRUE,
cv.prevalence = FALSE)
# get the best model
best.model = fbm[[1]]
# Visualize the model information (if needed)
printy_mc(best.model)
# Generate the plots
plots1 <- plotModel_mc(best.model, X, y, sort.features = FALSE, feature.name = TRUE, approch = "ovo")
plots2 <- plotModel_mc(best.model, X, y, sort.features = FALSE, feature.name = TRUE, importance = TRUE, approch = "ovo")
# Open a PDF device to save the grid of plots
pdf("model_visualization_plots2.pdf", width = 45, height = 28)  # Adjust width and height as needed
# Extract the plots from each list and pass them to `grid.arrange`
grid.arrange(grobs = c(plots1, plots2), ncol = 3)
# Close the PDF device
dev.off()
# Confirmation of the save process
cat("The plots have been saved under the name 'model_visualization_plots2.pdf'.\n")
best.model.test <- evaluateModel_mc(
mod = fbm[[1]],
X = X,
y = y,
clf = clf,
eval.all = TRUE,
force.re.evaluation = TRUE,
aggregation_ = "voting",
constraint_factor = "unconstrained",
mode = "test",
approch = "ovo"
)
tmp <- plotAUC_mcc(scores = best.model.test$score_, y = y, percent = TRUE, approch = "ovo"); rm(tmp)
data1 <- predomics.inputs$KarlssonFH_2013
df <- data1$y.df
y <- df$study_condition
X <- data1$X
table(y)
dim(X)
load("~/Documents/multiclasse_predomics/mcpredomics/vignette/res_clf_TD2_ovo.rda")
res_clf_TD2_ovo$crossVal$scores$mean.acc
# Convert the model collection into a population of models scrambled by model size
pop <- modelCollectionToPopulation(res_clf_TD2_ovo$classifier$models)
printy_mc(pop)
# Function to create boxplot for a given data frame
create_boxplot <- function(data, title) {
# Melt the dataframe for ggplot
data.melt <- melt(data, id.vars = c("accuracy_", "eval.sparsity"))
# Create ggplot
plot <- ggplot(data = data.melt, aes(y = accuracy_, x = eval.sparsity)) +
geom_boxplot(notch = FALSE, outlier.shape = NA, position = position_dodge(width = 0.9), alpha = 0.3) +
geom_point(aes(color = eval.sparsity), position = position_jitterdodge(dodge.width = 0.9), size = 1, alpha = 0.5) +
ylim(c(0, 1)) +
xlab("Model Parsimony") +
ggtitle(title) +
theme_bw() +
theme(legend.position = "bottom", legend.direction = "horizontal") +
guides(colour = "none")
return(plot)
}
# Convert the population to a data frame
pop.df <- populationToDataFrame_mc(pop)
# Plotting for the original population (single figure)
pop.dff <- as.data.frame(pop.df[[1]])  # Convert the first submodel to a data frame
g.before <- create_boxplot(pop.dff, title = "Original Population")
#print(g.before)  # Display the plot
# Select the best population models
fbm <- selectBestPopulation(pop)
#printy_mc(fbm)
# Convert the best population models to a data frame
fbm.df <- populationToDataFrame_mc(fbm)
# Plotting for the selected best models (single figure)
fbm.dff <- as.data.frame(fbm.df[[1]])  # Convert the first submodel to a data frame
g.after <- create_boxplot(fbm.dff, title = "FBM")
print(g.after)  # Display the plot
fa <- makeFeatureAnnot_mc(pop = fbm,
X = X,
y = y,
clf = clf,
approch = "ovo")
plot_distribution <- plotFeatureModelCoeffs_mc(feat.model.coeffs = fa, y, approch = "ovo")
plots_abundance <- plotAbundanceByClass_mc(features = fa, X, y, approch = "ovo")
plots_prevalence <- plotPrevalence_mc(features = fa, X = X, y = y, approch = "ovo")
feat1.import <- mergeMeltImportanceCV_mc(list.results = list(terBeam = res_clf_TD2_ovo),
filter.cv.prev = 0,
min.kfold.nb = FALSE,
learner.grep.pattern = "*",
#nb.top.features = 50,
feature.selection = fa,
scaled.importance = TRUE,
make.plot = TRUE,
cv.prevalence = FALSE)
feat2.import <- mergeMeltImportanceCV_mc(list.results = list(terBeam = res_clf_TD2_ovo),
filter.cv.prev = 0,
min.kfold.nb = FALSE,
learner.grep.pattern = "*",
nb.top.features = 148,
#feature.selection = rownames(fa$pop.noz),
scaled.importance = TRUE,
make.plot = TRUE,
cv.prevalence = FALSE)
# get the best model
best.model = fbm[[1]]
# Visualize the model information (if needed)
printy_mc(best.model)
# Generate the plots
plots1 <- plotModel_mc(best.model, X, y, sort.features = FALSE, feature.name = TRUE, approch = "ovo")
plots2 <- plotModel_mc(best.model, X, y, sort.features = FALSE, feature.name = TRUE, importance = TRUE, approch = "ovo")
# Open a PDF device to save the grid of plots
pdf("model_visualization_plots2.pdf", width = 45, height = 28)  # Adjust width and height as needed
# Extract the plots from each list and pass them to `grid.arrange`
grid.arrange(grobs = c(plots1, plots2), ncol = 3)
# Close the PDF device
dev.off()
# Confirmation of the save process
cat("The plots have been saved under the name 'model_visualization_plots2.pdf'.\n")
best.model.test <- evaluateModel_mc(
mod = fbm[[1]],
X = X,
y = y,
clf = clf,
eval.all = TRUE,
force.re.evaluation = TRUE,
aggregation_ = "voting",
constraint_factor = "semi_constrained",
mode = "test",
approch = "ovo"
)
tmp <- plotAUC_mcc(scores = best.model.test$score_, y = y, percent = TRUE, approch = "ovo"); rm(tmp)
