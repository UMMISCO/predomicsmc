max(floor(ncol(x)/3), 1) else floor(sqrt(ncol(x)))
}
if(is.null(clf$params$sampsize))
{
clf$params$sampsize = if(clf$params$replace) nrow(x) else ceiling(.632*nrow(x))
}
if(is.null(clf$params$nodesize))
{
clf$params$nodesize = if(!is.null(y) && !is.factor(y)) 5 else 1
}
if(is.null(clf$params$sparsity))
{
clf$params$sparsity <- nrow(X)
}
model_collection <- list()
for(i in 1:length(clf$params$sparsity))  # sparsity is = k, i.e. the number of features in a model
{
k <- clf$params$sparsity[i]
if(clf$params$verbose) cat("... ... Resolving problem with\t", k, "\tvariables ...\n")
for (o in 1:length(clf$feature.cor)){
xi <- list_X[[o]]
yi <- list_y[[o]]
xi <- as.matrix(t(xi))
y = as.factor(y)
selected.features <- rownames(clf$feature.cor[[o]])[order(clf$feature.cor[[o]]$p)][1:k]
x.reduced <- x[,selected.features]
### Launch randomForest with the parameters from the clf
set.seed(clf$params$seed)
rf[[o]] <- randomForest(x = x.reduced, y=y,
ntree=clf$params$ntree,
mtry=clf$params$mtry,
replace=clf$params$replace,
classwt=clf$params$classwt,
maxnodes = clf$params$maxnodes,
importance=clf$params$importance,
localImp=clf$params$localImp,
nPerm=nPerm,
norm.votes=clf$params$norm.votes,
do.trace=clf$params$do.trace,
keep.forest=clf$params$keep.forest,
corr.bias=clf$params$corr.bias,
keep.inbag=clf$params$keep.inbag
)
}
# build the model for this given sparsity
mod.res                  <- list() # to send the results
# Fill the object up with the rest of the values
mod.res$learner          <- clf$learner
mod.res$language         <- clf$params$language
mod.res$names_           <- selected.features
# match the index
mod.res$indices_         <- match(selected.features, rownames(X))
mod.res$eval.sparsity    <- length(unique(mod.res$names_))
# Add the rf object
mod.res$obj              <- rf
mod.res$auc_             <- NA
mod.res$cor_             <- NA
mod.res$aic_             <- NA
mod.res$score_           <- NA
mod.res$fit_             <- NA
mod.res$unpenalized_fit_ <- NA
mod.res$intercept_       <- NA
mod.res$sign_            <- NA
# evaluate all
}
mod.res
mod.res                  <- evaluateModel_ovo(mod = mod.res,
X = X,
y = y,
clf = clf,
eval.all = TRUE,
force.re.evaluation = TRUE,
estim.feat.importance = TRUE)
x <- as.matrix(t(X))
feature.cor <- list()
#rf <- list()
nClasse <- unique(y)
list_y <- list()
list_X <- list()
k <- 1
clf$feature.cor <- NA
list_selected_ <- list()
rows_list <- list()
listing_ <- list()
for (i in 1:(length(nClasse)-1)) {
for (j in (i+1):length(nClasse)) {
class_i <- nClasse[i]
class_j <- nClasse[j]
indices <- which(y == class_i | y == class_j)
y_pair <- y[indices]
y_pair <- as.vector(y_pair)
X_pair <- X[,indices]
list_y[[k]] <- y_pair
list_X[[k]] <- X_pair
k <- k+1
}
}
for(j in 1:length(list_y)){
yy <- list_y[[j]]
xx <- list_X[[j]]
# compute the feature correlation for feature selection
feature.cor[[j]] <- filterfeaturesK(data = xx, trait = yy, k = nrow(X), sort = TRUE) # to avoid having to recompute this all the time
}
clf$feature.cor <- feature.cor
listing_ <- clf$feature.cor
# initialize some parameteres
if(is.null(clf$params$mtry))
{
clf$params$mtry = if(!is.null(y) && !is.factor(y))
max(floor(ncol(x)/3), 1) else floor(sqrt(ncol(x)))
}
if(is.null(clf$params$sampsize))
{
clf$params$sampsize = if(clf$params$replace) nrow(x) else ceiling(.632*nrow(x))
}
if(is.null(clf$params$nodesize))
{
clf$params$nodesize = if(!is.null(y) && !is.factor(y)) 5 else 1
}
if(is.null(clf$params$sparsity))
{
clf$params$sparsity <- nrow(X)
}
model_collection <- list()
for(i in 1:length(clf$params$sparsity))  # sparsity is = k, i.e. the number of features in a model
{
k <- clf$params$sparsity[i]
if(clf$params$verbose) cat("... ... Resolving problem with\t", k, "\tvariables ...\n")
for (o in 1:length(clf$feature.cor)){
xi <- list_X[[o]]
yi <- list_y[[o]]
xi <- as.matrix(t(xi))
y = as.factor(y)
selected.features <- rownames(clf$feature.cor[[o]])[order(clf$feature.cor[[o]]$p)][1:k]
x.reduced <- x[,selected.features]
### Launch randomForest with the parameters from the clf
set.seed(clf$params$seed)
rf <- randomForest(x = x.reduced, y=y,
ntree=clf$params$ntree,
mtry=clf$params$mtry,
replace=clf$params$replace,
classwt=clf$params$classwt,
maxnodes = clf$params$maxnodes,
importance=clf$params$importance,
localImp=clf$params$localImp,
nPerm=nPerm,
norm.votes=clf$params$norm.votes,
do.trace=clf$params$do.trace,
keep.forest=clf$params$keep.forest,
corr.bias=clf$params$corr.bias,
keep.inbag=clf$params$keep.inbag
)
}
# build the model for this given sparsity
mod.res                  <- list() # to send the results
# Fill the object up with the rest of the values
mod.res$learner          <- clf$learner
mod.res$language         <- clf$params$language
mod.res$names_           <- selected.features
# match the index
mod.res$indices_         <- match(selected.features, rownames(X))
mod.res$eval.sparsity    <- length(unique(mod.res$names_))
# Add the rf object
mod.res$obj              <- rf
mod.res$auc_             <- NA
mod.res$cor_             <- NA
mod.res$aic_             <- NA
mod.res$score_           <- NA
mod.res$fit_             <- NA
mod.res$unpenalized_fit_ <- NA
mod.res$intercept_       <- NA
mod.res$sign_            <- NA
# evaluate all
mod.res                  <- evaluateModel_ovo(mod = mod.res,
X = X,
y = y,
clf = clf,
eval.all = TRUE,
force.re.evaluation = TRUE,
estim.feat.importance = TRUE)
if(clf$params$verbose)
}
mod.res
x <- as.matrix(t(X))
feature.cor <- list()
#rf <- list()
nClasse <- unique(y)
list_y <- list()
list_X <- list()
k <- 1
clf$feature.cor <- NA
list_selected_ <- list()
rows_list <- list()
listing_ <- list()
for (i in 1:(length(nClasse)-1)) {
for (j in (i+1):length(nClasse)) {
class_i <- nClasse[i]
class_j <- nClasse[j]
indices <- which(y == class_i | y == class_j)
y_pair <- y[indices]
y_pair <- as.vector(y_pair)
X_pair <- X[,indices]
list_y[[k]] <- y_pair
list_X[[k]] <- X_pair
k <- k+1
}
}
for(j in 1:length(list_y)){
yy <- list_y[[j]]
xx <- list_X[[j]]
# compute the feature correlation for feature selection
feature.cor[[j]] <- filterfeaturesK(data = xx, trait = yy, k = nrow(X), sort = TRUE) # to avoid having to recompute this all the time
}
clf$feature.cor <- feature.cor
listing_ <- clf$feature.cor
# initialize some parameteres
if(is.null(clf$params$mtry))
{
clf$params$mtry = if(!is.null(y) && !is.factor(y))
max(floor(ncol(x)/3), 1) else floor(sqrt(ncol(x)))
}
if(is.null(clf$params$sampsize))
{
clf$params$sampsize = if(clf$params$replace) nrow(x) else ceiling(.632*nrow(x))
}
if(is.null(clf$params$nodesize))
{
clf$params$nodesize = if(!is.null(y) && !is.factor(y)) 5 else 1
}
if(is.null(clf$params$sparsity))
{
clf$params$sparsity <- nrow(X)
}
model_collection <- list()
for(i in 1:length(clf$params$sparsity))  # sparsity is = k, i.e. the number of features in a model
{
k <- clf$params$sparsity[i]
if(clf$params$verbose) cat("... ... Resolving problem with\t", k, "\tvariables ...\n")
for (o in 1:length(clf$feature.cor)){
xi <- list_X[[o]]
yi <- list_y[[o]]
xi <- as.matrix(t(xi))
y = as.factor(y)
selected.features <- rownames(clf$feature.cor[[o]])[order(clf$feature.cor[[o]]$p)][1:k]
x.reduced <- x[,selected.features]
### Launch randomForest with the parameters from the clf
set.seed(clf$params$seed)
rf <- randomForest(x = x.reduced, y=y,
ntree=clf$params$ntree,
mtry=clf$params$mtry,
replace=clf$params$replace,
classwt=clf$params$classwt,
maxnodes = clf$params$maxnodes,
importance=clf$params$importance,
localImp=clf$params$localImp,
nPerm=nPerm,
norm.votes=clf$params$norm.votes,
do.trace=clf$params$do.trace,
keep.forest=clf$params$keep.forest,
corr.bias=clf$params$corr.bias,
keep.inbag=clf$params$keep.inbag
)
}
# build the model for this given sparsity
mod.res                  <- list() # to send the results
# Fill the object up with the rest of the values
mod.res$learner          <- clf$learner
mod.res$language         <- clf$params$language
mod.res$names_           <- selected.features
# match the index
mod.res$indices_         <- match(selected.features, rownames(X))
mod.res$eval.sparsity    <- length(unique(mod.res$names_))
# Add the rf object
mod.res$obj              <- rf
mod.res$auc_             <- NA
mod.res$cor_             <- NA
mod.res$aic_             <- NA
mod.res$score_           <- NA
mod.res$fit_             <- NA
mod.res$unpenalized_fit_ <- NA
mod.res$intercept_       <- NA
mod.res$sign_            <- NA
# evaluate all
mod.res                  <- evaluateModel_ovo(mod = mod.res,
X = X,
y = y,
clf = clf,
eval.all = TRUE,
force.re.evaluation = TRUE,
estim.feat.importance = TRUE)
}
load("~/Documents/multiclasse_predomics/mcpredomics/data/mc.input.Rda")
library(mcpredomics)
load("~/Documents/multiclasse_predomics/mcpredomics/data/mc.input.Rda")
knitr::opts_chunk$set(echo = TRUE)
library(mcpredomics)
library(predomics)
library(ggplot2)
library(gridExtra)
library(pROC)
library(reshape2)
library(randomForest())
# load the data
data("mc.input")
set.seed(123)
#recover the vector y
yvec <- mc.input$y$Enterotype[match(colnames(mc.input$X), rownames(mc.input$y))]
#Divide the dataset into training and testing
proportion_test <- 0.2
taille_test <- round(proportion_test * ncol(mc.input$X))
indices_test <- sample(1:ncol(mc.input$X), taille_test)
X <- mc.input$X[,-indices_test]
X.test <- mc.input$X[,indices_test]
y <- as.vector(yvec[-indices_test])
y.test <- as.vector(yvec[indices_test])
y
X
class(X)
class(y)
dim(y)
y
library(mcpredomics)
library(predomics)
library(ggplot2)
library(gridExtra)
library(pROC)
library(reshape2)
library(randomForest())
# load the data
data("mc.input")
set.seed(123)
#recover the vector y
yvec <- mc.input$y$Enterotype[match(colnames(mc.input$X), rownames(mc.input$y))]
#Divide the dataset into training and testing
proportion_test <- 0.2
taille_test <- round(proportion_test * ncol(mc.input$X))
indices_test <- sample(1:ncol(mc.input$X), taille_test)
X <- mc.input$X[,-indices_test]
X.test <- mc.input$X[,indices_test]
y <- as.vector(yvec[-indices_test])
y.test <- as.vector(yvec[indices_test])
clf <- terga1_ovo(nCores = 1,
seed = 1,
plot = TRUE
)
printy(clf) # print the object for more information
isClf(clf)  # test whether the object is a classifier
class(clf)  # the class of the classifier object
runit = TRUE
if(runit)
{
res_clf <- fit_OVO(X = X, y = y, clf = clf, cross.validate = TRUE, nfolds = 1); # class(res_clf)
# save results
save(res_clf, clf, file = "res_clf.rda", compression_level = 9)
}
# ... Database X is not a matrix! Converting ...
# ... Classification mode, computing factor(y) for speedup and robustness
# ... Loading feature correlation for speedup
# ... Correlation file loaded
# ... Storing data in the classifier object for speedup
# ... Computing ternary coefficients for speedup
# ... One seed found, setting by default
# ... Running the classifier terga2 with a single CPU
# ... Second and faster version of terga fitting based on Genetic Algorithm heuristics ...
# ... Cross validation mode
# ... Starting cross validation not in parallel
# ....................................................................................................
# ....................................................................................................
# ....................................................................................................
# ....................................................................................................
# ....................................................................................................
# ....................................................................................................
# ....................................................................................................
# ....................................................................................................
# ....................................................................................................
# ....................................................................................................
# ....................................................................................................
# ... Learning process is finished succesfuly
# ... Thank you for using Predomics. Don't forget to digest the results now.
#
# [1] "experiment" "predomics"
if(!runit)
{
load("res_clf.rda")
}
res_clf.dig <- digest(obj = res_clf, penalty = 0.75/100, plot = TRUE)
res_clf.dig <- digest(obj = res_clf, penalty = 0.75/100, plot = TRUE)
# get the best model
best.model <- res_clf.dig$best$model
printy(best.model)
grid.arrange(plotModel_ovo(best.model, X=X, y=y, sort.features = FALSE, feature.name = TRUE),
plotModel_ovo(best.model, X=X, y=y, sort.features = FALSE, feature.name = TRUE, importance = TRUE),ncol=2)
best.model.test <- evaluateModel_ovo(mod = best.model, X = X.test, y = y.test, clf = clf, eval.all = TRUE, force.re.evaluation = TRUE, mode = "test")
printy(best.model.test)
nClasse <- unique(y)
list_y <- list()
list_X <- list()
k <- 1
for (i in 1:(length(nClasse)-1)) {
for (j in (i+1):length(nClasse)) {
class_i <- nClasse[i]
class_j <- nClasse[j]
indices <- which(y == class_i | y == class_j)
y_pair <- y[indices]
X_pair <- X[,indices]
list_y[[k]] <- y_pair
list_X[[k]] <- X_pair
k <- k + 1
}
}
nClasse <- unique(y.test)
list_y.test <- list()
list_X.test <- list()
k <- 1
for (i in 1:(length(nClasse)-1)) {
for (j in (i+1):length(nClasse)) {
class_i <- nClasse[i]
class_j <- nClasse[j]
indicess <- which(y.test == class_i | y.test == class_j)
y_paire <- y[indicess]
X_paire <- X[,indicess]
list_y.test[[k]] <- y_paire
list_X.test[[k]] <- X_paire
k <- k + 1
}
}
# we recover the first output to apply the plot
X <- list_X[[1]]
y <- list_y[[1]]
X.test <- list_X.test[[1]]
y.test <- list_y.test[[1]]
tmp <- plotAUC(best.model$score_, y, percent = TRUE); rm(tmp)
# create the roc objects
rocobj.train <- roc(y ~ best.model$score_)
rocobj.test <- roc(y.test ~ best.model.test$score_)
# make the plot
ggroc(list(train = rocobj.train, test = rocobj.test))
# get the population of models scrambled by model size
pop <- modelCollectionToPopulation(res_clf$classifier$models)
printy(pop)
pop.df <- populationToDataFrame(pop)
head(pop.df[,-c(3,4,7,8,14)])
pop.df.melt <- melt(pop.df, id.vars = c("accuracy_","eval.sparsity"))
g.before <- ggplot(data = pop.df.melt, aes(y = accuracy_, x = eval.sparsity)) +
geom_boxplot(notch = FALSE, outlier.shape = " ", position = position_dodge(width=0.9), alpha = 0.3) +
geom_point(aes(color = eval.sparsity), position=position_jitterdodge(dodge.width=0.9), size = 1, alpha = 0.5) +
ylim(c(0,1)) +
xlab("Model parsimony") +
ggtitle("Original population") +
theme_bw() +
theme(legend.position="bottom", legend.direction="horizontal") +
guides(colour="none")
# select the best
fbm <- selectBestPopulation(pop)
printy(fbm)
fbm.df <- populationToDataFrame(fbm)
fbm.df.melt <- melt(fbm.df, id.vars = c("accuracy_","eval.sparsity"))#; head(fbm.df.melt)
g.after <- ggplot(data = fbm.df.melt, aes(y = accuracy_, x = eval.sparsity)) +
geom_boxplot(notch = FALSE, position = position_dodge(width=0.9), alpha = 0.3) +
geom_point(aes(color = eval.sparsity), position=position_jitterdodge(dodge.width=0.9), size = 1, alpha = 0.5) +
ylim(c(0,1)) +
xlab("Model parsimony") +
ggtitle("FBM") +
theme_bw() +
theme(legend.position="bottom", legend.direction="horizontal") +
guides(colour="none")
grid.arrange(g.before, g.after, ncol =2)
fa <- makeFeatureAnnot(pop = fbm,
X = X,
y = y,
clf = clf)
dim(fa$pop.noz)
(g1 <- plotFeatureModelCoeffs(feat.model.coeffs = fa$pop.noz))
(g2 <- plotAbundanceByClass(features = rownames(fa$pop.noz), X = X, y = y))
(g3 <- plotPrevalence(features = rownames(fa$pop.noz), X = X, y = y))
set.seed(123)
yvec <- mc.input$y$Enterotype[match(colnames(mc.input$X), rownames(mc.input$y))]
#Divide the dataset into training and testing
proportion_test <- 0.2
taille_test <- round(proportion_test * ncol(mc.input$X))
indices_test <- sample(1:ncol(mc.input$X), taille_test)
X <- mc.input$X[,-indices_test]
X.test <- mc.input$X[,indices_test]
y <- as.vector(yvec[-indices_test])
y.test <- as.vector(yvec[indices_test])
clf <- sota.rf_ovo(sparsity = c(2:10, 50, 70, 100, 150, 200, 300),
nrow(X),
max.nb.features = 10000,
seed = (1:20),
nCores = 1,
evalToFit = "accuracy_",
objective = "auc",
ntree=500,
experiment.id = "sota_rf_ovo",
experiment.save = "nothing")
printy(clf) #
runit = TRUE
if(runit)
{
res_clf <- fit_OVO(X = X, y = y, clf = clf, cross.validate = TRUE, nfolds = 1); # class(res_clf)
# save results
save(res_clf, clf, file = "res_clf_sota.rda", compression_level = 9)
}
res_clf.dig <- digest(obj = res_clf, penalty = 0.75/100, plot = TRUE)
# get the best model sota.rf_ovo
# get the best model
best.model <- res_clf.dig$best$model
printy(best.model)
best.model.test <- evaluateModel_ovo(mod = best.model, X = X.test, y = y.test, clf = clf, eval.all = TRUE, force.re.evaluation = TRUE, mode = "test")
printy(best.model.test)
library(mcpredomics)
library(mcpredomics)
