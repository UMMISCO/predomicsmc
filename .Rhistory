# Update 'pop_last' with the new list
pop_last <- new_list
}
}
# evaluate the fitting function for all the models of the populaion
# transform to a population of model objects
pop_last.mod <- listOfSparseVecToListOfModels_mc(X, y , clf = clf, v = pop_last,approch = approch)
# evaluate the population
pop.last.eval <- evaluatePopulation_mc(X , y, clf, pop_last.mod, force.re.evaluation = TRUE, eval.all = TRUE, approch=approch, aggregation_ = aggregation_)
# get the evaluation vector
evaluation    <- as.numeric(populationGet_X(element2get = "fit_", toVec = TRUE, na.rm = TRUE)(pop = pop.last.eval))
# get the evaluation
evaluation.ord <- order(abs(evaluation), decreasing = TRUE)
# order by best in front
evaluation <- evaluation[evaluation.ord]
pop_ordered_mod <- pop.last.eval[evaluation.ord] # we gain speed
# get the best individuals (should be the first)
best_individual_index <- which.max(abs(evaluation))
best_individual <- pop_ordered_mod[[best_individual_index]]
# print it out
if(clf$params$verbose)
{
if(isModel(best_individual))
{
try(cat(paste("gen =",i,"\t", printModel_mc(mod = best_individual, method = clf$params$print_ind_method, score = "fit_"),"\n")), silent = TRUE)
}
}
# transform the indexes into models
if(!isPopulation(obj = pop_ordered_mod))
{
pop_ordered_mod <- evaluatePopulation_mc(X, y, clf, pop_ordered_mod, force.re.evaluation = TRUE, approch = approch, aggregation_ = aggregation_,eval.all = TRUE)
}
# keep only models that are unique
pop_ordered_mod <- unique(pop_ordered_mod)
if(!(clf$params$popSaveFile=="NULL"))
{
#pop2Save      <- evaluatePopulation(X, y, clf, pop_ordered_mod, eval.all = TRUE)
pop2Save      <- pop_ordered_mod
savePopulation(pop2Save, paste("generation", i, clf$params$popSaveFile, sep = "_"))
}
# save the whole list of models ordered by fitting score. The best is the first
res[[paste("k",i,sep = "_")]] <- pop_ordered_mod
}
return(res)
}
#' Creates new combinations of features based from a parents.
#' @title evolve_mc
#' @description This function is used in terga1 and is the main engine of the algorithm that allows to cross, mutate and select individuals from one generation to the next (one versus one).
#' @param X: the data matrix with variables in the rows and observations in the columns
#' @param y: the response vector
#' @param clf: the classifier parameter object
#' @param pop: A population (i.e. list) of index vectors
#' @param seed: For reproductibility purpose to fix the random generator number.
#' @return a list population of models, containing parents and children(one versus one)
#' @export
evolve_mc <- function(X, y, clf, pop, seed = NULL, approch="ovo")
{
nClasse <- unique(y)
list_evolved_pop <- list() # List of different combinations of evolved
list_y <- list() # List of different combinations of y
list_X <- list() # List of different combinations of X
listcoeffs <- list() # List of different combinations of coeffs
listX <- list()
listXmin <- list() # List min of X
listXmax <- list() # List max of X
listy <- list()
listcoeffs <- clf$coeffs_
listX <- clf$data$X
listXmin <- clf$data$X.min
listXmax <- clf$data$X.max
listy <- clf$data$y
list_y <- list() #  List of different combinations of y
list_X <- list() #  List of different combinations of X
combi <- generate_combinations_with_factors(y, X, approch = approch)
list_y <- combi$list_y
list_X <- combi$list_X
for (i in 1:length(list_X)) {
clf$coeffs_ <- listcoeffs[[i]]
clf$data$X <- listX[[i]]
clf$data$X.min <- listXmin[[i]]
clf$data$X.max <- listXmax[[i]]
clf$data$y <- listy[[i]]
list_evolved_pop[[i]] <- evolve(X = list_X[[i]], y = list_y[[i]], clf, pop, seed = NULL)
}
evolved_pop <- list_evolved_pop
return(evolved_pop)
}
load("~/Documents/multiclasse_predomics/mcpredomics/vignette/Predomics_aggregation_ova_terbeam_unconstrained_2.rda")
Predomics_aggregation_ova_terbeam_unconstrained_2$crossVal$scores$mean.acc
load("~/Documents/multiclasse_predomics/mcpredomics/vignette/voting_terbeam_unconstrained_2.rda")
voting_terbeam_unconstrained_2$crossVal$scores$mean.acc
knitr::opts_chunk$set(echo = TRUE)
library(mcpredomics)
library(predomics)
library(ggplot2)
library(gridExtra)
library(pROC)
library(reshape2)
library(randomForest)
library(caret)
library(gtools)
library(ggpubr)
library(dplyr)
library(tidyr)
library(tibble)
library(knitr)
library(kableExtra)
library(DT)
library(e1071)
library(glmnet)
clf <- terBeam_mc(sparsity = c(8),
max.nb.features = 1000,
seed = 1,
nCores = 1,
evalToFit = "accuracy_",
objective = "auc",
experiment.id = "terBeam_mc",
experiment.save = "nothing")
printy(clf)
# Charger les packages nécessaires
library(readr)  # Pour lire les fichiers CSV
library(dplyr)  # Pour manipuler les données
library(ggplot2)  # Pour la visualisation
# Charger le fichier
dfs <- load("../data/predomics.inputs.ExperimentHubMulticlass.Rda")
lapply(predomics.inputs, function(x){summary(colSums(x[["X"]]))})
data1 = predomics.inputs$FengQ_2015
df = data1$y.df
df = data1$y.df
y = df$study_condition
X = data1$X
table(y)
runit = TRUE
if(runit)
{
resull2voting <- fit_mc(X = X, y = y, clf = clf,approch="ovo", cross.validate = TRUE,aggregation_ = "voting", nfolds= 10, constrained = FALSE);
save(resull2voting  , clf, file ="resull2voting.rda", compression_level = 9)
}
res_clf.dig <- digestmc(obj = resull2voting, penalty = 0.75/100, plot = TRUE)
# Convert the model collection into a population of models scrambled by model size
pop <- modelCollectionToPopulation(resull2voting$classifier$models)
printy_mc(pop)
# Function to create boxplot for a given data frame
create_boxplot <- function(data, title) {
# Melt the dataframe for ggplot
data.melt <- melt(data, id.vars = c("accuracy_", "eval.sparsity"))
# Create ggplot
plot <- ggplot(data = data.melt, aes(y = accuracy_, x = eval.sparsity)) +
geom_boxplot(notch = FALSE, outlier.shape = NA, position = position_dodge(width = 0.9), alpha = 0.3) +
geom_point(aes(color = eval.sparsity), position = position_jitterdodge(dodge.width = 0.9), size = 1, alpha = 0.5) +
ylim(c(0, 1)) +
xlab("Model Parsimony") +
ggtitle(title) +
theme_bw() +
theme(legend.position = "bottom", legend.direction = "horizontal") +
guides(colour = "none")
return(plot)
}
# Convert the population to a data frame
pop.df <- populationToDataFrame_mc(pop)
# Plotting for the original population (single figure)
pop.dff <- as.data.frame(pop.df[[1]])  # Convert the first submodel to a data frame
g.before <- create_boxplot(pop.dff, title = "Original Population")
#print(g.before)  # Display the plot
# Select the best population models
fbm <- selectBestPopulation(pop)
#printy_mc(fbm)
# Convert the best population models to a data frame
fbm.df <- populationToDataFrame_mc(fbm)
# Plotting for the selected best models (single figure)
fbm.dff <- as.data.frame(fbm.df[[1]])  # Convert the first submodel to a data frame
g.after <- create_boxplot(fbm.dff, title = "FBM")
print(g.after)  # Display the plot
best.model = fbm[[1]]
# get the best model
###best.model = res_clf.dig$best$models$k_7
# Visualize the model information (if needed)
printy_mc(best.model)
# Generate the plots
plots1 <- plotModel_mc(best.model, X, y, sort.features = FALSE, feature.name = TRUE, approch = "ova")
plots2 <- plotModel_mc(best.model, X, y, sort.features = FALSE, feature.name = TRUE, importance = TRUE, approch = "ova")
# Open a PDF device to save the grid of plots
pdf("model_visualization_plots2.pdf", width = 11, height = 8)  # Adjust width and height as needed
# Extract the plots from each list and pass them to `grid.arrange`
grid.arrange(grobs = c(plots1, plots2), ncol = 4)
# Close the PDF device
dev.off()
# Confirmation of the save process
cat("The plots have been saved under the name 'model_visualization_plots2.pdf'.\n")
# get the best model
###best.model = res_clf.dig$best$models$k_7
# Visualize the model information (if needed)
printy_mc(best.model)
# Generate the plots
plots1 <- plotModel_mc(best.model, X, y, sort.features = FALSE, feature.name = TRUE, approch = "ova")
plots2 <- plotModel_mc(best.model, X, y, sort.features = FALSE, feature.name = TRUE, importance = TRUE, approch = "ova")
# Open a PDF device to save the grid of plots
pdf("model_visualization_plots2.pdf", width = 30, height = 18)  # Adjust width and height as needed
# Extract the plots from each list and pass them to `grid.arrange`
grid.arrange(grobs = c(plots1, plots2), ncol = 4)
# Close the PDF device
dev.off()
# Confirmation of the save process
cat("The plots have been saved under the name 'model_visualization_plots2.pdf'.\n")
# get the best model
###best.model = res_clf.dig$best$models$k_7
# Visualize the model information (if needed)
printy_mc(best.model)
# Generate the plots
plots1 <- plotModel_mc(best.model, X, y, sort.features = FALSE, feature.name = TRUE, approch = "ova")
plots2 <- plotModel_mc(best.model, X, y, sort.features = FALSE, feature.name = TRUE, importance = TRUE, approch = "ova")
# Open a PDF device to save the grid of plots
pdf("model_visualization_plots2.pdf", width = 20, height = 15)  # Adjust width and height as needed
# Extract the plots from each list and pass them to `grid.arrange`
grid.arrange(grobs = c(plots1, plots2), ncol = 2)
# Close the PDF device
dev.off()
# Confirmation of the save process
cat("The plots have been saved under the name 'model_visualization_plots2.pdf'.\n")
# get the best model
###best.model = res_clf.dig$best$models$k_7
# Visualize the model information (if needed)
printy_mc(best.model)
# Generate the plots
plots1 <- plotModel_mc(best.model, X, y, sort.features = FALSE, feature.name = TRUE, approch = "ova")
plots2 <- plotModel_mc(best.model, X, y, sort.features = FALSE, feature.name = TRUE, importance = TRUE, approch = "ova")
# Open a PDF device to save the grid of plots
pdf("model_visualization_plots2.pdf", width = 20, height = 15)  # Adjust width and height as needed
# Extract the plots from each list and pass them to `grid.arrange`
grid.arrange(grobs = c(plots1, plots2), ncol = 1)
# Close the PDF device
dev.off()
# Confirmation of the save process
cat("The plots have been saved under the name 'model_visualization_plots2.pdf'.\n")
# get the best model
###best.model = res_clf.dig$best$models$k_7
# Visualize the model information (if needed)
printy_mc(best.model)
# Generate the plots
plots1 <- plotModel_mc(best.model, X, y, sort.features = FALSE, feature.name = TRUE, approch = "ova")
plots2 <- plotModel_mc(best.model, X, y, sort.features = FALSE, feature.name = TRUE, importance = TRUE, approch = "ova")
# Open a PDF device to save the grid of plots
pdf("model_visualization_plots2.pdf", width = 30, height = 25)  # Adjust width and height as needed
# Extract the plots from each list and pass them to `grid.arrange`
grid.arrange(grobs = c(plots1, plots2), ncol = 1)
# Close the PDF device
dev.off()
# Confirmation of the save process
cat("The plots have been saved under the name 'model_visualization_plots2.pdf'.\n")
tmp <- plotAUC_mc(scores = best.model$score_, y = y, percent = TRUE, approch = "ova"); rm(tmp)
tmp <- plotAUC_mc(scores = best.model$score_, y = y, percent = TRUE, approch = "ovo"); rm(tmp)
fa <- makeFeatureAnnot_mc(pop = fbm,
X = X,
y = y,
clf = clf,
approch = "ovo")
plot_distribution <- plotFeatureModelCoeffs_mc(feat.model.coeffs = fa, y, approch = "ovo")
plots_abundance <- plotAbundanceByClass_mc(features = fa, X, y, approch = "ovo")
plots_prevalence <- plotPrevalence_mc(features = fa, X = X, y = y, approch = "ovo")
fa <- makeFeatureAnnot_mc(pop = fbm,
X = X,
y = y,
clf = clf,
approch = "ovo")
plot_distribution <- plotFeatureModelCoeffs_mc(feat.model.coeffs = fa, y, approch = "ovo")
plots_abundance <- plotAbundanceByClass_mc(features = fa, X, y, approch = "ovo")
plots_prevalence <- plotPrevalence_mc(features = fa, X = X, y = y, approch = "ovo")
feat1.import <- mergeMeltImportanceCV_mc(list.results = list(terBeam = resull2voting),
filter.cv.prev = 0,
min.kfold.nb = FALSE,
learner.grep.pattern = "*",
#nb.top.features = 50,
feature.selection = fa,
scaled.importance = TRUE,
make.plot = TRUE,
cv.prevalence = FALSE)
feat2.import <- mergeMeltImportanceCV_mc(list.results = list(terBeam = resull2voting),
filter.cv.prev = 0,
min.kfold.nb = FALSE,
learner.grep.pattern = "*",
nb.top.features = 148,
#feature.selection = rownames(fa$pop.noz),
scaled.importance = TRUE,
make.plot = TRUE,
cv.prevalence = FALSE)
feat1.import <- mergeMeltImportanceCV_mc(list.results = list(terBeam = resull2voting),
filter.cv.prev = 0,
min.kfold.nb = FALSE,
learner.grep.pattern = "*",
#nb.top.features = 50,
feature.selection = fa,
scaled.importance = TRUE,
make.plot = TRUE,
cv.prevalence = FALSE)
feat2.import <- mergeMeltImportanceCV_mc(list.results = list(terBeam = resull2voting),
filter.cv.prev = 0,
min.kfold.nb = FALSE,
learner.grep.pattern = "*",
nb.top.features = 148,
#feature.selection = rownames(fa$pop.noz),
scaled.importance = TRUE,
make.plot = TRUE,
cv.prevalence = FALSE)
feat1.import <- mergeMeltImportanceCV_mc(list.results = list(terBeam = resull2voting),
filter.cv.prev = 0,
min.kfold.nb = FALSE,
learner.grep.pattern = "*",
#nb.top.features = 50,
feature.selection = fa,
scaled.importance = TRUE,
make.plot = TRUE,
cv.prevalence = FALSE)
feat2.import <- mergeMeltImportanceCV_mc(list.results = list(terBeam = resull2voting),
filter.cv.prev = 0,
min.kfold.nb = FALSE,
learner.grep.pattern = "*",
nb.top.features = 148,
#feature.selection = rownames(fa$pop.noz),
scaled.importance = TRUE,
make.plot = TRUE,
cv.prevalence = FALSE)
feat1.import <- mergeMeltImportanceCV_mc(list.results = list(terBeam = resull2voting),
filter.cv.prev = 0,
min.kfold.nb = FALSE,
learner.grep.pattern = "*",
#nb.top.features = 50,
feature.selection = fa,
scaled.importance = TRUE,
make.plot = TRUE,
cv.prevalence = FALSE)
feat2.import <- mergeMeltImportanceCV_mc(list.results = list(terBeam = resull2voting),
filter.cv.prev = 0,
min.kfold.nb = FALSE,
learner.grep.pattern = "*",
nb.top.features = 148,
#feature.selection = rownames(fa$pop.noz),
scaled.importance = TRUE,
make.plot = TRUE,
cv.prevalence = FALSE)
feat1.import <- mergeMeltImportanceCV_mc(list.results = list(terBeam = resull2voting),
filter.cv.prev = 0,
min.kfold.nb = FALSE,
learner.grep.pattern = "*",
#nb.top.features = 50,
feature.selection = fa,
scaled.importance = TRUE,
make.plot = TRUE,
cv.prevalence = FALSE)
feat2.import <- mergeMeltImportanceCV_mc(list.results = list(terBeam = resull2voting),
filter.cv.prev = 0,
min.kfold.nb = FALSE,
learner.grep.pattern = "*",
nb.top.features = 148,
#feature.selection = rownames(fa$pop.noz),
scaled.importance = TRUE,
make.plot = TRUE,
cv.prevalence = FALSE)
feat1.import <- mergeMeltImportanceCV_mc(list.results = list(terBeam = resull2voting),
filter.cv.prev = 0,
min.kfold.nb = FALSE,
learner.grep.pattern = "*",
#nb.top.features = 50,
feature.selection = fa,
scaled.importance = TRUE,
make.plot = TRUE,
cv.prevalence = FALSE)
feat2.import <- mergeMeltImportanceCV_mc(list.results = list(terBeam = resull2voting),
filter.cv.prev = 0,
min.kfold.nb = FALSE,
learner.grep.pattern = "*",
nb.top.features = 148,
#feature.selection = rownames(fa$pop.noz),
scaled.importance = TRUE,
make.plot = TRUE,
cv.prevalence = FALSE)
clf <- terBeam_mc(sparsity = c(2,3,4,5,6,7,8,9,10),
max.nb.features = 1000,
seed = 1,
nCores = 1,
evalToFit = "accuracy_",
objective = "auc",
experiment.id = "terBeam_mc",
experiment.save = "nothing")
printy(clf)
# Charger le fichier
dfs <- load("../data/predomics.inputs.ExperimentHubMulticlass.Rda")
lapply(predomics.inputs, function(x){summary(colSums(x[["X"]]))})
data1 = predomics.inputs$ZellerG_2014
df = data1$y.df
y = df$study_condition
X = data1$X
table(y)
runit = TRUE
if(runit)
{
resull3provo <- fit_mc(X = X, y = y, clf = clf,approch="ovo", cross.validate = TRUE,aggregation_ = "Predomics_aggregation_ovo", nfolds= 5, constrained = FALSE);
save(resull3provo  , clf, file ="resull3provo.rda", compression_level = 9)
}
resull3provo$crossVal$scores$mean.acc
# Convert the model collection into a population of models scrambled by model size
pop <- modelCollectionToPopulation(resull3provo$classifier$models)
printy_mc(pop)
# Function to create boxplot for a given data frame
create_boxplot <- function(data, title) {
# Melt the dataframe for ggplot
data.melt <- melt(data, id.vars = c("accuracy_", "eval.sparsity"))
# Create ggplot
plot <- ggplot(data = data.melt, aes(y = accuracy_, x = eval.sparsity)) +
geom_boxplot(notch = FALSE, outlier.shape = NA, position = position_dodge(width = 0.9), alpha = 0.3) +
geom_point(aes(color = eval.sparsity), position = position_jitterdodge(dodge.width = 0.9), size = 1, alpha = 0.5) +
ylim(c(0, 1)) +
xlab("Model Parsimony") +
ggtitle(title) +
theme_bw() +
theme(legend.position = "bottom", legend.direction = "horizontal") +
guides(colour = "none")
return(plot)
}
# Convert the population to a data frame
pop.df <- populationToDataFrame_mc(pop)
# Plotting for the original population (single figure)
pop.dff <- as.data.frame(pop.df[[1]])  # Convert the first submodel to a data frame
g.before <- create_boxplot(pop.dff, title = "Original Population")
#print(g.before)  # Display the plot
# Select the best population models
fbm <- selectBestPopulation(pop)
#printy_mc(fbm)
# Convert the best population models to a data frame
fbm.df <- populationToDataFrame_mc(fbm)
# Plotting for the selected best models (single figure)
fbm.dff <- as.data.frame(fbm.df[[1]])  # Convert the first submodel to a data frame
g.after <- create_boxplot(fbm.dff, title = "FBM")
print(g.after)  # Display the plot
fa <- makeFeatureAnnot_mc(pop = fbm,
X = X,
y = y,
clf = clf,
approch = "ovo")
plot_distribution <- plotFeatureModelCoeffs_mc(feat.model.coeffs = fa, y, approch = "ovo")
plots_abundance <- plotAbundanceByClass_mc(features = fa, X, y, approch = "ovo")
plots_prevalence <- plotPrevalence_mc(features = fa, X = X, y = y, approch = "ovo")
feat1.import <- mergeMeltImportanceCV_mc(list.results = list(terBeam = resull3provo),
filter.cv.prev = 0,
min.kfold.nb = FALSE,
learner.grep.pattern = "*",
#nb.top.features = 50,
feature.selection = fa,
scaled.importance = TRUE,
make.plot = TRUE,
cv.prevalence = FALSE)
feat2.import <- mergeMeltImportanceCV_mc(list.results = list(terBeam = resull3provo),
filter.cv.prev = 0,
min.kfold.nb = FALSE,
learner.grep.pattern = "*",
nb.top.features = 148,
#feature.selection = rownames(fa$pop.noz),
scaled.importance = TRUE,
make.plot = TRUE,
cv.prevalence = FALSE)
feat1.import <- mergeMeltImportanceCV_mc(list.results = list(terBeam = resull3provo),
filter.cv.prev = 0,
min.kfold.nb = FALSE,
learner.grep.pattern = "*",
#nb.top.features = 50,
feature.selection = fa,
scaled.importance = TRUE,
make.plot = TRUE,
cv.prevalence = FALSE)
feat2.import <- mergeMeltImportanceCV_mc(list.results = list(terBeam = resull3provo),
filter.cv.prev = 0,
min.kfold.nb = FALSE,
learner.grep.pattern = "*",
nb.top.features = 148,
#feature.selection = rownames(fa$pop.noz),
scaled.importance = TRUE,
make.plot = TRUE,
cv.prevalence = FALSE)
feat1.import <- mergeMeltImportanceCV_mc(list.results = list(terBeam = resull3provo),
filter.cv.prev = 0,
min.kfold.nb = FALSE,
learner.grep.pattern = "*",
#nb.top.features = 50,
feature.selection = fa,
scaled.importance = TRUE,
make.plot = TRUE,
cv.prevalence = FALSE)
feat2.import <- mergeMeltImportanceCV_mc(list.results = list(terBeam = resull3provo),
filter.cv.prev = 0,
min.kfold.nb = FALSE,
learner.grep.pattern = "*",
nb.top.features = 148,
#feature.selection = rownames(fa$pop.noz),
scaled.importance = TRUE,
make.plot = TRUE,
cv.prevalence = FALSE)
model.best = fbm[[1]]
best.model = model.best
# get the best model
###best.model = res_clf.dig$best$models$k_7
# Visualize the model information (if needed)
printy_mc(best.model)
# Generate the plots
plots1 <- plotModel_mc(best.model, X, y, sort.features = FALSE, feature.name = TRUE, approch = "ova")
plots2 <- plotModel_mc(best.model, X, y, sort.features = FALSE, feature.name = TRUE, importance = TRUE, approch = "ova")
# Open a PDF device to save the grid of plots
pdf("model_visualization_plots2.pdf", width = 30, height = 25)  # Adjust width and height as needed
# Extract the plots from each list and pass them to `grid.arrange`
grid.arrange(grobs = c(plots1, plots2), ncol = 1)
# Close the PDF device
dev.off()
# Confirmation of the save process
cat("The plots have been saved under the name 'model_visualization_plots2.pdf'.\n")
