# Create ggplot
plot <- ggplot(data = data.melt, aes(y = accuracy_, x = eval.sparsity)) +
geom_boxplot(notch = FALSE, outlier.shape = NA, position = position_dodge(width = 0.9), alpha = 0.3) +
geom_point(aes(color = eval.sparsity), position = position_jitterdodge(dodge.width = 0.9), size = 1, alpha = 0.5) +
ylim(c(0, 1)) +
xlab("Model Parsimony") +
ggtitle(title) +
theme_bw() +
theme(legend.position = "bottom", legend.direction = "horizontal") +
guides(colour = "none")
return(plot)
}
# Convert the population to a data frame
pop.df <- populationToDataFrame_mc(pop)
# Plotting for the original population (single figure)
pop.dff <- as.data.frame(pop.df[[1]])  # Convert the first submodel to a data frame
g.before <- create_boxplot(pop.dff, title = "Original Population")
#print(g.before)  # Display the plot
# Select the best population models
fbm <- selectBestPopulation(pop)
#printy_mc(fbm)
# Convert the best population models to a data frame
fbm.df <- populationToDataFrame_mc(fbm)
# Plotting for the selected best models (single figure)
fbm.dff <- as.data.frame(fbm.df[[1]])  # Convert the first submodel to a data frame
g.after <- create_boxplot(fbm.dff, title = "FBM")
print(g.after)  # Display the plot
g <- list()
fa <- makeFeatureAnnot_mc(pop = fbm,
X = X,
y = y,
clf = clf,
approch = "ovo")
plot_distribution2 <- plotFeatureModelCoeffs_mc(feat.model.coeffs = fa, y, approch = "OVO")
gridExtra::grid.arrange(grobs = plot_distribution2, ncol = 3)
(g2 <- plotAbundanceByClass_mc(features = fa, X = X, y = y, approch = "OVO"))
gridExtra::grid.arrange(grobs = g2, ncol = 3)
(g3 <- plotPrevalence_mc(features = fa, X = X, y = y , approch = "OVO"))
gridExtra::grid.arrange(grobs = g3, ncol = 3)  # Ici, ncol spÃ©cifie 6 colonnes
knitr::opts_chunk$set(echo = TRUE)
library(mcpredomics)
library(predomics)
library(ggplot2)
library(gridExtra)
library(pROC)
library(reshape2)
library(randomForest)
library(caret)
library(gtools)
library(ggpubr)
library(dplyr)
library(tidyr)
library(tibble)
library(knitr)
library(kableExtra)
library(DT)
library(e1071)
library(glmnet)
chemin_du_dataset <- system.file("data", "mc.input.Rda", package = "mcpredomics")
load(chemin_du_dataset)
set.seed(123)
yvec <- mc.input$y$Enterotype[match(colnames(mc.input$X), rownames(mc.input$y))]
indices_tries <- order(yvec)
yvec_trie <- yvec[indices_tries]
X_general  <- mc.input$X[,indices_tries]
# Create an index vector for data partitioning
X_general <- X_general[rowSums(X_general)!=0,]; dim(X_general) # filter out variables with only zero values
X_general <- filterNoSignal(X = X_general, side = 1, threshold = "auto", verbose = FALSE); dim(X_general)
set.seed(42)
y = as.vector(yvec_trie)
X = X_general
# Number of desired samples in each class
nombre_echantillons_par_classe <- min(table(y))
# Function to balance the classes
equilibrer_classes <- function(y, X, nombre_echantillons_par_classe,seed =123) {
classes <- unique(y)
indices_equilibres <- integer(0)
for (classe in classes) {
indices_classe <- which(y == classe)
set.seed(seed)
indices_equilibres <- c(indices_equilibres, sample(indices_classe, nombre_echantillons_par_classe))
}
return(list(y = y[indices_equilibres], X = X[, indices_equilibres]))
}
donnees_equilibrees <- equilibrer_classes(y, X, nombre_echantillons_par_classe)
y_equilibre <- donnees_equilibrees$y
X_equilibre <- donnees_equilibrees$X
# Verify the distribution after balancing
set.seed(42)
indices_division <- createDataPartition(y_equilibre, p = 0.8, list = FALSE)
# Split yvec_trie into 80% train and 20% test
y <- as.vector(y_equilibre[indices_division])
y.test <- as.vector(y_equilibre[-indices_division])
X <- X_equilibre[,indices_division]
X.test <- X_equilibre[,-indices_division]
table(y)
table(y.test)
dim(X)
dim(X.test)
clf <- terBeam_mc(sparsity = c(2,3,4),
max.nb.features = 1000,
seed = 1,
nCores = 1,
evalToFit = "accuracy_",
objective = "auc",
experiment.id = "terBeam_mc",
experiment.save = "nothing")
printy(clf)
runit = TRUE
if(runit)
{
res_clf <- fit_mc(X = X, y = y, clf = clf,approch="ova", cross.validate = TRUE,aggregation_ = "Predomics_aggregation_ova", nfolds= 10);
save(res_clf , clf, file ="res_clf.rda", compression_level = 9)
}
# ... Database X is not a matrix! Converting ...
# ... Classification mode, computing factor(y) for speedup and robustness
# ... Loading feature correlation for speedup
# ... Correlation file loaded
# ... Storing data in the classifier object for speedup
# ... Computing ternary coefficients for speedup
# ... One seed found, setting by default
# ... Running the classifier terga2 with a single CPU
# ... Second and faster version of terga fitting based on Genetic Algorithm heuristics ...
# ... Cross validation mode
# ... Starting cross validation not in parallel
# ....................................................................................................
# ....................................................................................................
# ....................................................................................................
# ....................................................................................................
# ....................................................................................................
# ....................................................................................................
# ....................................................................................................
# ....................................................................................................
# ....................................................................................................
# ....................................................................................................
# ....................................................................................................
# ... Learning process is finished succesfuly
# ... Thank you for using Predomics. Don't forget to digest the results now.
#
# [1] "experiment" "predomics"
load("Unique_Predomics_aggregation_ova.rda")
load("Unique_Predomics_aggregation_ovo.rda")
load("Unique_votingAggregation.rda")
load("Unique_maximizationAggregation.rda")
load("Unique_rankingAggregation.rda")
load("Unique_weightedAggregation.rda")
load("Multi_Predomics_aggregation_ova.rda")
#load("Multi_maximizationAggregation.rda")
#load("Multi_rankingAggregation.rda")
#load("Multi_weightedAggregation.rda")
#load("Multi_votingAggregation.rda")
#load("Multi_Predomics_aggregation_ovo.rda")
load("res_clf.rda")
# Function for transforming model data
transform_model_data <- function(model_data, model_name) {
testlist <- model_data$crossVal$scores[grep("generalization|empirical", names(model_data$crossVal$scores))]
testlist2 <- list()
for(i in names(testlist)) {
idf <- testlist[[i]]
if(unique(colSums(is.na(idf))) != nrow(idf)) {
idf$sparsity <- rownames(idf)
idf <- melt(idf)
idf$source <- i
testlist2[[i]] <- idf
}
}
testlist2.df <- do.call("rbind", testlist2)
testlist2.df$emp_gen <- gsub("\\..*$", "", testlist2.df$source)
testlist2.df$metric <- gsub("^.*\\.", "", testlist2.df$source)
testlist2.df$model <- model_name
testlist2.df <- testlist2.df[is.finite(testlist2.df$value), ]
# Filter only empirical scores
testlist2.df <- testlist2.df[testlist2.df$emp_gen == "empirical" & testlist2.df$metric == "acc", ]
return(testlist2.df)
}
# Calling up the function for each model
df1 <- transform_model_data(Unique_maximizationAggregation, "Unique_maximizationAggregation")
df2 <- transform_model_data(Unique_Predomics_aggregation_ova, "Unique_Predomics_aggregation_ova")
df3 <- transform_model_data(Unique_rankingAggregation, "Unique_rankingAggregation")
df4 <- transform_model_data(Unique_weightedAggregation, "Unique_weightedAggregation")
df5 <- transform_model_data(Unique_votingAggregation, "Unique_votingAggregation")
df6 <- transform_model_data(Unique_votingAggregation, "Unique_Predomics_aggregation_ovo")
alldf <- rbind(df1, df2, df3, df4, df5, df6)
# Calculate the mean and standard deviation for each sparsity
summary_df <- alldf %>%
filter(grepl("k_\\d", sparsity)) %>%
group_by(sparsity, model) %>%
summarise(mean_value = mean(value, na.rm = TRUE),
sd_value = sd(value, na.rm = TRUE),
.groups = 'drop')
# Creation of a graphic with 6 facets
ggplot(summary_df, aes(x = sparsity, y = mean_value, color = sparsity)) +
geom_point(size = 4) +
geom_errorbar(aes(ymin = mean_value - sd_value, ymax = mean_value + sd_value), width = 0.2) +
facet_wrap(~ model, scales = "free") +
geom_text(aes(label = round(sd_value, 2), y = mean_value + sd_value + 0.02),
position = position_dodge(0.2), vjust = -0.5) +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
labs(y = "Mean Empirical Accuracy",
title = "Cross-validation Empirical Performance of Our Experiments") +
theme_minimal()
# Function for transforming model data
transform_model_data <- function(model_data, model_name) {
testlist <- model_data$crossVal$scores[grep("generalization|empirical", names(model_data$crossVal$scores))]
testlist2 <- list()
for(i in names(testlist)) {
idf <- testlist[[i]]
if(unique(colSums(is.na(idf))) != nrow(idf)) {
idf$sparsity <- rownames(idf)
idf <- melt(idf)
idf$source <- i
testlist2[[i]] <- idf
}
}
testlist2.df <- do.call("rbind", testlist2)
testlist2.df$emp_gen <- gsub("\\..*$", "", testlist2.df$source)
testlist2.df$metric <- gsub("^.*\\.", "", testlist2.df$source)
testlist2.df$model <- model_name
testlist2.df <- testlist2.df[is.finite(testlist2.df$value), ]
# Filter only empirical scores
testlist2.df <- testlist2.df[testlist2.df$emp_gen == "generalization" & testlist2.df$metric == "acc", ]
return(testlist2.df)
}
# Calling up the function for each model
df1 <- transform_model_data(Unique_maximizationAggregation, "Unique_maximizationAggregation")
df2 <- transform_model_data(Unique_Predomics_aggregation_ova, "Unique_Predomics_aggregation_ova")
df3 <- transform_model_data(Unique_rankingAggregation, "Unique_rankingAggregation")
df4 <- transform_model_data(Unique_weightedAggregation, "Unique_weightedAggregation")
df5 <- transform_model_data(Unique_votingAggregation, "Unique_votingAggregation")
df6 <- transform_model_data(Unique_votingAggregation, "Unique_Predomics_aggregation_ovo")
alldf <- rbind(df1, df2, df3, df4, df5, df6)
# Calculate the mean and standard deviation for each sparsity
summary_df <- alldf %>%
filter(grepl("k_\\d", sparsity)) %>%  # Filtrer pour les sparsities k2, k3, k4
group_by(sparsity, model) %>%
summarise(mean_value = mean(value, na.rm = TRUE),
sd_value = sd(value, na.rm = TRUE),
.groups = 'drop')
# Creation of a graphic with 6 facets
ggplot(summary_df, aes(x = sparsity, y = mean_value, color = sparsity)) +
geom_point(size = 4) +
geom_errorbar(aes(ymin = mean_value - sd_value, ymax = mean_value + sd_value), width = 0.2) +
facet_wrap(~ model, scales = "free") +
geom_text(aes(label = round(sd_value, 2), y = mean_value + sd_value + 0.02),
position = position_dodge(0.2), vjust = -0.5) +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
labs(y = "Mean Accuracy",
title = "Cross-validation Generalization Performance of Our Experiments") +
theme_minimal()
res_clf.dig <- digestmc(obj = Unique_Predomics_aggregation_ova, penalty = 0.75/100, plot = TRUE)
# get the best model
best.model <- res_clf.dig$best$model
printy_mc(best.model)
plots1 <- plotModel_mc(best.model, X, y, sort.features = FALSE, feature.name = TRUE, approch = "ova")
plots2 <- plotModel_mc(best.model, X, y, sort.features = FALSE, feature.name = TRUE, importance = TRUE, approch = "ova")
# Extract the plots from each list and pass them to `grid.arrange
grid.arrange(grobs = c(plots1, plots2), ncol = 4)
clf <- regenerate_clf(clf, X, y, approch = "ova")
best.model.test <- evaluateModel_mc(
mod = best.model,
X = X.test,
y = y.test,
clf = clf,
eval.all = TRUE,
force.re.evaluation = TRUE,
approch = "ova",
aggregation_ = "Predomics_aggregation_ova",
mode = "test"
)
printy_mc(best.model.test)
approch = "OVA"
tmp <- plotAUC_mc(best.model$score_, y, percent = TRUE, approch = "ova"); rm(tmp)
# Create ROC objects for the training set
roc_objects_train <- lapply(seq_along(best.model$score_), function(i) {
roc(response = y, predictor = best.model$score_[[i]])
})
# Create ROC objects for the test set
roc_objects_test <- lapply(seq_along(best.model.test$score_), function(i) {
roc(response = y.test, predictor = best.model.test$score_[[i]])
})
# Define class combinations based on the approach (OVO or OVA)
classes <- unique(y)
if (approch == "OVO") {
combinations <- combn(classes, 2, function(x) paste0(x[1], "_vs_", x[2]))
} else if (approch == "OVA") {
combinations <- paste0(classes, "_vs_ALL")
} else {
stop("Invalid approach: choose 'ova' or 'ovo'")
}
# Assign labels and combine ROC objects for the training set
roc_objects_train <- lapply(seq_along(roc_objects_train), function(i) {
roc_obj <- roc_objects_train[[i]]
roc_obj$dataset <- "Train"
roc_obj$submodel <- combinations[i]
return(roc_obj)
})
# Assign labels and combine ROC objects for the test set
roc_objects_test <- lapply(seq_along(roc_objects_test), function(i) {
roc_obj <- roc_objects_test[[i]]
roc_obj$dataset <- "Test"
roc_obj$submodel <- combinations[i]
return(roc_obj)
})
# Combine ROC objects into a single list
all_roc_objects <- c(roc_objects_train, roc_objects_test)
# Convert to a format compatible with ggplot
roc_df <- do.call(rbind, lapply(all_roc_objects, function(roc_obj) {
data.frame(
FPR = 1 - roc_obj$specificities,  # False Positive Rate
TPR = roc_obj$sensitivities,       # True Positive Rate
Combination = roc_obj$submodel,    # Use the combination instead of "Submodel"
Dataset = roc_obj$dataset
)
}))
# Plot ROC curves using ggplot
ggplot(roc_df, aes(x = FPR, y = TPR, color = Dataset)) +
geom_line() +
facet_wrap(~ Combination, scales = "free", labeller = label_both) +  # Use "Combination" here
labs(title = "ROC Curves", x = "False Positive Rate", y = "True Positive Rate") +
theme_minimal() +
theme(legend.position = "bottom")
# Convert the model collection into a population of models scrambled by model size
pop <- modelCollectionToPopulation(Unique_Predomics_aggregation_ova$classifier$models)
printy_mc(pop)
# Function to create boxplot for a given data frame
create_boxplot <- function(data, title) {
# Melt the dataframe for ggplot
data.melt <- melt(data, id.vars = c("accuracy_", "eval.sparsity"))
# Create ggplot
plot <- ggplot(data = data.melt, aes(y = accuracy_, x = eval.sparsity)) +
geom_boxplot(notch = FALSE, outlier.shape = NA, position = position_dodge(width = 0.9), alpha = 0.3) +
geom_point(aes(color = eval.sparsity), position = position_jitterdodge(dodge.width = 0.9), size = 1, alpha = 0.5) +
ylim(c(0, 1)) +
xlab("Model Parsimony") +
ggtitle(title) +
theme_bw() +
theme(legend.position = "bottom", legend.direction = "horizontal") +
guides(colour = "none")
return(plot)
}
# Convert the population to a data frame
pop.df <- populationToDataFrame_mc(pop)
# Plotting for the original population (single figure)
pop.dff <- as.data.frame(pop.df[[1]])  # Convert the first submodel to a data frame
g.before <- create_boxplot(pop.dff, title = "Original Population")
#print(g.before)  # Display the plot
# Select the best population models
fbm <- selectBestPopulation(pop)
#printy_mc(fbm)
# Convert the best population models to a data frame
fbm.df <- populationToDataFrame_mc(fbm)
# Plotting for the selected best models (single figure)
fbm.dff <- as.data.frame(fbm.df[[1]])  # Convert the first submodel to a data frame
g.after <- create_boxplot(fbm.dff, title = "FBM")
print(g.after)  # Display the plot
fa <- makeFeatureAnnot_mc(pop = fbm,
X = X,
y = y,
clf = clf,
approch = "ova")
fa <- makeFeatureAnnot_mc(pop = fbm,
X = X,
y = y,
clf = clf,
approch = "ova")
plot_distribution <- plotFeatureModelCoeffs_mc(feat.model.coeffs = fa, y, approch = "OVA")
gridExtra::grid.arrange(grobs = plot_distribution, ncol = 4)
plots_abundance <- plotAbundanceByClass_mc(features = fa, X, y, approch = "OVA")
# Pour afficher tous les graphiques dans une grille
gridExtra::grid.arrange(grobs = plots_abundance, ncol = 4)
plots_abundance <- plotAbundanceByClass_mc(features = fa, X, y, approch = "OVA")
# Pour afficher tous les graphiques dans une grille
gridExtra::grid.arrange(grobs = plots_abundance, ncol = 4)
plots_prevalence <- plotPrevalence_mc(features = fa, X = X, y = y, approch = "OVA")
# Pour afficher tous les graphiques dans une grille
gridExtra::grid.arrange(grobs = plots_prevalence, ncol = 4)
res_clf.dig_ovo <- digestmc(obj = Unique_votingAggregation , penalty = 0.75/100, plot = TRUE)
# get the best model
best.model_ovo <- res_clf.dig_ovo$best$model
printy_mc(best.model_ovo)
plots11 <- plotModel_mc(best.model_ovo, X, y, sort.features = FALSE, feature.name = TRUE, approch = "ovo")
plots22 <- plotModel_mc(best.model_ovo, X, y, sort.features = FALSE, feature.name = TRUE, importance = TRUE, approch = "ovo")
# Extract the plots from each list and pass them to `grid.arrange
grid.arrange(grobs = c(plots11, plots22), ncol = 6)
clf <- regenerate_clf(clf, X, y, approch = "ovo")
best.model.test_ovo <- evaluateModel_mc(
mod = best.model_ovo,
X = X.test,
y = y.test,
clf = clf,
eval.all = TRUE,
force.re.evaluation = TRUE,
approch = "ovo",
aggregation_ = "votingAggregation",
mode = "test"
)
printy_mc(best.model.test_ovo)
# get the best model
best.model_ovo <- res_clf.dig_ovo$best$model
printy_mc(best.model_ovo)
plots11 <- plotModel_mc(best.model_ovo, X, y, sort.features = FALSE, feature.name = TRUE, approch = "ovo")
plots22 <- plotModel_mc(best.model_ovo, X, y, sort.features = FALSE, feature.name = TRUE, importance = TRUE, approch = "ovo")
# Extract the plots from each list and pass them to `grid.arrange
grid.arrange(grobs = c(plots11, plots22), ncol = 6)
clf <- regenerate_clf(clf, X, y, approch = "ovo")
best.model.test_ovo <- evaluateModel_mc(
mod = best.model_ovo,
X = X.test,
y = y.test,
clf = clf,
eval.all = TRUE,
force.re.evaluation = TRUE,
approch = "ovo",
aggregation_ = "votingAggregation",
mode = "test"
)
printy_mc(best.model.test_ovo)
tmp1 <- plotAUC_mc(best.model_ovo$score_, y, percent = TRUE, approch = "OVO"); rm(tmp)
# Create ROC objects for the training set
approch = "OVO"
roc_objects_train1 <- lapply(seq_along(best.model_ovo$score_), function(i) {
roc(response = y, predictor = best.model_ovo$score_[[i]])
})
# Create ROC objects for the test set
roc_objects_test1 <- lapply(seq_along(best.model.test_ovo$score_), function(i) {
roc(response = y.test, predictor = best.model.test_ovo$score_[[i]])
})
# Define class combinations based on the OVO approach
classes <- unique(y)
if (approch == "OVO") {
combinations <- combn(classes, 2, function(x) paste0(x[1], "_vs_", x[2]), simplify = TRUE)
} else if (approch == "OVA") {
combinations <- paste0(classes, "_vs_ALL")
} else {
stop("Invalid approach: choose 'ova' or 'ovo'")
}
# Assign labels and combine ROC objects for the training set
roc_objects_train1 <- lapply(seq_along(roc_objects_train1), function(i) {
roc_obj1 <- roc_objects_train1[[i]]
roc_obj1$dataset <- "Train"
roc_obj1$submodel <- combinations[i]  # Use the correct combination for OVO
return(roc_obj1)
})
# Assign labels and combine ROC objects for the test set
roc_objects_test1 <- lapply(seq_along(roc_objects_test1), function(i) {
roc_obj1 <- roc_objects_test1[[i]]
roc_obj1$dataset <- "Test"
roc_obj1$submodel <- combinations[i]  # Use the correct combination for OVO
return(roc_obj1)
})
# Combine ROC objects into a single list
all_roc_objects1 <- c(roc_objects_train1, roc_objects_test1)
# Convert to a format compatible with ggplot
roc_df1 <- do.call(rbind, lapply(all_roc_objects1, function(roc_obj1) {
data.frame(
FPR = 1 - roc_obj1$specificities,  # False Positive Rate
TPR = roc_obj1$sensitivities,       # True Positive Rate
Combination = roc_obj1$submodel,    # Use the combination instead of "Submodel"
Dataset = roc_obj1$dataset
)
}))
# Plot ROC curves using ggplot
ggplot(roc_df1, aes(x = FPR, y = TPR, color = Dataset)) +
geom_line() +
facet_wrap(~ Combination, scales = "free", labeller = label_both) +  # Use "Combination" here
labs(title = "ROC Curves", x = "False Positive Rate", y = "True Positive Rate") +
theme_minimal() +
theme(legend.position = "bottom")
# Convert the model collection into a population of models scrambled by model size
pop <- modelCollectionToPopulation(Unique_votingAggregation$classifier$models)
printy_mc(pop)
# Function to create boxplot for a given data frame
create_boxplot <- function(data, title) {
# Melt the dataframe for ggplot
data.melt <- melt(data, id.vars = c("accuracy_", "eval.sparsity"))
# Create ggplot
plot <- ggplot(data = data.melt, aes(y = accuracy_, x = eval.sparsity)) +
geom_boxplot(notch = FALSE, outlier.shape = NA, position = position_dodge(width = 0.9), alpha = 0.3) +
geom_point(aes(color = eval.sparsity), position = position_jitterdodge(dodge.width = 0.9), size = 1, alpha = 0.5) +
ylim(c(0, 1)) +
xlab("Model Parsimony") +
ggtitle(title) +
theme_bw() +
theme(legend.position = "bottom", legend.direction = "horizontal") +
guides(colour = "none")
return(plot)
}
# Convert the population to a data frame
pop.df <- populationToDataFrame_mc(pop)
# Plotting for the original population (single figure)
pop.dff <- as.data.frame(pop.df[[1]])  # Convert the first submodel to a data frame
g.before <- create_boxplot(pop.dff, title = "Original Population")
#print(g.before)  # Display the plot
# Select the best population models
fbm <- selectBestPopulation(pop)
#printy_mc(fbm)
# Convert the best population models to a data frame
fbm.df <- populationToDataFrame_mc(fbm)
# Plotting for the selected best models (single figure)
fbm.dff <- as.data.frame(fbm.df[[1]])  # Convert the first submodel to a data frame
g.after <- create_boxplot(fbm.dff, title = "FBM")
print(g.after)  # Display the plot
g <- list()
fa <- makeFeatureAnnot_mc(pop = fbm,
X = X,
y = y,
clf = clf,
approch = "ovo")
plot_distribution2 <- plotFeatureModelCoeffs_mc(feat.model.coeffs = fa, y, approch = "OVO")
gridExtra::grid.arrange(grobs = plot_distribution2, ncol = 3)
(g2 <- plotAbundanceByClass_mc(features = fa, X = X, y = y, approch = "OVO"))
gridExtra::grid.arrange(grobs = g2, ncol = 3)
