---
title: "My Vignette"
author: "Fabien KAMBU MBUANGI"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{My Vignette}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
if (!requireNamespace("pROC", quietly = TRUE)) knitr::knit_exit()
```

# The mcpredomics package is a supervised learning method for interpretable
# multiclass classification of metagenomic data. This method is derived 
# from one of the genetic algorithm-based heuristics in the predomics package.
# More details: https://github.com/predomics/predomicspkg

# Installation Instructions

## Step 1: Install dependencies
install.packages(c("doSNOW", "foreach", "snow", "doRNG", "gtools",
                   "glmnet", "pROC", "viridis", "kernlab", "randomForest"))

# Ensure BiocManager is installed
if (!requireNamespace("BiocManager", quietly = TRUE)) {
  install.packages("BiocManager")
}

# Install BioQC (a Bioconductor package)
BiocManager::install("BioQC")

# Optionally install additional packages
install.packages(c("testthat", "roxygen2", "predomics", "mcpredomics"))



# Introduction

The mcpredomics package is designed to extend predomics, which was initially developed for binary classification, in order to enable multiclass classification of the gut microbiome.

# Visualization Functions

The package includes a variety of general-purpose visualization functions to explore models, their performance metrics, and the underlying populations. These functions allow users to gain valuable insights into their data and models with ease.

The implemented functions include:

* Majority_Voting_with_Tie_Breaking
* Majority_Voting_with_Tie_Breaking_ova
* computeCardEnrichment_mc
* decompose_y_levels
* digestmc
* evaluateAccuracy
* evaluateAccuracy_mc
* evaluateFeatureImportanceInPopulation_mc
* evaluateModelRegression_mc
* evaluateModel_aggregation
* evaluateModel_mc
* evaluateModels_aggregation
* evaluatePopulation_mc
* evaluatesBestsModelsTest
* evolve_mc
* fit_mc
* generate_combinations_with_factors
* getFeaturePrevalence_mc
* getSign_mc
* listOfModels2ModelCollection
* listOfModelsToDenseCoefMatrix_mc
* listOfModelsToListOfDenseVec_mc
* listOfSparseVecToListOfModels_mc
* makeFeatureAnnot_mc
* maximization
* maximization_ovo
* meltScoreList_mc
* mergeMeltImportanceCV_mc
* modelToDenseVec_mc
* plotAUC_mc
* plotAbundanceByClass_mc
* plotFeatureModelCoeffs_mc
* plotModel_mc
* plotPrevalence_mc
* populationToDataFrame_mc
* predictModel_ova
* predictModel_ovo
* printClassifier_mc
* printExperiment_mc
* printModelCollection_mc
* printModel_mc
* printPopulation_mc
* printy_mc
* regenerate_clf
* runClassifier_mc
* runCrossval_mc
* sortPopulation
* sort_data
* terBeam_mc
* terga1_mc
* updateObjectIndex_mc
* voting
* votingova

To learn more about the functionality of each visualization tool, use the `??` command followed by the function name. For example, `??printy_mc` provides detailed information about the `printy_mc` function.


# Multiclass Predictions and Aggregation Methods

The package supports multiclass modeling using one-versus-all (OVA) and one-versus-one (OVO) approaches. Additionally, it provides multiple methods for aggregating predictions from these approaches, as well as tools for evaluating the aggregated models.
The available functions are:
Prediction: predictModel_ova, predictModel_ovo,
Aggregation: voting, maximization, maximization_ovo, Majority_Voting_with_Tie_Breaking, votingova, Majority_Voting_with_Tie_Breaking_ova
Evaluation: evaluateModel_aggregation, evaluateModels_aggregation.
Each function serves a unique role, whether it involves generating predictions, combining results, or assessing model performance. For more details, use the ?? command, such as ??predictModel_ova for the predictModel_ova function.

# Multiclass Algorithm Implementations

We have extended the terBeam and terga1 algorithms to handle multiclass problems, introducing a set of specialized functions for model generation, feature combination management, and evolution optimization. These tools are designed to create scalable and efficient multiclass models.
The implemented functions include:
terBeam_mc, terBeam_fit_mc
generateAllSingleFeatureModel_mc, generateAllCombinations_mc
countEachFeatureApperance_mc, getFeatures2Keep_mc
terga1_mc, terga1_mc_fit
evolve_mc
You can explore the purpose and functionality of each function using the ?? command. For example, ??terBeam_fit_mc will provide a detailed explanation of the terBeam_fit_mc function.

# Core Functionalities

To ensure flexibility and efficiency in training, testing, and validating multiclass models, we have implemented the following core functions:
fit_mc: Fits models to the provided dataset.
runClassifier_mc: Executes the classifier to generate predictions.
runCrossval_mc: Runs cross-validation to evaluate model performance.
These foundational functions make it easier to integrate multiclass workflows into your projects. For detailed information on any of these functions, use the ?? command, such as ??runClassifier_mc for the runClassifier_mc function.



# Experimental Phase

## Loading libraries

```{r warning=FALSE}
# Package multi class predomics
library(mcpredomics)
# Package predomics
library(predomics)
# Visualization library for creating complex plots
library(ggplot2) 
# Arranges multiple ggplot objects on a single page
library(gridExtra) 
# ROC curve analysis and AUC calculation
# Reshaping and melting data frames
library(reshape2) 
# Implementation of the Random Forest algorithm for classification and regression
library(randomForest) 
# Comprehensive library for classification and regression training
library(caret) 
# Various R programming tools and functions, including data manipulation
library(gtools) 
# Adding statistical comparisons and publication-ready visualizations
library(ggpubr) 
# Data manipulation and transformation (part of the tidyverse)
library(dplyr) 
# Tidying messy data by gathering and spreading
library(tidyr) 
# Enhanced data frames with row names as a column (tibble format)
library(tibble) 
# Dynamic report generation and displaying results in tables
library(knitr) 
# Creating aesthetically pleasing and customizable HTML tables
library(kableExtra) 
# Interactive tables for data visualization and exploration
library(DT) 
# Functions for statistical learning, including SVM and Naive Bayes
library(e1071) 
# Lasso and ridge regression via generalized linear models
library(glmnet) 
# Reading data from files (including CSV and text files)
library(readr) 
# String manipulation and regular expression functions
library(stringr) 
# package Excel
library(writexl)


```





## Dataset

We conducted experiments on several datasets. The first one comes from the MetaCardis project and consists of four enterotype groups: Bacteroidetes1, Bacteroidetes2, Prevotella, and Ruminococcus. To this end, we created an initial balanced dataset by randomly extracting the same number of samples from each group. We then used the original unbalanced dataset.

In addition, we integrated into our package the list predomics.inputs.ExperimentHubMulticlass, which contains about ten multiclass microbial datasets. In this study, we experimented with two of these datasets, namely:

A three-class dataset (Adenoma, Colorectal Cancer, Control) from the study by Qiang Feng et al.

A three-class dataset (T2D, IGT, and Control) from the study by Fredrik H. Karlsson.


### Balance the dataset Metacardis.

Here we present how to use the MetaCardis dataset with class balance. You simply need to uncomment the script to run it when needed.

```{r}
# # --------------------------------------------
# # Load data and required packages
# # --------------------------------------------
# 
# # mcpredomics provides the 'mc.input' demo object
# data("mc.input", package = "mcpredomics")
# 
# # 'createDataPartition' is provided by the 'caret' package
# # If you don't want to attach the package, replace the call by caret::createDataPartition(...)
# suppressPackageStartupMessages({
#   if (!requireNamespace("caret", quietly = TRUE)) {
#     stop("The 'caret' package is required for createDataPartition. Please install it: install.packages('caret')")
#   }
# })
# 
# # 'filterNoSignal' is expected to be available (e.g., from predomics/mcpredomics)
# # Make sure the package exposing this function is loaded if needed.
# 
# 
# # --------------------------------------------
# # Build response vector aligned with X
# # --------------------------------------------
# 
# set.seed(123)  # For reproducibility of any random steps above
# yvec <- mc.input$y$Enterotype[match(colnames(mc.input$X), rownames(mc.input$y))]
# 
# # --------------------------------------------
# # Basic filtering on features
# # --------------------------------------------
# 
# # Remove features with all-zero column sums
# X_general <- mc.input$X[, colSums(mc.input$X) != 0]
# 
# # Remove no-signal features (threshold set to "auto")
# X_general <- filterNoSignal(X = X_general, side = 1, threshold = "auto", verbose = FALSE)
# 
# # Final working copies
# set.seed(42)  # Reproducibility for the balancing step
# y <- as.vector(yvec)
# X <- X_general
# 
# # --------------------------------------------
# # Determine the target sample count per class
# # --------------------------------------------
# 
# # Minimum class size; we will sample this many instances from each class
# nombre_echantillons_par_classe <- min(table(y))
# 
# # --------------------------------------------
# # Helper to balance classes while preserving original order
# # --------------------------------------------
# 
# # Balances the dataset by randomly sampling the same number of indices
# # from each class, then sorts indices to keep original column order.
# equilibrer_classes <- function(y, X, nombre_echantillons_par_classe, seed = 123) {
#   # Identify unique classes
#   classes <- unique(y)
#   indices_equilibres <- integer(0)
#   
#   # Sample an equal number of indices for each class
#   for (classe in classes) {
#     indices_classe <- which(y == classe)
#     set.seed(seed)  # Keep reproducible sampling within each class
#     indices_equilibres <- c(indices_equilibres, sample(indices_classe, nombre_echantillons_par_classe))
#   }
#   
#   # Sort to preserve original order (important for aligned X columns)
#   indices_equilibres <- sort(indices_equilibres)
#   return(list(y = y[indices_equilibres], X = X[, indices_equilibres, drop = FALSE]))
# }
# 
# # --------------------------------------------
# # Build the balanced dataset
# # --------------------------------------------
# 
# donnees_equilibrees <- equilibrer_classes(y, X, nombre_echantillons_par_classe)
# y_equilibre <- donnees_equilibrees$y
# X_equilibre <- donnees_equilibrees$X
# 
# # --------------------------------------------
# # Train/test split (80/20) on the balanced data
# # --------------------------------------------
# 
# # Stratified split to keep class proportions in train/test
# set.seed(42)
# indices_division <- caret::createDataPartition(y_equilibre, p = 0.8, list = FALSE)
# 
# # Training split
# y <- as.vector(y_equilibre[indices_division])
# X <- X_equilibre[, indices_division, drop = FALSE]
# 
# # Test split
# y.test <- as.vector(y_equilibre[-indices_division])
# X.test <- X_equilibre[, -indices_division, drop = FALSE]
# 
# # --------------------------------------------
# # Quick sanity checks
# # --------------------------------------------
# 
# # Class distribution in training set
# print(table(y))
# 
# # Dimensions of training feature matrix
# print(dim(X))


```


### Original unbalanced dataset Metacardis

Please uncomment this code if needed.

```{r}
# # --------------------------------------------
# # Load the demo dataset provided in mcpredomics
# # --------------------------------------------
# data("mc.input", package = "mcpredomics")
# 
# # --------------------------------------------
# # Set a seed for reproducibility
# # --------------------------------------------
# set.seed(123)
# 
# # Extract the response vector (Enterotype labels) 
# # Ensure that columns of X and rows of y are properly aligned
# yvec <- mc.input$y$Enterotype[match(colnames(mc.input$X), rownames(mc.input$y))]
# 
# # --------------------------------------------
# # Filter features (columns) 
# # - Remove features with zero total abundance across all samples
# # - Apply filterNoSignal to remove uninformative features
# # --------------------------------------------
# X_general <- mc.input$X[, colSums(mc.input$X) != 0]
# X_general <- filterNoSignal(X = X_general, side = 1, threshold = "auto", verbose = FALSE)
# 
# # --------------------------------------------
# # Prepare working dataset
# # --------------------------------------------
# set.seed(42)      # Reset seed for reproducibility
# y <- as.vector(yvec)     # Response vector
# X <- X_general           # Filtered feature matrix
# 
# # --------------------------------------------
# # Create a stratified partition (80% training / 20% testing)
# # The function createDataPartition from caret ensures class balance
# # --------------------------------------------
# set.seed(42)
# indices_division <- createDataPartition(y, p = 0.8, list = FALSE)
# 
# # --------------------------------------------
# # Split the data
# # --------------------------------------------
# # Training set
# y <- as.vector(y[indices_division])
# X <- X[, indices_division, drop = FALSE]
# 
# # Test set
# y.test <- as.vector(y[-indices_division])
# X.test <- X[, -indices_division, drop = FALSE]
# 
# # --------------------------------------------
# # Quick checks: 
# # - Class distribution in the training set
# # - Dimensions of the training feature matrix
# # --------------------------------------------
# table(y)
# dim(X)

```

### Load Other Datasets

```{r}
# Load the file
data("predomics.inputs.ExperimentHubMulticlass", package = "mcpredomics")
lapply(predomics.inputs.ExperimentHubMulticlass, function(x){summary(colSums(x[["X"]]))})
```
#### Dataset Type 2 Diabetes (T2D)

Please uncomment this code if needed.


```{r}
# # --------------------------------------------
# # Dataset Type 2 Diabetes (T2D)
# # --------------------------------------------
# 
# # Load the KarlssonFH_2013 dataset from ExperimentHubMulticlass
# data1 <- predomics.inputs.ExperimentHubMulticlass$KarlssonFH_2013
# 
# # Extract metadata (phenotypes/labels)
# df <- data1$y.df
# y <- df$study_condition   # Response vector: study conditions
# 
# # Extract abundance/features matrix
# X <- data1$X
# 
# # --------------------------------------------
# # Quick sanity checks
# # --------------------------------------------
# 
# table(y)   # Show distribution of classes
# dim(X)     # Show dimensions of feature matrix

```


#### Dataset Colorectal cancer

We use an experimental example with the colorectal cancer dataset, which contains three classes, to illustrate and outline the steps.


```{r}
# --------------------------------------------
# Dataset Colorectal Cancer
# --------------------------------------------

# Load the FengQ_2015 dataset from ExperimentHubMulticlass
data1 <- predomics.inputs.ExperimentHubMulticlass$FengQ_2015

# Extract metadata (phenotypes/labels)
df <- data1$y.df
y <- df$study_condition   # Response vector: study conditions

# Extract abundance/features matrix
X <- data1$X

# --------------------------------------------
# Quick sanity checks
# --------------------------------------------

table(y)   # Show distribution of classes
dim(X)     # Show dimensions of feature matrix


```


## Experiments

In this example, we rely on the multiclass terBeam heuristic combined with the semi-constrained factor and OVO binarization, as this configuration yielded the optimal results according to the analyses reported in the Analyse_Resultat_Finale file. 


```{r}
clf <- terBeam_mc(sparsity = c(5,6,7,8,9), 
                                max.nb.features = 1000,
                                seed = 1,
                                nCores = 1,
                                evalToFit = "accuracy_",
                                objective = "auc",
                                experiment.id = "terBeam_mc",
                                experiment.save = "nothing")
  
                      
 printy(clf)  
```



### Running experiment

Three different constraint factors are implemented: unconstrained, fully_constrained, and semi_constrained. In this phase, we use the semi_constrained factor combined with the optimal aggregation method: Majority_Voting_with_Tie_Breaking.

```{r running experiment, echo=TRUE, fig.width=5, warning=FALSE}
runit = TRUE
if(runit)
{
res_clf_mc <- fit_mc(X = X, y = y, clf = clf,approch="ovo", cross.validate = TRUE,aggregation_ = "Majority_Voting_with_Tie_Breaking", nfolds = 10, constraint_factor = "semi_constrained"); 
save(res_clf_mc , clf, file ="res_clf_mc.rda", compression_level = 9)
}


```






### Family of Best Models (FBM)

A family of best models is defined as the set of models returned by the predomics algorithm, whose accuracy is within a given window of the best model's accuracy. This window is defined by computing a significance threshold assuming that accuracy follows a binomial distribution (p<0.05). 


```{r}
# Convert the model collection into a population of models scrambled by model size

pop <- modelCollectionToPopulation(res_clf_mc$classifier$models)
printy_mc(pop)
# Function to create boxplot for a given data frame
create_boxplot <- function(data, title) {
  # Melt the dataframe for ggplot
  data.melt <- melt(data, id.vars = c("accuracy_", "eval.sparsity"))
  
  # Create ggplot
  plot <- ggplot(data = data.melt, aes(y = accuracy_, x = eval.sparsity)) +
    geom_boxplot(notch = FALSE, outlier.shape = NA, position = position_dodge(width = 0.9), alpha = 0.3) +
    geom_point(aes(color = eval.sparsity), position = position_jitterdodge(dodge.width = 0.9), size = 1, alpha = 0.5) +
    ylim(c(0, 1)) +
    xlab("Model Parsimony") +
    ggtitle(title) +
    theme_bw() +
    theme(legend.position = "bottom", legend.direction = "horizontal") +
    guides(colour = "none")
  
  return(plot)
}

# Convert the population to a data frame
pop.df <- populationToDataFrame_mc(pop)

# Plotting for the original population (single figure)
pop.dff <- as.data.frame(pop.df[[1]])  # Convert the first submodel to a data frame
g.before <- create_boxplot(pop.dff, title = "Original Population")
#print(g.before)  # Display the plot

# Select the best population models
fbm <- selectBestPopulation(pop)
printy_mc(fbm)

# Convert the best population models to a data frame
fbm.df <- populationToDataFrame_mc(fbm)

# Plotting for the selected best models (single figure)
fbm.dff <- as.data.frame(fbm.df[[1]])  # Convert the first submodel to a data frame
g.after <- create_boxplot(fbm.dff, title = "FBM")
print(g.after)  # Display the plot
```

###Analyzing the FBM

The analysis of the family of best models (FBM) can be very insightful for discovering the most important variables in the prediction process. Let's start by examining the usage of variables in the FBM models. For this, we run the ?makeFeatureAnnot_mc function to obtain the feature distribution in the model matrix, which is a list of pop.noz elements. The models in the FBM are ranked by accuracy, and this order will be preserved in the coefficient dataframe. There are 20 features found in the FBM models. The figure below shows that some of these features are very prevalent in the FBM, making them likely important. The abundance and prevalence distribution of these features can be explored with ?plotAbundanceByClass_mc and ?plotPrevalence_mc, respectively. Gray stars on the right side of the graphics indicate significant differences between the prediction groups.


```{r warning=FALSE, paged.print=FALSE, message=FALSE,fig.height=8, fig.width=43}
fa <- makeFeatureAnnot_mc(pop = fbm, 
                          X = X, 
                          y = y, 
                          clf = clf,
                          approch = "ovo")
plot_distribution <- plotFeatureModelCoeffs_mc(feat.model.coeffs = fa, y, approch = "ovo")
plots_abundance <- plotAbundanceByClass_mc(features = fa, X, y, approch = "ovo")
plots_prevalence <- plotPrevalence_mc(features = fa, X = X, y = y, approch = "ovo")
```


### Feature importance

Finally, we can explore the feature importance using mean decrease accuracy information computed during the cross-validation process. It is worth noting that the order of variables based on the prevalence in FBM, is concordant with the order of mean decrease accuracy (i.e. importance) in the cross-validation. But when we look at the variables based on their importance indipendetly on the empirical learning FBM, the picture changes somewhow. There are some important variables that were not selected in the FBM of the whole dataset. It is thus important to explore the cross validation importance.

```{r warning=FALSE, paged.print=FALSE, message=FALSE,fig.height=8, fig.width=43}

feat1.import <- mergeMeltImportanceCV_mc(list.results = list(terBeam =  res_clf_mc),
                                         filter.cv.prev = 0,
                                         min.kfold.nb = FALSE,
                                         learner.grep.pattern = "*",
                                         #nb.top.features = 50,
                                         feature.selection = fa,
                                         scaled.importance = TRUE,
                                         make.plot = TRUE,
                                         cv.prevalence = FALSE)


feat2.import <- mergeMeltImportanceCV_mc(list.results = list(terBeam = res_clf_mc),
                                         filter.cv.prev = 0,
                                         min.kfold.nb = FALSE,
                                         learner.grep.pattern = "*",
                                         nb.top.features = 148,
                                         #feature.selection = rownames(fa$pop.noz),
                                         scaled.importance = TRUE,
                                         make.plot = TRUE,
                                         cv.prevalence = FALSE)
```



### Visualizing the best model

The best-learned model can be visualized simply by printing it along with a summary of information on performance and model size. Furthermore, we can further explore the model by visualizing it using the barcode plot ?plotModel_mc. Finally, the importance of each feature can also be displayed using the same function, as illustrated in the figure below.

```{r best model, fig.height=28, fig.width=70, warning=FALSE}

# --------------------------------------------
# Get the best model (first element of fbm)
# --------------------------------------------
best.model <- fbm[[1]]

# --------------------------------------------
# Print model information (optional)
# --------------------------------------------
printy_mc(best.model)

# --------------------------------------------
# Generate plots for model visualization
# - plots1: basic coefficients visualization
# - plots2: importance-based visualization
# --------------------------------------------
plots1 <- plotModel_mc(best.model, X, y, sort.features = FALSE, feature.name = TRUE, approch = "ovo")
plots2 <- plotModel_mc(best.model, X, y, sort.features = FALSE, feature.name = TRUE, importance = TRUE, approch = "ovo")

# --------------------------------------------
# Utility function to improve plot readability
# --------------------------------------------
adjust_plot_theme <- function(plot) {
  plot + theme(
    text = element_text(size = 16),              # Global text
    axis.title = element_text(size = 20),        # Axis titles
    axis.text = element_text(size = 14),         # Axis labels
    legend.title = element_text(size = 16),      # Legend title
    legend.text = element_text(size = 14),       # Legend text
    plot.title = element_text(size = 20, face = "bold"), # Plot title
    strip.text = element_text(size = 16)         # Facet labels
  )
}

# --------------------------------------------
# Apply the custom theme to all plots
# --------------------------------------------
plots1 <- lapply(plots1, adjust_plot_theme)
plots2 <- lapply(plots2, adjust_plot_theme)

# --------------------------------------------
# Save plots as a PDF file with high readability
# PDF size here is set to approx. A0 format
# --------------------------------------------
pdf("model_visualization_plots2.pdf", width = 70, height = 28)  
grid.arrange(grobs = c(plots1, plots2), ncol = 3)
dev.off()
cat("The plots have been saved under the name 'model_visualization_plots2.pdf'.\n")

# --------------------------------------------
# Direct visualization in RStudio (with better fonts)
# --------------------------------------------
grid.arrange(grobs = c(plots1, plots2), ncol = 3)



```















